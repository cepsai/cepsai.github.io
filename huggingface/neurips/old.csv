,id,forum,number,title,abstract,authors,authorids,venue,venueid,primary_area,pdf,cdate_iso,pdate_iso,mdate_iso,openreview_url,institutions
21,aVh9KRZdRk,aVh9KRZdRk,21497,Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks,"Large language models can solve tasks that were not present in the training set. This capability is believed to be due to in-context learning and skill composition. In this work, we study the emergence of in-context learning and skill composition in a collection of modular arithmetic tasks. Specifically, we consider a finite collection of linear modular functions $z = a  x + b  y \text{ mod } p$ labeled by the vector $(a, b) \in \mathbb{Z}_p^2$. We use some of these tasks for pre-training and the rest for out-of-distribution testing. We empirically show that a GPT-style transformer exhibits a transition from in-distribution to out-of-distribution generalization as the number of pre-training tasks increases. We find that the smallest model capable of out-of-distribution generalization requires two transformer blocks, while for deeper models, the out-of-distribution generalization phase is *transient*, necessitating early stopping. Finally, we perform an interpretability study of the pre-trained models, revealing highly structured representations in both attention heads and MLPs; and discuss the learned algorithms. Notably, we find an algorithmic shift in deeper models, as we go from few to many in-context examples.",Tianyu He; Darshil Doshi; Aritra Das; Andrey Gromov,~Tianyu_He2; ~Darshil_Doshi1; ~Aritra_Das1; ~Andrey_Gromov1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/5737b58d308dafc16130635934df4276a7a574aa.pdf,2024-05-15T19:42:34.333000,2024-09-25T18:17:36.361000,2024-11-06T06:20:05.890000,https://openreview.net/forum?id=aVh9KRZdRk,"University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park"
25,uSKzEaj9zJ,uSKzEaj9zJ,21440,Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery,"Despite recent popularity of attention-based neural architectures in core AI fields like natural language processing (NLP) and computer vision (CV), their potential in modeling complex physical systems remains under-explored. Learning problems in physical systems are often characterized as discovering operators that map between function spaces based on a few instances of function pairs. This task frequently presents a severely ill-posed PDE inverse problem. In this work, we propose a novel neural operator architecture based on the attention mechanism, which we coin Nonlocal Attention Operator (NAO), and explore its capability towards developing a foundation physical model. In particular, we show that the attention mechanism is equivalent to a double integral operator that enables nonlocal interactions among spatial tokens, with a data-dependent kernel characterizing the inverse mapping from data to the hidden parameter field of the underlying operator. As such, the attention mechanism extracts global prior information from training data generated by multiple systems, and suggests the exploratory space in the form of a nonlinear kernel map. Consequently, NAO can address ill-posedness and rank deficiency in inverse PDE problems by encoding regularization and achieving generalizability. Lastly, we empirically demonstrate the advantages of NAO over baseline neural models in terms of the generalizability to unseen data resolutions and system states. Our work not only suggests a novel neural operator architecture for learning an interpretable foundation model of physical systems, but also offers a new perspective towards understanding the attention mechanism.",Yue Yu; Ning Liu; Fei Lu; Tian Gao; Siavash Jafarzadeh; Stewart A Silling,~Yue_Yu3; ~Ning_Liu6; ~Fei_Lu2; ~Tian_Gao1; ~Siavash_Jafarzadeh1; ~Stewart_A_Silling1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/6cac3b157a00647405bf6878194d4c24024eac22.pdf,2024-05-15T19:37:08.327000,2024-09-25T18:17:35.522000,2024-11-06T06:20:05.786000,https://openreview.net/forum?id=uSKzEaj9zJ,"Lehigh University; Global Engineering and Materials, Inc."
27,owuEcT6BTl,owuEcT6BTl,21435,Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space,"Modern generative models demonstrate impressive capabilities, likely stemming from an ability to identify and manipulate abstract concepts underlying their training data. However, fundamental questions remain: what determines the concepts a model learns, the order in which it learns them, and its ability to manipulate those concepts? To address these questions, we propose analyzing a model’s learning dynamics via a framework we call the concept space, where each axis represents an independent concept underlying the data generating process. By characterizing learning dynamics in this space, we identify how the speed at which a concept is learned, and hence the order of concept learning, is controlled by properties of the data we term concept signal. Further, we observe moments of sudden turns in the direction of a model’s learning dynamics in concept space. Surprisingly, these points precisely correspond to the emergence of hidden capabilities, i.e., where latent interventions show the model possesses the capability to manipulate a concept, but these capabilities cannot yet be elicited via naive input prompting. While our results focus on synthetically defined toy datasets, we hypothesize a general claim on emergence of hidden capabilities may hold: generative models possess latent capabilities that emerge suddenly and consistently during training, though a model might not exhibit these capabilities under naive input prompting.",Core Francisco Park; Maya Okawa; Andrew Lee; Ekdeep Singh Lubana; Hidenori Tanaka,~Core_Francisco_Park1; ~Maya_Okawa1; ~Andrew_Lee2; ~Ekdeep_Singh_Lubana1; ~Hidenori_Tanaka1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/cd344c6f2d8a5970e4d4267156a7cfb867521da6.pdf,2024-05-15T19:36:55.850000,2024-09-25T18:17:35.090000,2024-12-18T19:45:51.648000,https://openreview.net/forum?id=owuEcT6BTl,Harvard University; Harvard University; University of Michigan - Ann Arbor; Harvard University; University of Michigan - Ann Arbor; Harvard University; NTT
30,qOSFiJdVkZ,qOSFiJdVkZ,21363,Continual learning with the neural tangent ensemble,"A natural strategy for continual learning is to weigh a Bayesian ensemble of fixed functions. This suggests that if a (single) neural network could be interpreted as an ensemble, one could design effective algorithms that learn without forgetting. To realize this possibility, we observe that a neural network classifier with N parameters can be interpreted as a weighted ensemble of N classifiers, and that in the lazy regime limit these classifiers are fixed throughout learning. We call these classifiers the *neural tangent experts* and show they output valid probability distributions over the labels. We then derive the likelihood and posterior probability of each expert given past data. Surprisingly,  the posterior updates for these experts are equivalent to a scaled and projected form of stochastic gradient descent (SGD) over the network weights. Away from the lazy regime, networks can be seen as ensembles of adaptive experts which improve over time. These results offer a new interpretation of neural networks as Bayesian ensembles of experts, providing a principled framework for understanding and mitigating catastrophic forgetting in continual learning settings.",Ari S Benjamin; Christian-Gernot Pehle; Kyle Daruwalla,~Ari_S_Benjamin1; ~Christian-Gernot_Pehle1; ~Kyle_Daruwalla1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,online_learning,/pdf/7ca99de5c6a3ad1c6a158db1bba6a3eb0841e7bc.pdf,2024-05-15T19:30:22.195000,2024-09-25T18:17:33.901000,2024-11-06T06:20:05.581000,https://openreview.net/forum?id=qOSFiJdVkZ,Cold Spring Harbor Laboratory; Cold Spring Harbor Laboratory
32,m6pVpdIN0y,m6pVpdIN0y,21353,Neglected Hessian component explains mysteries in sharpness regularization,"Recent work has shown that methods that regularize second order information like SAM can improve generalization in deep learning. Seemingly similar methods like weight noise and gradient penalties often fail to provide such benefits. We investigate this inconsistency and reveal its connection to the the structure of the Hessian of the loss. Specifically, its decomposition into the positive semi-definite Gauss-Newton matrix and an indefinite matrix, which we call the Nonlinear Modeling Error (NME) matrix. Previous studies have largely overlooked the significance of the NME in their analysis for various reasons. However, we provide empirical and theoretical evidence that the NME is important to the performance of gradient penalties and explains their sensitivity to activation functions. We also provide evidence that the difference in regularization performance between gradient penalties and weight noise can be explained by the NME. Our findings emphasize the necessity of considering the NME in both experimental design and theoretical analysis for sharpness regularization.",Yann Dauphin; Atish Agarwala; Hossein Mobahi,~Yann_Dauphin1; ~Atish_Agarwala1; ~Hossein_Mobahi2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/c1f6ee9f0e9ec1784d61f91dc4fd53ea887eb3b7.pdf,2024-05-15T19:29:46.050000,2024-09-25T18:17:33.780000,2024-11-06T06:20:05.520000,https://openreview.net/forum?id=m6pVpdIN0y,
37,wm9JZq7RCe,wm9JZq7RCe,21294,An Analysis of Tokenization: Transformers under Markov Data,"While there has been a large body of research attempting to circumvent tokenization for language modeling (Clark et al. 2022, Xue et al. 2022), the current consensus is that it is a necessary initial step for designing state-of-the-art performant language models. In this paper, we investigate tokenization from a theoretical point of view by studying the behavior of transformers on simple data generating processes. When trained on data drawn from certain simple $k^{\text{th}}$-order Markov processes for $k > 1$, transformers exhibit a surprising phenomenon - in the absence of tokenization, they empirically are incredibly slow or fail to learn the right distribution and predict characters according to a unigram model (Makkuva et al. 2024). With the addition of tokenization, however, we empirically observe that transformers break through this barrier and are able to model the probabilities of sequences drawn from the source near-optimally, achieving small cross-entropy loss. With this observation as starting point, we study the end-to-end cross-entropy loss achieved by transformers with and without tokenization. With the appropriate tokenization, we show that even the simplest unigram models (over tokens) learnt by transformers are able to model the probability of sequences drawn from $k^{\text{th}}$-order Markov sources near optimally. Our analysis provides a justification for the use of tokenization in practice through studying the behavior of transformers on Markovian data.",Nived Rajaraman; Jiantao Jiao; Kannan Ramchandran,~Nived_Rajaraman1; ~Jiantao_Jiao1; ~Kannan_Ramchandran1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/d6c78ee455f5fe6feda13258c2c22ffcc162624c.pdf,2024-05-15T19:25:32.543000,2024-09-25T18:17:31.988000,2024-11-15T17:53:05.062000,https://openreview.net/forum?id=wm9JZq7RCe,"University of California, Berkeley"
47,dtPIUXdJHY,dtPIUXdJHY,21176,Generalization Analysis for Label-Specific Representation Learning,"Label-specific representation learning (LSRL), i.e., constructing the representation with specific discriminative properties for each class label, is an effective strategy to improve the performance of multi-label learning. However, the generalization analysis of LSRL is still in its infancy. The existing theory bounds for multi-label learning, which preserve the coupling among different components, are invalid for LSRL. In an attempt to overcome this challenge and make up for the gap in the generalization theory of LSRL, we develop a novel vector-contraction inequality and derive the generalization bound for general function class of LSRL with a weaker dependency on the number of labels than the state of the art. In addition, we derive generalization bounds for typical LSRL methods, and these theoretical results reveal the impact of different label-specific representations on generalization analysis. The mild bounds without strong assumptions explain the good generalization ability of LSRL.",Yifan Zhang; Min-Ling Zhang,~Yifan_Zhang13; ~Min-Ling_Zhang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/366680d63d269891a286691d985e0b23a0be2b9c.pdf,2024-05-15T19:14:28.356000,2024-09-25T18:17:29.734000,2024-12-30T18:03:57.695000,https://openreview.net/forum?id=dtPIUXdJHY,Southeast University
55,7sACcaOmGi,7sACcaOmGi,21125,The Power of Resets in Online Reinforcement Learning,"Simulators are a pervasive tool in reinforcement learning, but most existing algorithms cannot efficiently exploit simulator access -- particularly in high-dimensional domains that require general function approximation. We explore the power of simulators through online reinforcement learning with local simulator access (or, local planning), an RL protocol where the agent is allowed to reset to previously observed states and follow their dynamics during training. We use local simulator access to unlock new statistical guarantees that were previously out of reach:
- We show that MDPs with low coverability (Xie et al. 2023) -- a general structural condition that subsumes Block MDPs and Low-Rank MDPs -- can be learned in a sample-efficient fashion with only Q⋆-realizability (realizability of the optimal state-value function); existing online RL algorithms require significantly stronger representation conditions.
- As a consequence, we show that the notorious Exogenous Block MDP problem (Efroni et al. 2022) is tractable under local simulator access.
The results above are achieved through a computationally inefficient algorithm. We complement them with a more computationally efficient algorithm, RVFS (Recursive Value Function Search), which achieves provable sample complexity guarantees under a strengthened statistical assumption known as pushforward coverability. RVFS can be viewed as a principled, provable counterpart to a successful empirical paradigm that combines recursive search (e.g., MCTS) with value function approximation.",Zakaria Mhammedi; Dylan J Foster; Alexander Rakhlin,~Zakaria_Mhammedi1; ~Dylan_J_Foster1; ~Alexander_Rakhlin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/fda028ecb1732284f7e606eff350f4f12b43fdba.pdf,2024-05-15T19:09:28.986000,2024-09-25T18:17:28.834000,2024-11-06T06:20:04.729000,https://openreview.net/forum?id=7sACcaOmGi,Google; Microsoft
70,LxxIiInmuF,LxxIiInmuF,20958,Paths to Equilibrium in Games,"In multi-agent reinforcement learning (MARL) and game theory, agents repeatedly interact and revise their strategies as new data arrives, producing a sequence of strategy profiles. This paper studies sequences of strategies satisfying a pairwise constraint inspired by policy updating in reinforcement learning, where an agent who is best responding in one period does not switch its strategy in the next period. This constraint merely requires that optimizing agents do not switch strategies, but does not constrain the non-optimizing agents in any way, and thus allows for exploration. Sequences with this property are called satisficing paths, and arise naturally in many MARL algorithms.  A fundamental question about strategic dynamics is such: for a given game and initial strategy profile, is it always possible to construct a satisficing path that terminates at an equilibrium? The resolution of this question has implications about the capabilities or limitations of a class of MARL algorithms. We answer this question in the affirmative for normal-form games. Our analysis reveals a counterintuitive insight that suboptimal, and perhaps even reward deteriorating, strategic updates are key to driving play to equilibrium along a satisficing path.",Bora Yongacoglu; Gurdal Arslan; Lacra Pavel; Serdar Yuksel,~Bora_Yongacoglu1; ~Gurdal_Arslan1; ~Lacra_Pavel1; ~Serdar_Yuksel1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/582aaeff29e17b6359504251c8c0b44500771299.pdf,2024-05-15T18:56:17.268000,2024-09-25T18:17:25.762000,2024-11-06T06:20:04.174000,https://openreview.net/forum?id=LxxIiInmuF,University of Toronto; University of Hawaii at Manoa
95,LJNqVIKSCr,LJNqVIKSCr,20765,Double-Ended Synthesis Planning with Goal-Constrained Bidirectional Search,"Computer-aided synthesis planning (CASP) algorithms have demonstrated expert-level abilities in planning retrosynthetic routes to molecules of low to moderate complexity. However, current search methods assume the sufficiency of reaching arbitrary building blocks, failing to address the common real-world constraint where using specific molecules is desired. To this end, we present a formulation of synthesis planning with starting material constraints. Under this formulation, we propose Double-Ended Synthesis Planning ($\texttt{DESP}$), a novel CASP algorithm under a _bidirectional graph search_ scheme that interleaves expansions from the target and from the goal starting materials to ensure constraint satisfiability. The search algorithm is guided by a goal-conditioned cost network learned offline from a partially observed hypergraph of valid chemical reactions. We demonstrate the utility of $\texttt{DESP}$ in improving solve rates and reducing the number of search expansions by biasing synthesis planning towards expert goals on multiple new benchmarks. $\texttt{DESP}$ can make use of existing one-step retrosynthesis models, and we anticipate its performance to scale as these one-step model capabilities improve.",Kevin Yu; Jihye Roh; Ziang Li; Wenhao Gao; Runzhong Wang; Connor W. Coley,~Kevin_Yu1; ~Jihye_Roh1; ~Ziang_Li2; ~Wenhao_Gao1; ~Runzhong_Wang1; ~Connor_W._Coley1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/28a84c7beddeea0844e294d5a0ccea7ea6314dc5.pdf,2024-05-15T18:37:14.534000,2024-09-25T18:17:21.227000,2024-11-06T06:20:03.250000,https://openreview.net/forum?id=LJNqVIKSCr,Massachusetts Institute of Technology; Massachusetts Institute of Technology; Georgia Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology
104,nY0BrZdqLt,nY0BrZdqLt,20713,Time-Reversal Provides Unsupervised Feedback to LLMs,"Large Language Models (LLMs) are typically trained to predict in the forward direction of time. However, recent works have shown that prompting these models to look back and critique their own generations can produce useful feedback. Motivated by this, we explore the question of whether LLMs can be empowered to think (predict and score) backwards to provide unsupervised feedback that complements forward LLMs. Towards this, we introduce Time Reversed Language Models (TRLMs), which can score and generate queries when conditioned on responses, effectively functioning in the reverse direction of time. Further, to effectively infer in the response to query direction, we pre-train and fine-tune a language model (TRLM-Ba) in the reverse token order from scratch. We show empirically (and theoretically in a stylized setting) that time-reversed models can indeed complement forward model predictions when used to score the query given response for re-ranking multiple forward generations. We obtain up to 5\% improvement on the widely used AlpacaEval Leaderboard over the competent baseline of best-of-N re-ranking using self log-perplexity scores. We further show that TRLM scoring outperforms conventional forward scoring of response given query, resulting in significant gains in applications such as citation generation and passage retrieval. We next leverage the generative ability of TRLM to augment or provide unsupervised feedback to input safety filters of LLMs, demonstrating a drastic reduction in false negative rate with negligible impact on false positive rates against several attacks published on the popular JailbreakBench leaderboard.",Yerram Varun; Rahul Madhavan; Sravanti Addepalli; Arun Suggala; Karthikeyan Shanmugam; Prateek Jain,~Yerram_Varun1; ~Rahul_Madhavan1; ~Sravanti_Addepalli1; ~Arun_Suggala1; ~Karthikeyan_Shanmugam1; ~Prateek_Jain1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/08ee7a3ea3b3fd8e7bf896a4e8fac2fc695aab87.pdf,2024-05-15T18:33:10.836000,2024-09-25T18:17:19.996000,2024-12-28T14:58:55.152000,https://openreview.net/forum?id=nY0BrZdqLt,"Indian Institute of Science, Bangalore; Indian Institute of Science, Bangalore; Google; Google; Google"
109,fOQunr2E0T,fOQunr2E0T,20686,Compositional Generalization Across Distributional Shifts with Sparse Tree Operations,"Neural networks continue to struggle with compositional generalization, and this issue is exacerbated by a lack of massive pre-training. One successful approach for developing neural systems which exhibit human-like compositional generalization is $\textit{hybrid}$ neurosymbolic techniques. However, these techniques run into the core issues that plague symbolic approaches to AI: scalability and flexibility. The reason for this failure is that at their core, hybrid neurosymbolic models perform symbolic computation and relegate the scalable and flexible neural computation to parameterizing a symbolic system. We investigate a $\textit{unified}$ neurosymbolic system where transformations in the network can be interpreted simultaneously as both symbolic and neural computation. We extend a unified neurosymbolic architecture called the Differentiable Tree Machine in two central ways. First, we significantly increase the model’s efficiency through the use of sparse vector representations of symbolic structures. Second, we enable its application beyond the restricted set of tree2tree problems to the more general class of seq2seq problems. The improved model retains its prior generalization capabilities and, since there is a fully neural path through the network, avoids the pitfalls of other neurosymbolic techniques that elevate symbolic computation over neural computation.",Paul Soulos; Henry Conklin; Mattia Opper; Paul Smolensky; Jianfeng Gao; Roland Fernandez,~Paul_Soulos1; ~Henry_Conklin1; ~Mattia_Opper1; ~Paul_Smolensky1; ~Jianfeng_Gao1; ~Roland_Fernandez1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/aed15ce9fc817ff18604e2186dc4382de379f78a.pdf,2024-05-15T18:30:47.938000,2024-09-25T18:17:19.429000,2024-12-18T20:22:13.166000,https://openreview.net/forum?id=fOQunr2E0T,University of Edinburgh; University of Edinburgh; Microsoft
113,AbTpJl7vN6,AbTpJl7vN6,20639,Flexible task abstractions emerge in linear networks with fast and bounded units,"Animals survive in dynamic environments changing at arbitrary timescales, but such data distribution shifts are a challenge to neural networks. To adapt to change, neural systems may change a large number of parameters, which is a slow process involving forgetting past information. In contrast, animals leverage distribution changes to segment their stream of experience into tasks and associate them with internal task abstracts. Animals can then respond flexibly by selecting the appropriate task abstraction. However, how such flexible task abstractions may arise in neural systems remains unknown. Here, we analyze a linear gated network where the weights and gates are jointly optimized via gradient descent, but with neuron-like constraints on the gates including a faster timescale, non-negativity, and bounded activity. We observe that the weights self-organize into modules specialized for tasks or sub-tasks encountered, while the gates layer forms unique representations that switch the appropriate weight modules (task abstractions). We analytically reduce the learning dynamics to an effective eigenspace, revealing a virtuous cycle: fast adapting gates drive weight specialization by protecting previous knowledge, while weight specialization in turn increases the update rate of the gating layer. Task switching in the gating layer accelerates as a function of curriculum block size and task training, mirroring key findings in cognitive neuroscience. We show that the discovered task abstractions support generalization through both task and subtask composition, and we extend our findings to a non-linear network switching between two tasks. Overall, our work offers a theory of cognitive flexibility in animals as arising from joint gradient descent on synaptic and neural gating in a neural network architecture.",Kai Jappe Sandbrink; Jan Philipp Bauer; Alexandra Maria Proca; Andrew M Saxe; Christopher Summerfield; Ali Hummos,~Kai_Jappe_Sandbrink1; ~Jan_Philipp_Bauer1; ~Alexandra_Maria_Proca1; ~Andrew_M_Saxe1; ~Christopher_Summerfield2; ~Ali_Hummos1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/91f2b1e84633a2f794ca5f058a2d41a582bfb93b.pdf,2024-05-15T18:25:59.956000,2024-09-25T18:17:18.399000,2025-01-15T17:42:55.354000,https://openreview.net/forum?id=AbTpJl7vN6,EPFL - EPF Lausanne; University of Oxford; University College London; Hebrew University of Jerusalem; Imperial College London; University College London
114,7Swrtm9Qsp,7Swrtm9Qsp,20638,Stable Minima Cannot Overfit in Univariate ReLU Networks: Generalization by Large Step Sizes,"We study the generalization of two-layer ReLU neural networks in a univariate nonparametric regression problem with noisy labels. This is a problem where kernels (\emph{e.g.} NTK) are provably sub-optimal and benign overfitting does not happen, thus disqualifying existing theory for interpolating (0-loss, global optimal) solutions. We present a new theory of generalization for local minima that gradient descent with a constant learning rate can \emph{stably} converge to.  We show that gradient descent with a fixed learning rate $\eta$ can only find local minima that represent smooth functions with a certain weighted \emph{first order total variation} bounded by $1/\eta - 1/2 + \widetilde{O}(\sigma + \sqrt{\mathrm{MSE}})$ where $\sigma$ is the label noise level, $\mathrm{MSE}$ is short for mean squared error against the ground truth, and $\widetilde{O}(\cdot)$ hides a logarithmic factor. Under mild assumptions, we also prove a nearly-optimal MSE bound of $\widetilde{O}(n^{-4/5})$  within the strict interior of the support of the $n$ data points. Our theoretical results are validated by extensive simulation that demonstrates large learning rate training induces sparse linear spline fits. To the best of our knowledge, we are the first to obtain generalization bound via minima stability in the non-interpolation case and the first to show ReLU NNs without regularization can achieve near-optimal rates in nonparametric regression.",Dan Qiao; Kaiqi Zhang; Esha Singh; Daniel Soudry; Yu-Xiang Wang,~Dan_Qiao1; ~Kaiqi_Zhang2; ~Esha_Singh1; ~Daniel_Soudry1; ~Yu-Xiang_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/52b99ae7d04dbbc7673c754b5d471e8b6c2ea071.pdf,2024-05-15T18:25:52.222000,2024-09-25T18:17:18.315000,2024-11-06T06:20:02.498000,https://openreview.net/forum?id=7Swrtm9Qsp,"University of California, San Diego; University of California, Santa Barbara; University of California, San Diego; University of California, Santa Barbara; Computer Science Department, Technion - Israel Institute of Technology; University of California, San Diego; University of California, Santa Barbara"
115,Li2rpRZWjy,Li2rpRZWjy,20620,Rule Extrapolation in Language Modeling: A Study of Compositional Generalization on OOD Prompts,"LLMs show remarkable emergent abilities, such as inferring concepts from presumably out-of-distribution prompts, known as in-context learning. Though this success is often attributed to the Transformer architecture, our systematic understanding is limited. In complex real-world data sets, even defining what is out-of-distribution is not obvious. To better understand the OOD behaviour of autoregressive LLMs, we focus on formal languages, which are defined by the intersection of rules. We define a new scenario of OOD compositional generalization, termed \textit{rule extrapolation}. Rule extrapolation describes OOD scenarios, where the prompt violates at least one rule. We evaluate rule extrapolation in formal languages with varying complexity in linear and recurrent architectures, the Transformer, and state space models to understand the architectures' influence on rule extrapolation. We also lay the first stones of a normative theory of rule extrapolation, inspired by the Solomonoff prior in algorithmic information theory.",Anna Mészáros; Szilvia Ujváry; Wieland Brendel; Patrik Reizinger; Ferenc Huszár,~Anna_Mészáros1; ~Szilvia_Ujváry1; ~Wieland_Brendel1; ~Patrik_Reizinger1; ~Ferenc_Huszár1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/3af363183546a7b36996e9a348c55afdeac6a35f.pdf,2024-05-15T18:24:46.234000,2024-09-25T18:17:17.901000,2024-11-06T06:20:02.452000,https://openreview.net/forum?id=Li2rpRZWjy,"ELLIS Institute, Tübingen; University of Tübingen"
120,kfdEXQu6MC,kfdEXQu6MC,20594,A generalized neural tangent kernel for surrogate gradient learning,"State-of-the-art neural network training methods depend on the gradient of the network function. Therefore, they cannot be applied to networks whose activation functions do not have useful derivatives, such as binary and discrete-time spiking neural networks. To overcome this problem, the activation function's derivative is commonly substituted with a surrogate derivative, giving rise to surrogate gradient learning (SGL). This method works well in practice but lacks theoretical foundation.

The neural tangent kernel (NTK) has proven successful in the analysis of gradient descent. Here, we provide a generalization of the NTK, which we call the surrogate gradient NTK, that enables the analysis of SGL. First, we study a naive extension of the NTK to activation functions with jumps, demonstrating that gradient descent for such activation functions is also ill-posed in the infinite-width limit. To address this problem, we generalize the NTK to gradient descent with surrogate derivatives, i.e., SGL. We carefully define this generalization and expand the existing key theorems on the NTK with mathematical rigor. Further, we illustrate our findings with numerical experiments. Finally, we numerically compare SGL in networks with sign activation function and finite width to kernel regression with the surrogate gradient NTK; the results confirm that the surrogate gradient NTK provides a good characterization of SGL.",Luke Eilers; Raoul-Martin Memmesheimer; Sven Goedeke,~Luke_Eilers1; ~Raoul-Martin_Memmesheimer1; ~Sven_Goedeke1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/a3dec7e2507a4c6b97bd5406e21049ad0ea78ef0.pdf,2024-05-15T18:22:02.107000,2024-09-25T18:17:17.475000,2025-01-14T10:41:30.678000,https://openreview.net/forum?id=kfdEXQu6MC,University of Bonn; University of Freiburg
121,232VcN8tSx,232VcN8tSx,20576,GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration,"Online batch selection methods offer an adaptive alternative to static training data selection by dynamically selecting data batches during training. However, existing methods either rely on impractical reference models or simple heuristics that may not capture true data informativeness. To address these limitations, we propose \emph{GREedy Approximation Taylor Selection} (GREATS), a principled and efficient online batch selection method that applies greedy algorithm to optimize the data batch quality approximated by Taylor expansion. We develop a series of techniques to scale GREATS to large-scale model training. Extensive experiments with large language models (LLMs) demonstrate that GREATS significantly improves training convergence speed and generalization performance.",Jiachen T. Wang; Tong Wu; Dawn Song; Prateek Mittal; Ruoxi Jia,~Jiachen_T._Wang1; ~Tong_Wu1; ~Dawn_Song1; ~Prateek_Mittal1; ~Ruoxi_Jia1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/7ba7cf8ca5ca55af699a32b1f769c0926532eb3e.pdf,2024-05-15T18:19:52.808000,2024-09-25T18:17:17.006000,2025-01-16T03:59:26.554000,https://openreview.net/forum?id=232VcN8tSx,Princeton University; Princeton University; Princeton University; Virginia Tech
133,RQCmMSSzvI,RQCmMSSzvI,20492,Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning,"Uncertainty quantification (UQ) is a crucial but challenging task in many high-dimensional learning problems to increase the confidence of a given predictor. We develop a new data-driven approach for UQ in regression that applies both to classical optimization approaches such as the LASSO as well as to neural networks. One of the most notable UQ techniques is the debiased LASSO, which modifies the LASSO to allow for the construction of asymptotic confidence intervals by decomposing the estimation error into a Gaussian and an asymptotically vanishing bias component. However, in real-world problems with finite-dimensional data, the bias term is often too significant to disregard, resulting in overly narrow confidence intervals. Our work rigorously addresses this issue and derives a data-driven adjustment that corrects the confidence intervals for a large class of predictors by estimating the means and variances of the bias terms from training data, exploiting high-dimensional concentration phenomena. This gives rise to non-asymptotic confidence intervals, which can help avoid overestimating certainty in critical applications such as MRI diagnosis. Importantly, our analysis extends beyond sparse regression to data-driven predictors like neural networks, enhancing the reliability of model-based deep learning. Our findings bridge the gap between established theory and the practical applicability of such methods.",Frederik Hoppe; Claudio Mayrink Verdun; Hannah Laus; Felix Krahmer; Holger Rauhut,~Frederik_Hoppe1; ~Claudio_Mayrink_Verdun1; ~Hannah_Laus1; ~Felix_Krahmer1; ~Holger_Rauhut1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/671e6746eaf5082a512cdfed10dc26c04a8dfb64.pdf,2024-05-15T18:11:47.779000,2024-09-25T18:17:14.918000,2025-01-16T10:48:32.767000,https://openreview.net/forum?id=RQCmMSSzvI,CONTACT-Software GmbH; RWTH Aachen University; Harvard University; Technical University of Munich; Ludwig-Maximilians-Universität München
182,go4zzXBWVs,go4zzXBWVs,20184,Boosting Vision-Language Models with Transduction,"Transduction is a powerful paradigm that leverages the structure of unlabeled data to boost predictive accuracy. We present TransCLIP, a novel and computationally efficient transductive approach designed for Vision-Language Models (VLMs). TransCLIP is applicable as a plug-and-play module on top of popular inductive zero- and few-shot models, consistently improving their performances. Our new objective function can be viewed as a regularized maximum-likelihood estimation, constrained by a KL divergence penalty that integrates the text-encoder knowledge and guides the transductive learning process. We further derive an iterative Block Majorize-Minimize (BMM) procedure for optimizing our objective, with guaranteed convergence and decoupled sample-assignment updates, yielding computationally efficient transduction for large-scale datasets. We report comprehensive evaluations, comparisons, and ablation studies that demonstrate: (i) Transduction can greatly enhance the generalization capabilities of inductive pretrained zero- and few-shot VLMs; (ii) TransCLIP substantially outperforms standard transductive few-shot learning methods relying solely on vision features, notably due to the KL-based language constraint.",Maxime Zanella; Benoît Gérin; Ismail Ben Ayed,~Maxime_Zanella1; ~Benoît_Gérin1; ~Ismail_Ben_Ayed1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/165a3547dab21e1476a8a33906c72652f74ed988.pdf,2024-05-15T17:42:09.350000,2024-09-25T18:17:07.311000,2024-11-06T06:19:59.762000,https://openreview.net/forum?id=go4zzXBWVs,"UCLouvain; UCLouvain; École de technologie supérieure, Université du Québec"
202,kXKrLsR4aJ,kXKrLsR4aJ,20062,Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space,"Even though a variety of methods have been proposed in the literature, efficient and effective latent-space control (i.e., control in a learned low-dimensional space) of physical systems remains an open challenge.
We argue that a promising avenue is to leverage powerful and well-understood closed-form strategies from control theory literature in combination with learned dynamics, such as potential-energy shaping.
We identify three fundamental shortcomings in existing latent-space models that have so far prevented this powerful combination: (i) they lack the mathematical structure of a physical system, (ii) they do not inherently conserve the stability properties of the real systems, (iii) these methods do not have an invertible mapping between input and latent-space forcing.
This work proposes a novel Coupled Oscillator Network (CON) model that simultaneously tackles all these issues. 
More specifically, (i) we show analytically that CON is a Lagrangian system - i.e., it possesses well-defined potential and kinetic energy terms. Then, (ii) we provide formal proof of global Input-to-State stability using Lyapunov arguments.
Moving to the experimental side, we demonstrate that CON reaches SoA performance when learning complex nonlinear dynamics of mechanical systems directly from images.
An additional methodological innovation contributing to achieving this third goal is an approximated closed-form solution for efficient integration of network dynamics, which eases efficient training.
We tackle (iii) by approximating the forcing-to-input mapping with a decoder that is trained to reconstruct the input based on the encoded latent space force.
Finally, we leverage these three properties and show that they enable latent-space control. We use an integral-saturated PID with potential force compensation and demonstrate high-quality performance on a soft robot using raw pixels as the only feedback information.",Maximilian Stölzle; Cosimo Della Santina,~Maximilian_Stölzle1; ~Cosimo_Della_Santina1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,robotics,/pdf/fac38d41d80be55ab5f6463f5ba220894dd5d996.pdf,2024-05-15T17:28:33.991000,2024-09-25T18:17:04.600000,2024-12-22T13:12:09.885000,https://openreview.net/forum?id=kXKrLsR4aJ,Delft University of Technology; Massachusetts Institute of Technology
234,hUGD1aNMrp,hUGD1aNMrp,19825,"Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability","We develop a unifying framework for information-theoretic lower bound in statistical estimation and interactive decision making. Classical lower bound techniques---such as Fano's method, Le Cam's method, and Assouad's lemma---are central to the study of minimax risk in statistical estimation, yet are insufficient to provide tight lower bounds for \emph{interactive decision making} algorithms that collect data interactively (e.g., algorithms for bandits and reinforcement learning). Recent work of Foster et al. provides minimax lower bounds for interactive decision making using seemingly different analysis techniques from the classical methods. These results---which are proven using a complexity measure known as the \emph{Decision-Estimation Coefficient} (DEC)---capture difficulties unique to interactive learning, yet do not recover the tightest known lower bounds for passive estimation. We propose a unified view of these distinct methodologies through a new lower bound approach called \emph{interactive Fano method}. As an application, we introduce a novel complexity measure, the \emph{Fractional Covering Number}, which facilitates the new lower bounds for interactive decision making that extend the DEC methodology by incorporating the complexity of estimation. Using the fractional covering number, we (i) provide a unified characterization of learnability for \emph{any} stochastic bandit problem, (ii) close the remaining gap between the upper and lower bounds in Foster et al. (up to polynomial factors) for any interactive decision making problem in which the underlying model class is convex.",Fan Chen; Dylan J Foster; Yanjun Han; Jian Qian; Alexander Rakhlin; Yunbei Xu,~Fan_Chen4; ~Dylan_J_Foster1; ~Yanjun_Han1; ~Jian_Qian2; ~Alexander_Rakhlin1; ~Yunbei_Xu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/94267aff144f6a5c859f0ceb646fc519cab87f8e.pdf,2024-05-15T17:09:28.226000,2024-09-25T18:16:59.084000,2025-01-15T08:17:01.766000,https://openreview.net/forum?id=hUGD1aNMrp,Massachusetts Institute of Technology; Microsoft; Massachusetts Institute of Technology; National University of Singapore; Massachusetts Institute of Technology
242,uvFDaeFR9X,uvFDaeFR9X,19778,"Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations","Variational inequalities represent a broad class of problems, including minimization and min-max problems, commonly found in machine learning. Existing second-order and high-order methods for variational inequalities require precise computation of derivatives, often resulting in prohibitively high iteration costs. In this work, we study the impact of Jacobian inaccuracy on second-order methods. For the smooth and monotone case, we establish a lower bound with explicit dependence on the level of Jacobian inaccuracy and propose an optimal algorithm for this key setting. When derivatives are exact, our method converges at the same rate as exact optimal second-order methods. To reduce the cost of solving the auxiliary problem, which arises in all high-order methods with global convergence, we introduce several Quasi-Newton approximations. Our method with Quasi-Newton updates achieves a global sublinear convergence rate. We extend our approach with a tensor generalization for inexact high-order derivatives and support the theory with experiments.",Artem Agafonov; Petr Ostroukhov; Roman Mozhaev; Konstantin Yakovlev; Eduard Gorbunov; Martin Takáč; Alexander Gasnikov; Dmitry Kamzolov,~Artem_Agafonov1; ~Petr_Ostroukhov1; ~Roman_Mozhaev1; ~Konstantin_Yakovlev2; ~Eduard_Gorbunov1; ~Martin_Takáč1; ~Alexander_Gasnikov1; ~Dmitry_Kamzolov1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/3fe99623de2ff3f95d6609a46442ea841749e161.pdf,2024-05-15T17:06:04.585000,2024-09-25T18:16:57.627000,2024-11-06T06:19:57.625000,https://openreview.net/forum?id=uvFDaeFR9X,Mohamed bin Zayed University of Artificial Intelligence; Institute for Information Transmission Problems; Mohamed bin Zayed University of Artificial Intelligence; Moscow Institute of Physics and Technology; National Research University Higher School of Economics; Huawei Noah's Ark Lab; Moscow Institute of Physics and Technology; Mohamed bin Zayed University of Artificial Intelligence; Mohamed bin Zayed University of Artificial Intelligence; The Skolkovo Institute of Science and Technology; Innopolis; Moscow Institute of Physics and Technology; Mohamed bin Zayed University of Artificial Intelligence
252,eSes1Mic9d,eSes1Mic9d,19693,Who's asking? User personas and the mechanics of latent misalignment,"Studies show that safety-tuned models may nevertheless divulge harmful information. In this work, we show that whether they do so depends significantly on who they are talking to, which we refer to as *user persona*. In fact, we find manipulating user persona to be more effective for eliciting harmful content than certain more direct attempts to control model refusal. We study both natural language prompting and activation steering as intervention methods and show that activation steering is significantly more effective at bypassing safety filters.
We shed light on the mechanics of this phenomenon by showing that even when model generations are safe, harmful content can persist in hidden representations and can be extracted by decoding from earlier layers.  We also show we can predict a persona’s effect on refusal given only the geometry of its steering vector. Finally, we show that certain user personas induce the model to form more charitable interpretations of otherwise dangerous queries.",Asma Ghandeharioun; Ann Yuan; Marius Guerard; Emily Reif; Michael A. Lepori; Lucas Dixon,~Asma_Ghandeharioun1; ~Ann_Yuan1; ~Marius_Guerard1; ~Emily_Reif2; ~Michael_A._Lepori1; ~Lucas_Dixon1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/705bfa192122d3300f182ceb90cb64e45c96c18a.pdf,2024-05-15T16:58:52.451000,2024-09-25T18:16:55.599000,2024-11-06T06:19:57.259000,https://openreview.net/forum?id=eSes1Mic9d,Google; Google; University of Washington; Brown University; Google
257,cyv0LkIaoH,cyv0LkIaoH,19674,Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences,"The rapid progress in generative models has resulted in impressive leaps in generation quality, blurring the lines between synthetic and real data. Web-scale datasets are now prone to the inevitable contamination by synthetic data, directly impacting the training of future generated models.
    Already, some theoretical results on self-consuming generative models (a.k.a., iterative retraining) have emerged in the literature, showcasing that either model collapse or stability could be possible depending on the fraction of generated data used at each retraining step.
    However, in practice, synthetic data is often subject to human feedback and curated by users before being used and uploaded online. For instance, many interfaces of popular text-to-image generative models, such as Stable Diffusion or Midjourney, produce several variations of an image for a given query which can eventually be curated by the users.
    In this paper, we theoretically study the impact of data curation on iterated retraining of generative models and show that it can be seen as an implicit preference optimization mechanism. However, unlike standard preference optimization, the generative model does not have access to the reward function or negative samples needed for pairwise comparisons. Moreover, our study doesn't require access to the density function, only to samples. We prove that, if the data is curated according to a reward model, then the expected reward of the iterative retraining procedure is maximized. We further provide theoretical results on the stability of the retraining loop when using a positive fraction of real data at each step. Finally, we conduct illustrative experiments on both synthetic datasets and on CIFAR10 showing that such a procedure amplifies biases of the reward model.",Damien Ferbach; Quentin Bertrand; Joey Bose; Gauthier Gidel,~Damien_Ferbach1; ~Quentin_Bertrand1; ~Joey_Bose1; ~Gauthier_Gidel1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/f07d0b33e2273d7fc20cee68f1443d6346c4b922.pdf,2024-05-15T16:57:33.581000,2024-09-25T18:16:55.207000,2024-11-06T06:19:57.071000,https://openreview.net/forum?id=cyv0LkIaoH,"Ecole Normale Supérieure; Montreal Institute of Learning Algorithms; Inria, Paris; University of Oxford; Montreal Institute of Learning Algorithms"
271,glfYOAzh2f,glfYOAzh2f,19619,Selective Generation for Controllable Language Models,"Trustworthiness of generative language models (GLMs) is crucial in their deployment to critical decision making systems. Hence, certified risk control methods such as selective prediction and conformal prediction have been applied to mitigating the hallucination problem in various supervised downstream tasks. However, the lack of appropriate correctness metric hinders applying such principled methods to language generation tasks. In this paper, we circumvent this problem by leveraging the concept of textual entailment to evaluate the correctness of the generated sequence, and propose two selective generation algorithms which control the false discovery rate with respect to the textual entailment relation (FDR-E) with a theoretical guarantee: $\texttt{SGen}^{\texttt{Sup}}$ and $\texttt{SGen}^{\texttt{Semi}}$. $\texttt{SGen}^{\texttt{Sup}}$, a direct modification of the selective prediction, is a supervised learning algorithm which exploits entailment-labeled data, annotated by humans. Since human annotation is costly, we further propose a semi-supervised version, $\texttt{SGen}^{\texttt{Semi}}$, which fully utilizes the unlabeled data by pseudo-labeling, leveraging an entailment set function learned via conformal prediction. Furthermore, $\texttt{SGen}^{\texttt{Semi}}$ enables to use more general class of selection functions, neuro-selection functions, and provides users with an optimal selection function class given multiple candidates. Finally, we demonstrate the efficacy of the $\texttt{SGen}$ family in achieving a desired FDR-E level with comparable selection efficiency to those from baselines on both open and closed source GLMs. Code and datasets are provided at https://github.com/ml-postech/selective-generation.",Minjae Lee; Kyungmin Kim; Taesoo Kim; Sangdon Park,~Minjae_Lee5; ~Kyungmin_Kim3; ~Taesoo_Kim1; ~Sangdon_Park1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/4d507f1ece2d76cf04cc44d48e998506039f31f2.pdf,2024-05-15T16:52:57.527000,2024-09-25T18:16:53.935000,2025-01-15T13:07:51.046000,https://openreview.net/forum?id=glfYOAzh2f,Pohang University of Science and Technology; Pohang University of Science and Technology; Georgia Institute of Technology; Pohang University of Science and Technology
292,ZtTWKr51yH,ZtTWKr51yH,19442,Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data,"State-of-the-art deep learning models for tabular data have recently achieved acceptable performance to be deployed in industrial settings. However, the robustness of these models remains scarcely explored. Contrary to computer vision, there are no effective attacks to properly evaluate the adversarial robustness of deep tabular models due to intrinsic properties of tabular data, such as categorical features, immutability, and feature relationship constraints. To fill this gap, we first propose CAPGD, a gradient attack that overcomes the failures of existing gradient attacks with adaptive mechanisms. This new attack does not require parameter tuning and further degrades the accuracy, up to 81\% points compared to the previous gradient attacks. Second, we design CAA, an efficient evasion attack that combines our CAPGD attack and MOEVA, the best search-based attack.  We demonstrate the effectiveness of our attacks on five architectures and four critical use cases. Our empirical study demonstrates that CAA outperforms all existing attacks in 17 over the 20 settings, and leads to a drop in the accuracy by up to 96.1\% points and 21.9\% points compared to CAPGD and MOEVA respectively while being up to five times faster than MOEVA. Given the effectiveness and efficiency of our new attacks, we argue that they should become the minimal test for any new defense or robust architectures in tabular machine learning.",Thibault Simonetto; Salah GHAMIZI; Maxime Cordy,~Thibault_Simonetto1; ~Salah_GHAMIZI1; ~Maxime_Cordy1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/151ebd76908a045bd9c3ca528bba5126fdf5056f.pdf,2024-05-15T16:36:11.114000,2024-09-25T18:16:49.829000,2025-01-15T19:25:04.012000,https://openreview.net/forum?id=ZtTWKr51yH,Luxembourg Institute of Science and Technology; University of Luxembourg
299,Vxijl0IOId,Vxijl0IOId,19387,Learning Generalized Linear Programming Value Functions,"We develop a theoretically-grounded learning method for the Generalized Linear Programming Value Function (GVF), which models the optimal value of a linear programming (LP) problem as its objective and constraint bounds vary. This function plays a fundamental role in algorithmic techniques for large-scale optimization, particularly in decomposition for two-stage mixed-integer linear programs (MILPs). This paper establishes a structural characterization of the GVF that enables it to be modeled as a particular neural network architecture, which we then use to learn the GVF in a way that benefits from three notable properties. First, our method produces a true under-approximation of the value function with respect to the constraint bounds. Second, the model is input-convex in the constraint bounds, which not only matches the structure of the GVF but also enables the trained model to be efficiently optimized over using LP. Finally, our learning method is unsupervised, meaning that training data generation does not require computing LP optimal values, which can be prohibitively expensive at large scales.  We numerically show that our method can approximate the GVF well, even when compared to supervised methods that collect training data by solving an LP for each data point. Furthermore, as an application of our framework, we develop a fast heuristic method for large-scale two-stage MILPs with continuous second-stage variables, via a compact reformulation that can be solved faster than the full model linear relaxation at large scales and orders of magnitude faster than the original model.",Tu Anh-Nguyen; Joey Huchette; Christian Tjandraatmadja,~Tu_Anh-Nguyen1; ~Joey_Huchette1; ~Christian_Tjandraatmadja1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/7ef012b4970fced95be8425bc6e03ba6f3a1cc9b.pdf,2024-05-15T16:30:37.182000,2024-09-25T18:16:48.680000,2025-01-15T01:14:49.852000,https://openreview.net/forum?id=Vxijl0IOId,Rice University
317,hVmi98a0ki,hVmi98a0ki,19244,Optimizing Automatic Differentiation with Deep Reinforcement Learning,"Computing Jacobians with automatic differentiation is ubiquitous in many scientific domains such as machine learning, computational fluid dynamics, robotics and finance. 
Even small savings in the number of computations or memory usage in Jacobian computations can already incur massive savings in energy consumption and runtime. 
While there exist many methods that allow for such savings, they generally trade computational efficiency for approximations of the exact Jacobian.

In this paper, we present a novel method to optimize the number of necessary multiplications for Jacobian computation by leveraging deep reinforcement learning (RL) and a concept called cross-country elimination while still computing the exact Jacobian. 
Cross-country elimination is a framework for automatic differentiation that phrases Jacobian accumulation as ordered elimination of all vertices on the computational graph where every elimination incurs a certain computational cost.
Finding the optimal elimination order that minimizes the number of necessary multiplications can be seen as a single player game which in our case is played by an RL agent.
We demonstrate that this method achieves up to 33% improvements over state-of-the-art methods on several relevant tasks taken from relevant domains.
Furthermore, we show that these theoretical gains translate into actual runtime improvements by providing a cross-country elimination interpreter in JAX that can execute the obtained elimination orders.",Jamie Lohoff; Emre Neftci,~Jamie_Lohoff1; ~Emre_Neftci1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/5e8452cabdcbe57ca595b5b7a5bc46375ef01533.pdf,2024-05-15T16:19:21.651000,2024-09-25T18:16:45.192000,2024-11-06T06:19:54.652000,https://openreview.net/forum?id=hVmi98a0ki,Forschungszentrum Jülich; Forschungszentrum Jülich
321,2TktDpGqNM,2TktDpGqNM,19203,Overcoming Common Flaws in the Evaluation of Selective Classification Systems,"Selective Classification, wherein models can reject low-confidence predictions, promises reliable translation of machine-learning based classification systems to real-world scenarios such as clinical diagnostics. While current evaluation of these systems typically assumes fixed working points based on pre-defined rejection thresholds, methodological progress requires benchmarking the general performance of systems akin to the $\mathrm{AUROC}$ in standard classification. In this work, we define 5 requirements for multi-threshold metrics in selective classification regarding task alignment, interpretability, and flexibility, and show how current approaches fail to meet them. We propose the Area under the Generalized Risk Coverage curve ($\mathrm{AUGRC}$), which meets all requirements and can be directly interpreted as the average risk of undetected failures. We empirically demonstrate the relevance of $\mathrm{AUGRC}$ on a comprehensive benchmark spanning 6 data sets and 13 confidence scoring functions. We find that the proposed metric substantially changes metric rankings on 5 out of the 6 data sets.",Jeremias Traub; Till J. Bungert; Carsten T. Lüth; Michael Baumgartner; Klaus Maier-Hein; Lena Maier-hein; Paul F Jaeger,~Jeremias_Traub1; ~Till_J._Bungert1; ~Carsten_T._Lüth1; ~Michael_Baumgartner2; ~Klaus_Maier-Hein1; ~Lena_Maier-hein2; ~Paul_F_Jaeger1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,evaluation,/pdf/430d98e354241367dc7f1beee9d1a73de5be0353.pdf,2024-05-15T16:15:32.622000,2024-09-25T18:16:44.281000,2024-11-06T06:19:54.496000,https://openreview.net/forum?id=2TktDpGqNM,Deutsches Krebsforschungszentrum; Deutsches Krebsforschungszentrum; Heidelberg University; Deutsches Krebsforschungszentrum; Deutsches Krebsforschungszentrum; Deutsches Krebsforschungszentrum; Deutsches Krebsforschungszentrum; Deutsches Krebsforschungszentrum; Google
337,Ehsd856Ltb,Ehsd856Ltb,19111,Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning,"Obtaining effective representations of DNA sequences is crucial for genome analysis. Metagenomic binning, for instance, relies on genome representations to cluster complex mixtures of DNA fragments from biological samples with the aim of determining their microbial compositions. In this paper, we revisit k-mer-based representations of genomes and provide a theoretical analysis of their use in representation learning. Based on the analysis, we propose a lightweight and scalable model for performing metagenomic binning at the genome read level, relying only on the k-mer compositions of the DNA fragments. We compare the model to recent genome foundation models and demonstrate that while the models are comparable in performance, the proposed model is significantly more effective in terms of scalability, a crucial aspect for performing metagenomic binning of real-world data sets.",Abdulkadir Celikkanat; Andres R Masegosa; Thomas Dyhre Nielsen,~Abdulkadir_Celikkanat2; ~Andres_R_Masegosa1; ~Thomas_Dyhre_Nielsen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/13552900aae60abd834cf99abce0caf2f04633fb.pdf,2024-05-15T16:07:37.770000,2024-09-25T18:16:42.221000,2024-11-06T06:19:53.894000,https://openreview.net/forum?id=Ehsd856Ltb,Aalborg University; Aalborg University; Aalborg University
341,REIK4SZMJt,REIK4SZMJt,19094,Trading Place for Space: Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes,"Many animals learn cognitive maps of their environment - a simultaneous representation of context, experience, and position.  Place cells in the hippocampus, named for their explicit encoding of position, are believed to be a neural substrate of these maps, with place cell ""remapping"" explaining how this system can represent different contexts. Briefly, place cells alter their firing properties, or ""remap"", in response to changes in experiential or sensory cues. Substantial sensory changes, produced, e.g., by moving between environments, cause large subpopulations of place cells to change their tuning entirely. While many studies have looked at the physiological basis of remapping, we lack explicit calculations of how the contextual capacity of the place cell system changes as a function of place field firing properties. Here, we propose a geometric approach to understanding population level activity of place cells.  Using known firing field statistics, we investigate how changes to place cell firing properties affect the distances between representations of different environments within firing rate space.  Using this approach, we find that the number of contexts storable by the hippocampus grows exponentially with the number of place cells, and calculate this exponent for environments of different sizes. We identify a fundamental trade-off between high resolution encoding of position and the number of storable contexts. This trade-off is tuned by place cell width, which might explain the change in firing field scale along the dorsal-ventral axis of the hippocampus. We demonstrate that clustering of place cells near likely points of confusion, such as boundaries, increases the contextual capacity of the place system within our framework and conclude by discussing how our geometric approach could be extended to include other cell types and abstract spaces.",Spencer Rooke; Zhaoze Wang; Ronald W Di Tullio; Vijay Balasubramanian,~Spencer_Rooke1; ~Zhaoze_Wang2; ~Ronald_W_Di_Tullio1; ~Vijay_Balasubramanian2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/3b84d66d0ad7e68594730c3e952459bcaa55fb37.pdf,2024-05-15T16:05:57.260000,2024-09-25T18:16:41.803000,2025-01-11T02:08:29.788000,https://openreview.net/forum?id=REIK4SZMJt,University of Pennsylvania; University of Pennsylvania; University of Pennsylvania
344,gojL67CfS8,gojL67CfS8,19076,Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction,"We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine ""next-scale prediction"" or ""next-resolution prediction"", diverging from the standard raster-scan ""next-token prediction"". This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and generalize well: VAR, for the first time, makes GPT-style AR models surpass diffusion transformers in image generation. On ImageNet 256x256 benchmark, VAR significantly improve AR baseline by improving Frechet inception distance (FID) from 18.65 to 1.73, inception score (IS) from 80.4 to 350.2, with around 20x faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling laws similar to those observed in LLMs, with linear correlation coefficients near -0.998 as solid evidence. VAR further showcases zero-shot generalization ability in downstream tasks including image in-painting, out-painting, and editing. These results suggest VAR has initially emulated the two important properties of LLMs: Scaling Laws and zero-shot task generalization. We have released all models and codes to promote the exploration of AR/VAR models for visual generation and unified learning.",Keyu Tian; Yi Jiang; Zehuan Yuan; BINGYUE PENG; Liwei Wang,~Keyu_Tian1; ~Yi_Jiang2; ~Zehuan_Yuan1; ~BINGYUE_PENG1; ~Liwei_Wang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,generative_models,/pdf/28293540753deed132a951a787dbc32da1d76e4c.pdf,2024-05-15T16:04:03.155000,2024-09-25T18:16:41.162000,2025-01-16T07:02:47.960000,https://openreview.net/forum?id=gojL67CfS8,Peking University; ByteDance Inc.; ByteDance Inc.; ByteDance Inc.; Peking University
357,VXxj3XZ1X8,VXxj3XZ1X8,19015,Reproducibility of predictive networks for mouse visual cortex,"Deep predictive models of neuronal activity have recently enabled several new discoveries about the selectivity and invariance of neurons in the visual cortex.
These models learn a shared set of nonlinear basis functions, which are linearly combined via a learned weight vector to represent a neuron's function.
Such weight vectors, which can be thought as embeddings of neuronal function, have been proposed to define functional cell types via unsupervised clustering.
However, as deep models are usually highly overparameterized, the learning problem is unlikely to have a unique solution, which raises the question if such embeddings can be used in a meaningful way for downstream analysis.
In this paper, we investigate how stable neuronal embeddings are with respect to changes in model architecture and initialization. 
We find that $L_1$ regularization to be an important ingredient for structured embeddings and develop an adaptive regularization that adjusts the strength of regularization per neuron.  
This regularization improves both predictive performance and how consistently neuronal embeddings cluster across model fits  compared to uniform regularization.
To overcome overparametrization, we propose an iterative feature pruning strategy which reduces the dimensionality of performance-optimized models by half without loss of performance and improves the consistency of neuronal embeddings with respect to clustering neurons.
Our results suggest that to achieve an objective taxonomy of cell types or a compact representation of the functional landscape, we need novel architectures or learning techniques that improve identifiability. 
The code is available https://github.com/pollytur/readout_reproducibility.",Polina Turishcheva; Max F Burg; Fabian H. Sinz; Alexander S Ecker,~Polina_Turishcheva1; ~Max_F_Burg1; ~Fabian_H._Sinz1; ~Alexander_S_Ecker1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/e37322f120845748e036c62e87d167cfecaa2df5.pdf,2024-05-15T15:58:42.936000,2024-09-25T18:16:39.504000,2024-11-06T06:19:53.159000,https://openreview.net/forum?id=VXxj3XZ1X8,Georg-August-Universität Göttingen; University of Tübingen; Georg-August-Universität Göttingen; Baylor College of Medicine; Georg-August-Universität Göttingen; Max Planck Institute for Software Systems
365,nw9JmfL99s,nw9JmfL99s,18952,Nonlinear dynamics of localization in neural receptive fields,"Localized receptive fields—neurons that are selective for certain contiguous spatiotemporal features of their input—populate early sensory regions of the mammalian brain. Unsupervised learning algorithms that optimize explicit sparsity or independence criteria replicate features of these localized receptive fields, but fail to explain directly how localization arises through learning without efficient coding, as occurs in early layers of deep neural networks and might occur in early sensory regions of biological systems. We consider an alternative model in which localized receptive fields emerge without explicit top-down efficiency constraints—a feed-forward neural network trained on a data model inspired by the structure of natural images. Previous work identified the importance of non-Gaussian statistics to localization in this setting but left open questions about the mechanisms driving dynamical emergence. We address these questions by deriving the effective learning dynamics for a single nonlinear neuron, making precise how higher-order statistical properties of the input data drive emergent localization, and we demonstrate that the predictions of these effective dynamics extend to the many-neuron setting. Our analysis provides an alternative explanation for the ubiquity of localization as resulting from the nonlinear dynamics of learning in neural circuits",Leon Lufkin; Andrew M Saxe; Erin Grant,~Leon_Lufkin1; ~Andrew_M_Saxe1; ~Erin_Grant1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/639227bcf1a258fd70ce091042536afc3780a946.pdf,2024-05-15T15:52:18.241000,2024-09-25T18:16:38.046000,2024-11-06T06:19:52.850000,https://openreview.net/forum?id=nw9JmfL99s,Yale University; University College London; University College London
398,ENlubvb262,ENlubvb262,18764,Learning Noisy Halfspaces with a Margin: Massart is No Harder than Random,"We study the problem of PAC learning $\gamma$-margin halfspaces with Massart noise. We propose a simple  proper learning algorithm, the Perspectron, that has sample complexity $\widetilde{O}((\epsilon\gamma)^{-2})$ and achieves classification error at most $\eta+\epsilon$ where $\eta$ is the Massart noise rate. 
 Prior works (DGT19, CKMY20)  came with worse sample complexity
 guarantees (in both $\epsilon$ and $\gamma$) or could only
 handle random classification noise (DDKWZ23,KITBMV23)--- a much milder noise assumption. 
We also show that our results extend to the more challenging setting of learning generalized linear models with a known link function under Massart noise, achieving a similar sample complexity to the halfspace case. This significantly improves upon the prior state-of-the-art in this setting due to CKMY20, who introduced this model.",Gautam Chandrasekaran; Vasilis Kontonis; Konstantinos Stavropoulos; Kevin Tian,~Gautam_Chandrasekaran1; ~Vasilis_Kontonis1; ~Konstantinos_Stavropoulos1; ~Kevin_Tian4,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/93481be590bc855b9a240f930181773c4ec3111a.pdf,2024-05-15T15:34:28.379000,2024-09-25T18:16:32.735000,2024-11-06T06:19:51.657000,https://openreview.net/forum?id=ENlubvb262,The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin
400,bCMpdaQCNW,bCMpdaQCNW,18748,Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions,"Recent advancements in large vision language models have demonstrated remarkable proficiency across a wide range of tasks. 
Yet, these models still struggle with understanding the nuances of human humor through juxtaposition, particularly when it involves nonlinear narratives that underpin many jokes and humor cues.  This paper investigates this challenge by focusing on comics with contradictory narratives, where each comic consists of two panels that create a humorous contradiction. We introduce the YesBut benchmark, which comprises tasks of varying difficulty aimed at assessing AI's capabilities in recognizing and interpreting these comics, ranging from literal content comprehension to deep narrative reasoning. Through extensive experimentation and analysis of recent commercial or open-sourced large vision language models, we assess their capability to comprehend the complex interplay of the narrative humor inherent in these comics. Our results show that even the state-of-the-art models still struggle with this task. Our findings offer insights into the current limitations and potential improvements for AI in understanding human creative expressions.",Zhe Hu; Tuo Liang; Jing Li; Yiren Lu; Yunlai Zhou; Yiran Qiao; Jing Ma; Yu Yin,~Zhe_Hu4; ~Tuo_Liang2; ~Jing_Li18; ~Yiren_Lu2; ~Yunlai_Zhou1; ~Yiran_Qiao2; ~Jing_Ma2; ~Yu_Yin2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/1f618d0020c8650176d91ef4418ef3cea6151adb.pdf,2024-05-15T15:33:01.563000,2024-09-25T18:16:32.191000,2024-11-06T06:19:51.595000,https://openreview.net/forum?id=bCMpdaQCNW,Hong Kong Polytechnic University; Case Western Reserve University; Hong Kong Polytechnic University; Case Western Reserve University; Case Western Reserve University; Case Western Reserve University; Case Western Reserve University; Case Western Reserve University
405,aVK4JFpegy,aVK4JFpegy,18682,Evaluating the World Model Implicit in a Generative Model,"Recent work suggests that large language models may implicitly learn world models. How should we assess this possibility? We formalize this question for the case where the underlying reality is governed by a deterministic finite automaton. This includes problems as diverse as simple logical reasoning, geographic navigation, game-playing, and chemistry. We propose new evaluation metrics for world model recovery inspired by the classic Myhill-Nerode theorem from language theory. We illustrate their utility in three domains: game playing, logic puzzles, and navigation. In all domains, the generative models we consider do well on existing diagnostics for assessing world models, but our evaluation metrics reveal their world models to be far less coherent than they appear. Such incoherence creates fragility: using a generative model to solve related but subtly different tasks can lead to failures. Building generative models that meaningfully capture the underlying logic of the domains they model would be immensely valuable; our results suggest new ways to assess how close a given model is to that goal.",Keyon Vafa; Justin Y. Chen; Ashesh Rambachan; Jon Kleinberg; Sendhil Mullainathan,~Keyon_Vafa1; ~Justin_Y._Chen1; ~Ashesh_Rambachan1; ~Jon_Kleinberg3; ~Sendhil_Mullainathan2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,evaluation,/pdf/eba080455ba462cb32784bbc6001046330923824.pdf,2024-05-15T15:27:08.757000,2024-09-25T18:16:30.493000,2024-12-18T22:59:56.876000,https://openreview.net/forum?id=aVK4JFpegy,Harvard University; Massachusetts Institute of Technology; Massachusetts Institute of Technology; University of Chicago
417,eKHQbgvL3G,eKHQbgvL3G,18541,TrackIME: Enhanced Video Point Tracking via Instance Motion Estimation,"Tracking points in video frames is essential for understanding video content. However, the task is fundamentally hindered by the computation demands for brute-force correspondence matching across the frames. As the current models down-sample the frame resolutions to mitigate this challenge, they fall short in accurately representing point trajectories due to information truncation. Instead, we address the challenge by pruning the search space for point tracking and let the model process only the important regions of the frames without down-sampling. Our first key idea is to identify the object instance and its trajectory over the frames, then prune the regions of the frame that do not contain the instance. Concretely, to estimate the instance’s trajectory, we track a group of points on the instance and aggregate their motion trajectories. Furthermore, to deal with the occlusions in complex scenes, we propose to compensate for the occluded points while tracking. To this end, we introduce a unified framework that jointly performs point tracking and segmentation, providing synergistic effects between the two tasks. For example, the segmentation results enable a tracking model to avoid the occluded points referring to the instance mask, and conversely, the improved tracking results can help to produce more accurate segmentation masks. Our framework can be easily incorporated with various tracking models, and we demonstrate its efficacy for enhanced point tracking throughout extensive experiments. For example, on the recent TAP-Vid benchmark, our framework consistently improves all baselines, e.g., up to 13.5% improvement on the average Jaccard metric.",Seong Hyeon Park; Huiwon Jang; Byungwoo Jeon; Sukmin Yun; Paul Hongsuck Seo; Jinwoo Shin,~Seong_Hyeon_Park2; ~Huiwon_Jang1; ~Byungwoo_Jeon1; ~Sukmin_Yun1; ~Paul_Hongsuck_Seo1; ~Jinwoo_Shin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/a1d1099a9b6d3563c77c9a4445e17803dde50b7d.pdf,2024-05-15T15:13:39.861000,2024-09-25T18:16:26.966000,2024-11-06T06:19:50.874000,https://openreview.net/forum?id=eKHQbgvL3G,Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Korea University; Korea Advanced Institute of Science and Technology; Hanyang University; Mohamed bin Zayed University of Artificial Intelligence; Korea University; Korea Advanced Institute of Science and Technology
422,A969ouPqEs,A969ouPqEs,18530,DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data,"The application of reinforcement learning in traffic signal control (TSC) has been extensively researched and yielded notable achievements. However, most existing works for TSC assume that traffic data from all surrounding intersections is fully and continuously available through sensors. In real-world applications, this assumption often fails due to sensor malfunctions or data loss, making TSC with missing data a critical challenge. To meet the needs of practical applications, we introduce DiffLight, a novel conditional diffusion model for TSC under data-missing scenarios in the offline setting. Specifically, we integrate two essential sub-tasks, i.e., traffic data imputation and decision-making, by leveraging a Partial Rewards Conditioned Diffusion (PRCD) model to prevent missing rewards from interfering with the learning process. Meanwhile, to effectively capture the spatial-temporal dependencies among intersections, we design a Spatial-Temporal transFormer (STFormer) architecture. In addition, we propose a Diffusion Communication Mechanism (DCM) to promote better communication and control performance under data-missing scenarios. Extensive experiments on five datasets with various data-missing scenarios demonstrate that DiffLight is an effective controller to address TSC with missing data. The code of DiffLight is released at https://github.com/lokol5579/DiffLight-release.",Hanyang Chen; Yang Jiang; Shengnan Guo; Xiaowei Mao; Youfang Lin; Huaiyu Wan,~Hanyang_Chen1; ~Yang_Jiang2; ~Shengnan_Guo1; ~Xiaowei_Mao1; ~Youfang_Lin1; ~Huaiyu_Wan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/af4dd840094f3effb374aea9f6c86be4a8164f02.pdf,2024-05-15T15:12:48.496000,2024-09-25T18:16:26.708000,2024-11-06T06:19:50.655000,https://openreview.net/forum?id=A969ouPqEs,Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University
440,Oo7HY9kmK6,Oo7HY9kmK6,18467,Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach,"Mean-field Langevin dynamics (MLFD) is a class of interacting particle methods that tackle convex optimization over probability measures on a manifold, which are scalable, versatile, and enjoy computational guarantees. However, some important problems -- such as risk minimization for infinite width two-layer neural networks, or sparse deconvolution -- are originally defined over the set of signed, rather than probability, measures. In this paper, we investigate how to extend the MFLD framework to convex optimization problems over signed measures.
Among two known reductions from signed to probability measures -- the lifting and the bilevel approaches -- we show that the bilevel reduction leads to stronger guarantees and faster rates (at the price of a higher per-iteration complexity).
In particular, we investigate the convergence rate of MFLD applied to the bilevel reduction in the low-noise regime and obtain two results. First, this dynamics is amenable to an annealing schedule, adapted from [Suzuki et al., 2023], that results in polynomial convergence rates to a fixed multiplicative accuracy. Second, we investigate the problem of learning a single neuron with the bilevel approach and obtain local exponential convergence rates that depend polynomially on the dimension and noise level (to compare with the exponential dependence that would result from prior analyses).",Guillaume Wang; Alireza Mousavi-Hosseini; Lénaïc Chizat,~Guillaume_Wang1; ~Alireza_Mousavi-Hosseini1; ~Lénaïc_Chizat1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/af21a5d2b1c2cdf6ca4d807e62f8beaf42c1bcbc.pdf,2024-05-15T15:08:02.574000,2024-09-25T18:16:24.621000,2024-11-06T06:19:49.985000,https://openreview.net/forum?id=Oo7HY9kmK6,EPFL - EPF Lausanne
446,WukSyFSzDt,WukSyFSzDt,18429,Stabilized Proximal-Point Methods for Federated Optimization,"In developing efficient optimization algorithms, it is crucial to account for communication constraints&mdash;a significant challenge in modern Federated Learning. 
    The best-known communication complexity among non-accelerated algorithms is achieved by DANE, a distributed proximal-point algorithm that solves local subproblems at each iteration and that can exploit second-order similarity among individual functions.
    However, to achieve such communication efficiency, the algorithm
    requires solving local subproblems sufficiently accurately resulting in slightly sub-optimal local complexity.
    Inspired by the hybrid-projection proximal-point method, in this work, we propose a novel distributed algorithm S-DANE. Compared to DANE, this method uses an auxiliary sequence of prox-centers while maintaining the same deterministic communication complexity. Moreover, the accuracy condition for solving the subproblem is milder, leading to enhanced local computation efficiency. Furthermore, S-DANE supports partial client participation and arbitrary stochastic local solvers, making it attractive in practice. We further accelerate S-DANE and show that the resulting algorithm achieves the best-known communication complexity among all existing methods for distributed convex optimization while still enjoying good local computation efficiency as S-DANE.
    Finally, we propose adaptive variants of both methods using line search, obtaining the first provably efficient adaptive algorithms that could exploit local second-order similarity without the prior knowledge of any parameters.",Xiaowen Jiang; Anton Rodomanov; Sebastian U Stich,~Xiaowen_Jiang1; ~Anton_Rodomanov1; ~Sebastian_U_Stich1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/839b99d9710e24ed126a5710e53c26313662fa1f.pdf,2024-05-15T15:04:01.192000,2024-09-25T18:16:23.511000,2024-12-18T19:16:06.364000,https://openreview.net/forum?id=WukSyFSzDt,Helmholtz Center CISPA for Information Security; Helmholtz Center CISPA for Information Security
450,fu0xdh4aEJ,fu0xdh4aEJ,18420,"Bigger, Regularized, Optimistic: scaling for compute and sample efficient continuous control","Sample efficiency in Reinforcement Learning (RL) has traditionally been driven by algorithmic enhancements. In this work, we demonstrate that scaling can also lead to substantial improvements.  We conduct a thorough investigation into the interplay of scaling model capacity and domain-specific RL enhancements. These empirical findings inform the design choices underlying our proposed BRO (Bigger, Regularized, Optimistic) algorithm. The key innovation behind BRO is that strong regularization allows for effective scaling of the critic networks, which, paired with optimistic exploration, leads to superior performance. BRO achieves state-of-the-art results, significantly outperforming the leading model-based and model-free algorithms across 40 complex tasks from the DeepMind Control, MetaWorld, and MyoSuite benchmarks. BRO is the first model-free algorithm to achieve near-optimal policies in the notoriously challenging Dog and Humanoid tasks.",Michal Nauman; Mateusz Ostaszewski; Krzysztof Jankowski; Piotr Miłoś; Marek Cygan,~Michal_Nauman1; ~Mateusz_Ostaszewski1; ~Krzysztof_Jankowski1; ~Piotr_Miłoś1; ~Marek_Cygan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/8d9002f8c6ce752bead54805f9bae68a41b6f7ad.pdf,2024-05-15T15:03:09.604000,2024-09-25T18:16:23.208000,2025-01-06T02:20:52.719000,https://openreview.net/forum?id=fu0xdh4aEJ,University of Warsaw; Warsaw University of Technology; University of Warsaw; Polish Academy of Sciences; IDEAS NCBR; University of Warsaw; Nomagic; University of Warsaw
451,ihEHCbqZEx,ihEHCbqZEx,18418,Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts,"Multimodal learning has gained increasing importance across various fields, offering the ability to integrate data from diverse sources such as images, text, and personalized records, which are frequently observed in medical domains. However, in scenarios where some modalities are missing, many existing frameworks struggle to accommodate arbitrary modality combinations, often relying heavily on a single modality or complete data. This oversight of potential modality combinations limits their applicability in real-world situations. To address this challenge, we propose Flex-MoE (Flexible Mixture-of-Experts), a new framework designed to flexibly incorporate arbitrary modality combinations while maintaining robustness to missing data. The core idea of Flex-MoE is to first address missing modalities using a new missing modality bank that integrates observed modality combinations with the corresponding missing ones. This is followed by a uniquely designed Sparse MoE framework. Specifically, Flex-MoE first trains experts using samples with all modalities to inject generalized knowledge through the generalized router ($\mathcal{G}$-Router). The $\mathcal{S}$-Router then specializes in handling fewer modality combinations by assigning the top-1 gate to the expert corresponding to the observed modality combination. We evaluate Flex-MoE on the ADNI dataset, which encompasses four modalities in the Alzheimer's Disease domain, as well as on the MIMIC-IV dataset. The results demonstrate the effectiveness of Flex-MoE, highlighting its ability to model arbitrary modality combinations in diverse missing modality scenarios. Code is available at: \url{https://github.com/UNITES-Lab/flex-moe}.",Sukwon Yun; Inyoung Choi; Jie Peng; Yangfan Wu; Jingxuan Bao; Qiyiwen Zhang; Jiayi Xin; Qi Long; Tianlong Chen,~Sukwon_Yun1; ~Inyoung_Choi1; ~Jie_Peng4; ~Yangfan_Wu1; ~Jingxuan_Bao1; ~Qiyiwen_Zhang1; ~Jiayi_Xin1; ~Qi_Long1; ~Tianlong_Chen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_healthcare,/pdf/9024e0bde24ca01c1346e1016782a3db8130706f.pdf,2024-05-15T15:03:05.982000,2024-09-25T18:16:23.149000,2024-11-06T06:19:49.563000,https://openreview.net/forum?id=ihEHCbqZEx,University of North Carolina at Chapel Hill; University of Pennsylvania; University of Science and Technology of China; Hong Kong University of Science and Technology(Guangzhou); University of Science and Technology of China; University of Hong Kong; University of Pennsylvania; University of Pennsylvania; University of North Carolina at Chapel Hill; Harvard University; Massachusetts Institute of Technology
457,204YOrDHny,204YOrDHny,18366,Reparameterization invariance in approximate Bayesian inference,"Current approximate posteriors in Bayesian neural networks (BNNs) exhibit a crucial limitation: they fail to maintain invariance under reparameterization, i.e. BNNs assign different posterior densities to different parametrizations of identical functions. This creates a fundamental flaw in the application of Bayesian principles as it breaks the correspondence between uncertainty over the parameters with uncertainty over the parametrized function. In this paper, we investigate this issue in the context of the increasingly popular linearized Laplace approximation. Specifically, it has been observed that linearized predictives alleviate the common underfitting problems of the Laplace approximation. We develop a new geometric view of reparametrizations from which we explain the success of linearization. Moreover, we demonstrate that these reparameterization invariance properties can be extended to the original neural network predictive using a Riemannian diffusion process giving a straightforward algorithm for approximate posterior sampling, which empirically improves posterior fit.",Hrittik Roy; Marco Miani; Carl Henrik Ek; Philipp Hennig; Marvin Pförtner; Lukas Tatzel; Søren Hauberg,~Hrittik_Roy2; ~Marco_Miani1; ~Carl_Henrik_Ek1; ~Philipp_Hennig1; ~Marvin_Pförtner1; ~Lukas_Tatzel1; ~Søren_Hauberg1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/3551594ff0fb669105bd16f447f24593595399c5.pdf,2024-05-15T14:58:38.804000,2024-09-25T18:16:21.232000,2024-11-14T07:06:49.791000,https://openreview.net/forum?id=204YOrDHny,Technical University of Denmark; University of Tübingen; University of Tübingen; University of Tübingen; Technical University of Denmark
459,9sP4oejtjB,9sP4oejtjB,18355,Disentangling the Roles of Distinct Cell Classes with Cell-Type Dynamical Systems,"Latent dynamical systems have been widely used to characterize the dynamics of neural population activity in the brain. However, these models typically ignore the fact that the brain contains multiple cell types. This limits their ability to capture the functional roles of distinct cell classes, and to predict the effects of cell-specific perturbations on neural activity or behavior. To overcome these limitations, we introduce the `""cell-type dynamical systems"" (CTDS) model. This model extends latent linear dynamical systems to contain distinct latent variables for each cell class, with biologically inspired constraints on both dynamics and emissions. To illustrate our approach, we consider neural recordings with distinct excitatory (E) and inhibitory (I) populations. 

The CTDS model defines separate latents for both cell types, and constrains the dynamics so that E (I) latents have a strictly positive (negative) effects on other latents. We applied CTDS to recordings from rat frontal orienting fields (FOF) and anterior dorsal striatum (ADS) during an auditory decision-making task. The model achieved higher accuracy than a standard linear dynamical system (LDS), and revealed that the animal's choice can be decoded from both E and I latents and thus is not restricted to a single cell-class. We also performed in-silico optogenetic perturbation experiments in the FOF and ADS, and found that CTDS was able to replicate the experimentally observed effects of different perturbations on behavior, whereas a standard LDS model---which does not differentiate between cell types---did not. Crucially, our model allowed us to understand the effects of these perturbations by revealing the dynamics of different cell-specific latents. Finally, CTDS can also be used to identify cell types for neurons whose class labels are unknown in electrophysiological recordings. These results illustrate the power of the CTDS model to provide more accurate and more biologically interpretable descriptions of neural population dynamics and their relationship to behavior.",Aditi Jha; Diksha Gupta; Carlos D Brody; Jonathan W. Pillow,~Aditi_Jha1; ~Diksha_Gupta1; ~Carlos_D_Brody1; ~Jonathan_W._Pillow1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/1e119625f0fd8571721c354ed1d8701846445c1f.pdf,2024-05-15T14:57:53.172000,2024-09-25T18:16:20.411000,2024-11-06T06:19:49.307000,https://openreview.net/forum?id=9sP4oejtjB,Stanford University; University College London; Princeton University
462,4G2DN4Kjk1,4G2DN4Kjk1,18318,Linear Regression using Heterogeneous Data Batches,"In many learning applications, data are collected from multiple sources, each providing a \emph{batch} of samples that by itself is insufficient to learn its input-output relationship. A common approach assumes that the sources fall in one of several unknown subgroups, each with an unknown input distribution and input-output relationship. We consider one of this setup's most fundamental and important manifestations where the output is a noisy linear combination of the inputs, and there are $k$ subgroups, each with its own regression vector. Prior work [KSS$^+$20] showed that with abundant small-batches, the regression vectors can be learned with only few, $\tilde\Omega( k^{3/2})$, batches of medium-size with $\tilde\Omega(\sqrt k)$ samples each. However, the paper requires that the input distribution for all $k$ subgroups be isotropic Gaussian, and states that removing this assumption is an ``interesting and challenging problem"". We propose a novel gradient-based algorithm that improves on the existing results in several ways. It extends the applicability of the algorithm by: (1) allowing the subgroups' underlying input distributions to be different, unknown, and heavy-tailed; (2) recovering all subgroups followed by a significant proportion of batches even for infinite $k$; (3) removing the separation requirement between the regression vectors; (4) reducing the number of batches and allowing smaller batch sizes.",Ayush Jain; Rajat Sen; Weihao Kong; Abhimanyu Das; Alon Orlitsky,~Ayush_Jain4; ~Rajat_Sen1; ~Weihao_Kong1; ~Abhimanyu_Das2; ~Alon_Orlitsky1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/4e34b2fc83260145359788e951b2012a124b1880.pdf,2024-05-15T14:54:43.093000,2024-09-25T18:16:18.498000,2024-11-06T06:19:49.206000,https://openreview.net/forum?id=4G2DN4Kjk1,
472,4aEwZkWB5z,4aEwZkWB5z,18267,A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise,"We study the problem of PAC learning $\gamma$-margin halfspaces in the presence of Massart noise. 
Without computational considerations, the sample complexity of this learning problem is known to be 
$\widetilde{\Theta}(1/(\gamma^2 \epsilon))$. 
Prior computationally efficient algorithms for the problem incur sample complexity 
$\tilde{O}(1/(\gamma^4 \epsilon^3))$ and achieve 0-1 error of $\eta+\epsilon$, 
where $\eta<1/2$ is the upper bound on the noise rate.
Recent work gave evidence of an information-computation tradeoff, 
suggesting that a quadratic dependence on $1/\epsilon$ is required 
for computationally efficient algorithms. 
Our main result is a computationally efficient learner with sample complexity 
$\widetilde{\Theta}(1/(\gamma^2 \epsilon^2))$, nearly matching this lower bound. 
In addition, our algorithm is simple and practical, 
relying on online SGD on a carefully selected sequence of convex losses.",Ilias Diakonikolas; Nikos Zarifis,~Ilias_Diakonikolas1; ~Nikos_Zarifis1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/bfb489a2b7a3ead973df18f431d072353f759e26.pdf,2024-05-15T14:49:53.361000,2024-09-25T18:16:15.889000,2025-01-15T18:24:49.046000,https://openreview.net/forum?id=4aEwZkWB5z,University of Wisconsin - Madison; University of Wisconsin - Madison
486,ZX6CEo1Wtv,ZX6CEo1Wtv,18165,Latent Diffusion for Neural Spiking Data,"Modern datasets in neuroscience enable unprecedented inquiries into the relationship between complex behaviors and the activity of many simultaneously recorded neurons. While latent variable models can successfully extract low-dimensional embeddings from such recordings, using them to generate realistic spiking data, especially in a behavior-dependent manner, still poses a challenge. Here, we present Latent Diffusion for Neural Spiking data (LDNS), a diffusion-based generative model with a low-dimensional latent space: LDNS employs an autoencoder with structured state-space (S4) layers to project discrete high-dimensional spiking data into continuous time-aligned latents. On these inferred latents, we train expressive (conditional) diffusion models, enabling us to sample neural activity with realistic single-neuron and population spiking statistics. We validate LDNS on synthetic data, accurately recovering latent structure, firing rates, and spiking statistics. Next, we demonstrate its flexibility by generating variable-length data that mimics human cortical activity during attempted speech. We show how to equip LDNS with an expressive observation model that accounts for single-neuron dynamics not mediated by the latent state, further increasing the realism of generated samples. Finally, conditional LDNS trained on motor cortical activity during diverse reaching behaviors can generate realistic spiking data given reach direction or unseen reach trajectories. In summary, LDNS simultaneously enables inference of low-dimensional latents and realistic conditional generation of neural spiking datasets, opening up further possibilities for simulating experimentally testable hypotheses.",Jaivardhan Kapoor; Auguste Schulz; Julius Vetter; Felix C Pei; Richard Gao; Jakob H. Macke,~Jaivardhan_Kapoor1; ~Auguste_Schulz1; ~Julius_Vetter2; ~Felix_C_Pei1; ~Richard_Gao1; ~Jakob_H._Macke1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/e0637f09f9affab400ed1f1dc2b8c58116dff2f6.pdf,2024-05-15T14:40:34.155000,2024-09-25T18:16:13.128000,2024-11-06T06:19:48.336000,https://openreview.net/forum?id=ZX6CEo1Wtv,University of Tübingen; University of Tübingen; University of Tübingen; Carnegie Mellon University; University of Tübingen
487,cqfE9eYMdP,cqfE9eYMdP,18161,Neural Krylov Iteration for Accelerating Linear System Solving,"Solving large-scale sparse linear systems is essential in fields like mathematics, science, and engineering. Traditional numerical solvers, mainly based on the Krylov subspace iteration algorithm, suffer from the low-efficiency problem, which primarily arises from the less-than-ideal iteration. To tackle this problem, we propose a novel method, namely **Neur**al **K**rylov **It**era**t**ion (**NeurKItt**), for accelerating linear system solving.
Specifically, NeurKItt employs a neural operator to predict the invariant subspace of the linear system and then leverages the predicted subspace to accelerate linear system solving. To enhance the subspace prediction accuracy, we utilize QR decomposition for the neural operator outputs and introduce a novel projection loss function for training. NeurKItt benefits the solving by using the predicted subspace to guide the iteration process, significantly reducing the number of iterations.
We provide extensive experiments and comprehensive theoretical analyses to demonstrate the feasibility and efficiency of NeurKItt. In our main experiments, NeurKItt accelerates the solving of linear systems across various settings and datasets, achieving up to a 5.5× speedup in computation time and a 16.1× speedup in the number of iterations.",Jian Luo; Jie Wang; Hong Wang; huanshuo dong; Zijie Geng; Hanzhu Chen; Yufei Kuang,~Jian_Luo5; ~Jie_Wang1; ~Hong_Wang14; ~huanshuo_dong1; ~Zijie_Geng1; ~Hanzhu_Chen1; ~Yufei_Kuang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/fdd5680d6ab89e3dc1bc23e5e0623387bfd0a59a.pdf,2024-05-15T14:40:24.920000,2024-09-25T18:16:12.980000,2024-11-06T06:19:48.292000,https://openreview.net/forum?id=cqfE9eYMdP,University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China
507,wpGJ2AX6SZ,wpGJ2AX6SZ,18035,Human Expertise in Algorithmic Prediction,"We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach leverages human judgment to distinguish inputs which are *algorithmically indistinguishable*, or ""look the same"" to predictive algorithms.  We argue that this framing clarifies the problem of human-AI collaboration in prediction tasks, as experts often form judgments by drawing on information which is not encoded in an algorithm's training data. Algorithmic indistinguishability yields a natural test for assessing whether experts incorporate this kind of ""side information"", and further provides a simple but principled method for selectively incorporating human feedback into algorithmic predictions. We show that this method provably improves the performance of any feasible algorithmic predictor and precisely quantify this improvement.  We find empirically that although algorithms often outperform their human counterparts *on average*, human judgment can improve algorithmic predictions on *specific* instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly 30% of the patient population. Our approach provides a natural way of uncovering this heterogeneity and thus enabling effective human-AI collaboration.",Rohan Alur; Manish Raghavan; Devavrat Shah,~Rohan_Alur1; ~Manish_Raghavan1; ~Devavrat_Shah1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,human-AI_interaction,/pdf/4f5dc6075a84c5c600343c682e95020208b5f943.pdf,2024-05-15T14:29:10.124000,2024-09-25T18:16:08.012000,2024-11-06T06:19:47.534000,https://openreview.net/forum?id=wpGJ2AX6SZ,Massachusetts Institute of Technology
516,FFW6rPz48Z,FFW6rPz48Z,17983,Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting,"In this paper, we introduce a novel theoretical framework for multi-task regression, applying random matrix theory to provide precise performance estimations, under high-dimensional, non-Gaussian data distributions. We formulate a multi-task optimization problem as a regularization technique to enable single-task models to leverage multi-task learning information. We derive a closed-form solution for multi-task optimization in the context of linear models. Our analysis provides valuable insights by linking the multi-task learning performance to various model statistics such as raw data covariances, signal-generating hyperplanes, noise levels, as well as the size and number of datasets. We finally propose a consistent estimation of training and testing errors, thereby offering a robust foundation for hyperparameter optimization in multi-task regression scenarios. Experimental validations on both synthetic and real-world datasets in regression and multivariate time series forecasting demonstrate improvements on univariate models, incorporating our method into the training loss and thus leveraging multivariate information.",Romain Ilbert; Malik Tiomoko; Cosme Louart; Ambroise Odonnat; Vasilii Feofanov; Themis Palpanas; Ievgen Redko,~Romain_Ilbert1; ~Malik_Tiomoko1; ~Cosme_Louart1; ~Ambroise_Odonnat1; ~Vasilii_Feofanov1; ~Themis_Palpanas1; ~Ievgen_Redko2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/ff5c8afaf7b48ba26b5ac93b76f334af498c83a9.pdf,2024-05-15T14:23:03.492000,2024-09-25T18:16:06.826000,2024-11-06T06:19:47.172000,https://openreview.net/forum?id=FFW6rPz48Z,Huawei Technologies Research & Development (UK) Ltd; University Paris Descartes; Chinese University of Hong Kong; Huawei Technologies Research & Development (UK) Ltd; Université Rennes 1; Huawei Noah's Ark Lab; Universite Paris Cite; Huawei Technologies Research & Development (UK) Ltd
528,xojbzSYIVS,xojbzSYIVS,17900,LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation,"Sequential recommender systems (SRS) aim to predict users' subsequent choices based on their historical interactions and have found applications in diverse fields such as e-commerce and social media. However, in real-world systems, most users interact with only a handful of items, while the majority of items are seldom consumed. These two issues, known as the long-tail user and long-tail item challenges, often pose difficulties for existing SRS. These challenges can adversely affect user experience and seller benefits, making them crucial to address. Though a few works have addressed the challenges, they still struggle with the seesaw or noisy issues due to the intrinsic scarcity of interactions. The advancements in large language models (LLMs) present a promising solution to these problems from a semantic perspective. As one of the pioneers in this field, we propose the Large Language Models Enhancement framework for Sequential Recommendation (LLM-ESR). This framework utilizes semantic embeddings derived from LLMs to enhance SRS without adding extra inference load. To address the long-tail item challenge, we design a dual-view modeling framework that combines semantics from LLMs and collaborative signals from conventional SRS. For the long-tail user challenge, we propose a retrieval augmented self-distillation method to enhance user preference representation using more informative interactions from similar users. To verify the effectiveness and versatility of our proposed enhancement framework, we conduct extensive experiments on three real-world datasets using three popular SRS models. The results consistently show that our method surpasses existing baselines. The implementation code is available in Supplementary Material.",Qidong Liu; Xian Wu; Yejing Wang; Zijian Zhang; Feng Tian; Yefeng Zheng; Xiangyu Zhao,~Qidong_Liu2; ~Xian_Wu1; ~Yejing_Wang1; ~Zijian_Zhang5; ~Feng_Tian4; ~Yefeng_Zheng3; ~Xiangyu_Zhao1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/154f17c1f444becfea5d4859af7ffcf05d69ce31.pdf,2024-05-15T14:15:12.496000,2024-09-25T18:16:04.490000,2025-01-02T07:22:48.900000,https://openreview.net/forum?id=xojbzSYIVS,City University of Hong Kong; Xi'an Jiaotong University; Tencent; City University of Hong Kong; City University of Hong Kong; Jilin University; Xi'an Jiaotong University; Westlake University; Tencent; City University of Hong Kong
532,HW9S9vY5gZ,HW9S9vY5gZ,17866,No-regret Learning in Harmonic Games: Extrapolation in the Face of Conflicting Interests,"The long-run behavior of multi-agent online learning -- and, in particular, no-regret learning -- is relatively well-understood in potential games, where players have common interests. By contrast, in general harmonic games -- the strategic complement of potential games, where players have competing interests -- very little is known outside the narrow subclass of $2$-player zero-sum games with a fully-mixed equilibrium. Our paper seeks to partially fill this gap by focusing on the full class of (generalized) harmonic games and examining the convergence properties of ""follow-the-regularized-leader"" (FTRL), the most widely studied class of no-regret learning schemes. As a first result, we show that the continuous-time dynamics of FTRL are Poincaré recurrent, i.e., they return arbitrarily close to their starting point infinitely often, and hence fail to converge. In discrete time, the standard, ""vanilla"" implementation of FTRL may lead to even worse outcomes, eventually trapping the players in a perpetual cycle of best-responses. However, if FTRL is augmented with a suitable extrapolation step -- which includes as special cases the optimistic and mirror-prox variants of FTRL -- we show that learning converges to a Nash equilibrium from any initial condition, and all players are guaranteed at most $\mathcal{O}(1)$ regret. These results provide an in-depth understanding of no-regret learning in harmonic games, nesting prior work on $2$-player zero-sum games, and showing at a high level that potential and harmonic games are complementary not only from the strategic but also from the dynamic viewpoint.",Davide Legacci; Panayotis Mertikopoulos; Christos Papadimitriou; Georgios Piliouras; Bary Pradelski,~Davide_Legacci1; ~Panayotis_Mertikopoulos1; ~Christos_Papadimitriou2; ~Georgios_Piliouras1; ~Bary_Pradelski1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/a191dfcbd501f4251fa2a23b27ed7bf8b95257c0.pdf,2024-05-15T14:11:15.364000,2024-09-25T18:16:03.615000,2024-12-28T11:18:05.682000,https://openreview.net/forum?id=HW9S9vY5gZ,Université Grenoble Alpes; LAAS / CNRS; Google; Singapore University of Technology and Design
535,Ma0993KZlq,Ma0993KZlq,17813,Active Classification with Few Queries under Misspecification,"We study pool-based active learning, where a learner has a large pool $S$ of unlabeled examples and can adaptively ask a labeler questions to learn these labels. The goal of the learner is to output a labeling for $S$ that can compete with the best hypothesis from a given hypothesis class $\mathcal{H}$. We focus on halfspace learning, one of the most important problems in active learning.

It is well known that in the standard active learning model, learning the labels of an arbitrary pool of examples labeled by some halfspace up to error $\epsilon$ requires at least $\Omega(1/\epsilon)$ queries. To overcome this difficulty, previous work designs simple but powerful query languages to achieve $O(\log(1/\epsilon))$ query complexity, but only focuses on the realizable setting where data are perfectly labeled by some halfspace.
However, when labels are noisy, such queries are too fragile and lead to high query complexity even under the simple random classification noise model.
  
In this work, we propose a new query language called threshold statistical queries and study their power for learning under various noise models. Our main algorithmic result is the first query-efficient algorithm for learning halfspaces under the popular Massart noise model. With an arbitrary dataset corrupted with Massart noise at noise rate $\eta$, our algorithm uses only $\mathrm{polylog(1/\epsilon)}$ threshold statistical queries and computes an $(\eta + \epsilon)$-accurate labeling in polynomial time. For the harder case of agnostic noise, we show that it is impossible to beat $O(1/\epsilon)$ query complexity even for the much simpler problem of learning singleton functions (and thus for learning halfspaces) using a reduction from agnostic distributed learning.",Vasilis Kontonis; Mingchen Ma; Christos Tzamos,~Vasilis_Kontonis1; ~Mingchen_Ma1; ~Christos_Tzamos1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/0f1720fec758593c3efb788bd2dd1c6f081bcb1f.pdf,2024-05-15T14:07:11.210000,2024-09-25T18:16:02.570000,2025-01-14T13:39:12.710000,https://openreview.net/forum?id=Ma0993KZlq,University of Wisconsin - Madison; University of Wisconsin - Madison; National and Kapodistrian University of Athens
542,3uI4ceR4iz,3uI4ceR4iz,17768,SA3DIP: Segment Any 3D Instance with Potential 3D Priors,"The proliferation of 2D foundation models has sparked research into adapting them for open-world 3D instance segmentation. Recent methods introduce a paradigm that leverages superpoints as geometric primitives and incorporates 2D multi-view masks from Segment Anything model (SAM) as merging guidance, achieving outstanding zero-shot instance segmentation results. However, the limited use of 3D priors restricts the segmentation performance. Previous methods calculate the 3D superpoints solely based on estimated normal from spatial coordinates, resulting in under-segmentation for instances with similar geometry. Besides, the heavy reliance on SAM and hand-crafted algorithms in 2D space suffers from over-segmentation due to SAM's inherent part-level segmentation tendency. To address these issues, we propose SA3DIP, a novel method for Segmenting Any 3D Instances via exploiting potential 3D Priors. Specifically, on one hand, we generate complementary 3D primitives based on both geometric and textural priors, which reduces the initial errors that accumulate in subsequent procedures. On the other hand, we introduce supplemental constraints from the 3D space by using a 3D detector to guide a further merging process. Furthermore, we notice a considerable portion of low-quality ground truth annotations in ScanNetV2 benchmark, which affect the fair evaluations. Thus, we present ScanNetV2-INS with complete ground truth labels and supplement additional instances for 3D class-agnostic instance segmentation. Experimental evaluations on various 2D-3D datasets demonstrate the effectiveness and robustness of our approach. Our code and proposed ScanNetV2-INS dataset are available HERE.",Xi Yang; Xu Gu; Xingyilang Yin; Xinbo Gao,~Xi_Yang4; ~Xu_Gu2; ~Xingyilang_Yin1; ~Xinbo_Gao5,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/adef2de9b0dd37c0582dcff7b7a584a29b4b099a.pdf,2024-05-15T14:02:35.996000,2024-09-25T18:16:01.315000,2024-11-06T06:19:46.184000,https://openreview.net/forum?id=3uI4ceR4iz,Xidian University; Xidian University; Xidian University; Chongqing Post and Communications University
546,y10avdRFNK,y10avdRFNK,17735,Learning diffusion at lightspeed,"Diffusion regulates numerous natural processes and the dynamics of many successful generative models. Existing models to learn the diffusion terms from observational data rely on complex bilevel optimization problems and model only the drift of the system.
We propose a new simple model, JKOnet*, which bypasses the complexity of existing architectures while presenting significantly enhanced representational capabilities: JKOnet* recovers the potential, interaction, and internal energy components of the underlying diffusion process. JKOnet* minimizes a simple quadratic loss and outperforms other baselines in terms of sample efficiency, computational complexity, and accuracy. Additionally, JKOnet* provides a closed-form optimal solution for linearly parametrized functionals, and, when applied to predict the evolution of cellular processes from real-world data, it achieves state-of-the-art accuracy at a fraction of the computational cost of all existing methods.
Our methodology is based on the interpretation of diffusion processes as energy-minimizing trajectories in the probability space via the so-called JKO scheme, which we study via its first-order optimality conditions.",Antonio Terpin; Nicolas Lanzetti; Martín Gadea; Florian Dorfler,~Antonio_Terpin1; ~Nicolas_Lanzetti1; ~Martín_Gadea1; ~Florian_Dorfler1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,optimization,/pdf/71e85a95e3f40ebd277c5df65f9dff3c748e2ddb.pdf,2024-05-15T14:01:01.947000,2024-09-25T18:16:00.670000,2024-11-06T06:19:46.035000,https://openreview.net/forum?id=y10avdRFNK,ETH Zurich; ETH Zurich; ETH Zurich
555,ZYrZ5V84ZI,ZYrZ5V84ZI,17690,Voila-A: Aligning Vision-Language Models with User's Gaze Attention,"In recent years, the integration of vision and language understanding has led to significant advancements in artificial intelligence, particularly through Vision-Language Models (VLMs). However, existing VLMs face challenges in handling real-world applications with complex scenes and multiple objects, as well as aligning their focus with the diverse attention patterns of human users. In this paper, we introduce gaze information, feasibly collected by ubiquitous wearable devices such as MR glasses, as a proxy for human attention to guide VLMs. We propose a novel approach, Voila-A, for gaze alignment to enhance the effectiveness of these models in real-world applications. First, we collect hundreds of minutes of gaze data to demonstrate that we can mimic human gaze modalities using localized narratives. We then design an automatic data annotation pipeline utilizing GPT-4 to generate the VOILA-COCO dataset. Additionally, we introduce a new model VOILA-A that integrate gaze information into VLMs while maintain pretrained knowledge from webscale dataset. We evaluate Voila-A using a hold-out validation set and a newly collected VOILA-GAZE testset, which features real-life scenarios captured with a gaze-tracking device. Our experimental results demonstrate that Voila-A significantly outperforms several baseline models. By aligning model attention with human gaze patterns, Voila-A paves the way for more intuitive, user-centric VLMs and fosters engaging human-AI interaction across a wide range of applications.",Kun Yan; Zeyu Wang; Lei Ji; Yuntao Wang; Nan Duan; Shuai Ma,~Kun_Yan2; ~Zeyu_Wang12; ~Lei_Ji1; ~Yuntao_Wang1; ~Nan_Duan1; ~Shuai_Ma1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,human-AI_interaction,/pdf/8696e1c0f625799d940b22be14539bebad8a2bc8.pdf,2024-05-15T13:56:00.548000,2024-09-25T18:15:59.880000,2025-01-15T08:23:17.027000,https://openreview.net/forum?id=ZYrZ5V84ZI,"Beihang University; Microsoft; Tsinghua University, Beijing; Microsoft; Tsinghua University, Beijing; Stepfun; Microsoft"
557,OAjHFvrTbq,OAjHFvrTbq,17688,Barely Random Algorithms and Collective Metrical Task Systems,"We consider metrical task systems on general metric spaces with $n$ points, and show that any fully randomized algorithm can be turned into a randomized algorithm that uses only $2\log n$ random bits, and achieves the same competitive ratio up to a factor $2$. This provides the first order-optimal barely random algorithms for metrical task systems, i.e. which use a number of random bits that does not depend on the number of requests addressed to the system. We discuss implications on various aspects of online decision making such as: distributed systems, advice complexity and transaction costs, suggesting broad applicability. We put forward an equivalent view that we call collective metrical task systems where $k$ agents in a metrical task system team up, and suffer the average cost paid by each agent. Our results imply that such team can be $O(\log^2 n)$-competitive as soon as $k\geq n^2$. In comparison, a single agent is always $\Omega(n)$-competitive.",Romain Cosson; Laurent Massoulié,~Romain_Cosson1; ~Laurent_Massoulié1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,online_learning,/pdf/1740bfcd3898647c7b2eab1a04cfb582e207f485.pdf,2024-05-15T13:55:51.024000,2024-09-25T18:15:59.744000,2024-11-06T06:19:45.608000,https://openreview.net/forum?id=OAjHFvrTbq,"Inria, Paris"
565,Y0EfJJeb4V,Y0EfJJeb4V,17624,Goal Reduction with Loop-Removal Accelerates RL and Models Human Brain Activity in Goal-Directed Learning,"Goal-directed planning presents a challenge for classical RL algorithms due to the vastness of the combinatorial state and goal spaces, while humans and animals adapt to complex environments, especially with diverse, non-stationary objectives, often employing intermediate goals for long-horizon tasks.
Here, we propose a goal reduction mechanism for effectively deriving subgoals from arbitrary and distant original goals, using a novel loop-removal technique.
The product of the method, called goal-reducer, distills high-quality subgoals from a replay buffer, all without the need for prior global environmental knowledge.
Simulations show that the goal-reducer can be integrated into RL frameworks like Deep Q-learning and Soft Actor-Critic.
It accelerates performance in both discrete and continuous action space tasks, such as grid world navigation and robotic arm manipulation, relative to the corresponding standard RL models.
Moreover, the goal-reducer, when combined with a local policy, without iterative training, outperforms its integrated deep RL counterparts in solving a navigation task.
This goal reduction mechanism also models human problem-solving.
Comparing the model's performance and activation with human behavior and fMRI data in a treasure hunting task, we found matching representational patterns between an goal-reducer agent's components and corresponding human brain areas, particularly the vmPFC and basal ganglia. The results suggest that humans may use a similar computational framework for goal-directed behaviors.",Huzi Cheng; Joshua W Brown,~Huzi_Cheng1; ~Joshua_W_Brown1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/a9641cd247e6e7a43fd893f0d42fd17484c244b6.pdf,2024-05-15T13:48:02.965000,2024-09-25T18:15:58.165000,2024-11-06T06:19:45.294000,https://openreview.net/forum?id=Y0EfJJeb4V,Indiana University
576,ltnDg0EzF9,ltnDg0EzF9,17508,Latent Intrinsics Emerge from Training to Relight,"Image relighting is the task of showing what a scene from a source image would look like if illuminated differently.  Inverse graphic schemes recover an explicit representation of geometry and a set of chosen intrinsics, then relight with some form of renderer.  But error control for inverse graphics is difficult, and inverse graphics methods can represent only the effects of the chosen intrinsics. This paper describes a relighting method that is entirely data-driven, where intrinsics and lighting are each represented as latent variables.  Our approach produces SOTA relightings of real scenes, as measured by standard metrics.  We show that albedo can be recovered from our latent intrinsics without using any example albedos, and that the albedos recovered are competitive with SOTA methods.",Xiao Zhang; William Gao; Seemandhar Jain; Michael Maire; David Forsyth; Anand Bhattad,~Xiao_Zhang11; ~William_Gao1; ~Seemandhar_Jain1; ~Michael_Maire1; ~David_Forsyth1; ~Anand_Bhattad1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/29f443e642012f7d29c1f0d893b1100d764b548d.pdf,2024-05-15T13:33:13.430000,2024-09-25T18:15:55.345000,2024-11-06T06:19:44.903000,https://openreview.net/forum?id=ltnDg0EzF9,"University of Chicago; NVIDIA; Meta; University of Chicago; University of California, San Diego; Department of Computer Science, University of Illinois at Urbana Champaign; University of Chicago; Department of Computer Science, University of Illinois at Urbana Champaign; Toyota Technological Institute at Chicago; Department of Computer Science, University of Illinois at Urbana Champaign"
586,8iytZCnXIu,8iytZCnXIu,17440,BricksRL: A Platform for Democratizing Robotics and  Reinforcement Learning Research and Education with LEGO,"We present BricksRL, a platform designed to democratize access to robotics for reinforcement learning research and education. BricksRL facilitates the creation, design, and training of custom LEGO robots in the real world by interfacing them with the TorchRL library for reinforcement learning agents. The integration of TorchRL with the LEGO hubs, via Bluetooth bidirectional communication, enables state-of-the-art reinforcement learning training on GPUs for a wide variety of LEGO builds. This offers a flexible and cost-efficient approach for scaling and also provides a robust infrastructure for robot-environment-algorithm communication. We present various experiments across tasks and robot configurations, providing built plans and training results. Furthermore, we demonstrate that inexpensive LEGO robots can be trained end-to-end in the real world to achieve simple tasks, with training times typically under 120 minutes on a normal laptop. Moreover, we show how users can extend the capabilities, exemplified by the successful integration of non-LEGO sensors. By enhancing accessibility to both robotics and reinforcement learning, BricksRL establishes a strong foundation for democratized robotic learning in research and educational settings.",Sebastian Dittert; Vincent Moens; Gianni De Fabritiis,~Sebastian_Dittert1; ~Vincent_Moens3; ~Gianni_De_Fabritiis1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,robotics,/pdf/2da707af995bbe5a2fd1bf93469260c40d2c5dd5.pdf,2024-05-15T13:25:35.977000,2024-09-25T18:15:53.668000,2024-11-06T06:19:44.504000,https://openreview.net/forum?id=8iytZCnXIu,Meta; Acellera Therapeutics Inc; Universitat Pompeu Fabra
603,WpPNVPAEyv,WpPNVPAEyv,17318,Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts,"Traditional long-tailed learning methods often perform poorly when dealing with inconsistencies between training and test data distributions, and they cannot flexibly adapt to different user preferences for trade-offs between head and tail classes. To address this issue, we propose a novel long-tailed learning paradigm that aims to tackle distribution shift in real-world scenarios and accommodate different user preferences for the trade-off between head and tail classes. We generate a set of diverse expert models via hypernetworks to cover all possible distribution scenarios, and optimize the model ensemble to adapt to any test distribution. Crucially, in any distribution scenario, we can flexibly output a dedicated model solution that matches the user's preference. Extensive experiments demonstrate that our method not only achieves higher performance ceilings but also effectively overcomes distribution shift while allowing controllable adjustments according to user preferences. We provide new insights and a paradigm for the long-tailed learning problem, greatly expanding its applicability in practical scenarios. The code can be found here: https://github.com/DataLab-atom/PRL.",Zhe Zhao; HaiBin Wen; Zikang Wang; Pengkun Wang; Fanfu Wang; Song Lai; Qingfu Zhang; Yang Wang,~Zhe_Zhao5; ~HaiBin_Wen1; ~Zikang_Wang2; ~Pengkun_Wang1; ~Fanfu_Wang1; ~Song_Lai1; ~Qingfu_Zhang1; ~Yang_Wang32,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/01b154d188c25147a4bc22b558ec38402aba389e.pdf,2024-05-15T13:13:44.051000,2024-09-25T18:15:49.884000,2024-11-06T06:19:43.883000,https://openreview.net/forum?id=WpPNVPAEyv,University of Science and Technology of China; Shaoguan University; Hong Kong University of Science and Technology(Guangzhou); Harbin Institute of Technology; University of Science and Technology of China; Lanzhou University; City University of Hong Kong; City University of Hong Kong; University of Science and Technology of China
608,HTLJptF7qM,HTLJptF7qM,17281,Noisy Label Learning with Instance-Dependent Outliers: Identifiability via Crowd Wisdom,"The generation of label noise is often modeled as a process involving a probability transition matrix (also interpreted as the _annotator confusion matrix_) imposed onto the label distribution. Under this model, learning the ``ground-truth classifier''---i.e., the classifier that can be learned if no noise was present---and the confusion matrix boils down to a model identification problem. Prior works along this line demonstrated appealing empirical performance, yet identifiability of the model was mostly established by assuming an instance-invariant confusion matrix. Having an (occasionally) instance-dependent confusion matrix across data samples is apparently more realistic, but inevitably introduces outliers to the model. Our interest lies in confusion matrix-based noisy label learning with such outliers taken into consideration. We begin with pointing out that under the model of interest, using labels produced by only one annotator is fundamentally insufficient to detect the outliers or identify the ground-truth classifier. Then, we prove that by employing a crowdsourcing strategy involving multiple annotators, a carefully designed loss function can establish the desired model identifiability under reasonable conditions. Our development builds upon a link between the noisy label model and a column-corrupted matrix factorization mode---based on which we show that crowdsourced annotations distinguish nominal data and instance-dependent outliers using a low-dimensional subspace. Experiments show that our learning scheme substantially improves outlier detection and the classifier's testing accuracy.",Tri Nguyen; Shahana Ibrahim; Xiao Fu,~Tri_Nguyen2; ~Shahana_Ibrahim1; ~Xiao_Fu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/46d266c36e09ce5345faedf1fd11f1d459037850.pdf,2024-05-15T13:09:33.884000,2024-09-25T18:15:49.118000,2024-11-06T06:19:43.715000,https://openreview.net/forum?id=HTLJptF7qM,Oregon State University; University of Central Florida; Oregon State University
611,jM9atrvUii,jM9atrvUii,17246,Kermut: Composite kernel regression for protein variant effects,"Reliable prediction of protein variant effects is crucial for both protein optimization and for advancing biological understanding. For practical use in protein engineering, it is important that we can also provide reliable uncertainty estimates for our predictions, and while prediction accuracy has seen much progress in recent years, uncertainty metrics are rarely reported. We here provide a Gaussian process regression model, Kermut, with a novel composite kernel for modeling mutation similarity, which obtains state-of-the-art performance for supervised protein variant effect prediction while also offering estimates of uncertainty through its posterior. An analysis of the quality of the uncertainty estimates demonstrates that our model provides meaningful levels of overall calibration, but that instance-specific uncertainty calibration remains more challenging.",Peter Mørch Groth; Mads Herbert Kerrn; Lars Olsen; Jesper Salomon; Wouter Boomsma,~Peter_Mørch_Groth1; ~Mads_Herbert_Kerrn1; ~Lars_Olsen1; ~Jesper_Salomon1; ~Wouter_Boomsma1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/e7dbf11a43656d3ed6f4ed209a4eb7f6a3f056d6.pdf,2024-05-15T13:05:57.754000,2024-09-25T18:15:48.189000,2024-11-06T06:19:43.578000,https://openreview.net/forum?id=jM9atrvUii,University of Copenhagen; University of Copenhagen; University of Copenhagen
616,SOsiObSdU2,SOsiObSdU2,17161,Automatically Learning Hybrid Digital Twins of Dynamical Systems,"Digital Twins (DTs) are computational models that simulate the states and temporal dynamics of real-world systems, playing a crucial role in prediction, understanding, and decision-making across diverse domains. However, existing approaches to DTs often struggle to generalize to unseen conditions in data-scarce settings, a crucial requirement for such models. To address these limitations, our work begins by establishing the essential desiderata for effective DTs. Hybrid Digital Twins (**HDTwins**) represent a promising approach to address these requirements, modeling systems using a composition of both mechanistic and neural components. This hybrid architecture simultaneously leverages (partial) domain knowledge and neural network expressiveness to enhance generalization, with its modular design facilitating improved evolvability. While existing hybrid models rely on expert-specified architectures with only parameters optimized on data, *automatically* specifying and optimizing HDTwins remains intractable due to the complex search space and the need for flexible integration of domain priors. To overcome this complexity, we propose an evolutionary algorithm (**HDTwinGen**) that employs Large Language Models (LLMs) to autonomously propose, evaluate, and optimize HDTwins. Specifically, LLMs iteratively generate novel model specifications, while offline tools are employed to optimize emitted parameters. Correspondingly, proposed models are evaluated and evolved based on targeted feedback, enabling the discovery of increasingly effective hybrid models. Our empirical results reveal that HDTwinGen produces generalizable, sample-efficient, and evolvable models, significantly advancing DTs' efficacy in real-world applications.",Samuel Holt; Tennison Liu; Mihaela van der Schaar,~Samuel_Holt1; ~Tennison_Liu1; ~Mihaela_van_der_Schaar2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/35404004e633fb0e988ac69784f37da350d47c00.pdf,2024-05-15T12:54:26.675000,2024-09-25T18:15:46.170000,2024-11-06T06:19:43.394000,https://openreview.net/forum?id=SOsiObSdU2,Google; University of Cambridge
626,TUwWBLjFk9,TUwWBLjFk9,17086,On the Identifiability of Poisson Branching Structural Causal Model Using Probability Generating Function,"Causal discovery from observational data, especially for count data, is essential across scientific and industrial contexts, such as biology, economics, and network operation maintenance. For this task, most approaches model count data using Bayesian networks or ordinal relations. However, they overlook the inherent branching structures that are frequently encountered, e.g., a browsing event might trigger an adding cart or purchasing event. This can be modeled by a binomial thinning operator (for branching) and an additive independent Poisson distribution (for noising), known as Poisson Branching Structure Causal Model (PB-SCM). There is a provably sound cumulant-based causal discovery method that allows the identification of the causal structure under a branching structure. However, we show that there still remains a gap in that there exist causal directions that are identifiable while the algorithm fails to identify them. In this work, we address this gap by exploring the identifiability of PB-SCM using the Probability Generating Function (PGF). By developing a compact and exact closed-form solution for the PGF of PB-SCM, we demonstrate that each component in this closed-form solution uniquely encodes a specific local structure, enabling the identification of the local structures by testing their corresponding component appearances in the PGF. Building on this, we propose a practical algorithm for learning causal skeletons and identifying causal directions of PB-SCM using PGF. The effectiveness of our method is demonstrated through experiments on both synthetic and real datasets.",Yu Xiang; Jie Qiao; Zefeng Liang; Zihuai Zeng; Ruichu Cai; Zhifeng Hao,~Yu_Xiang9; ~Jie_Qiao1; ~Zefeng_Liang1; ~Zihuai_Zeng1; ~Ruichu_Cai1; ~Zhifeng_Hao4,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,causal_inference,/pdf/4d2cb1ec6dc22c5e9b9d2289e344d1bf27c1c875.pdf,2024-05-15T12:44:32.472000,2024-09-25T18:15:44.517000,2024-11-06T06:19:42.963000,https://openreview.net/forum?id=TUwWBLjFk9,Guangdong University of Technology; Guangdong University of Technology; Guangdong University of Technology; Guangdong University of Technology; Shantou University
644,9O2sVnEHor,9O2sVnEHor,16891,Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning,"We introduce $r$-loopy Weisfeiler-Leman ($r$-$\ell$WL), a novel hierarchy of graph isomorphism tests and a corresponding GNN framework, $r$-$\ell$MPNN, that can count cycles up to length $r{+}2$. Most notably, we show that $r$-$\ell$WL can count homomorphisms of cactus graphs. This extends 1-WL, which can only count homomorphisms of trees and, in fact, is incomparable to $k$-WL for any fixed $k$. We empirically validate the expressive and counting power of $r$-$\ell$MPNN on several synthetic datasets and demonstrate the scalability and strong performance on various real-world datasets, particularly on sparse graphs.",Raffaele Paolino; Sohir Maskey; Pascal Welke; Gitta Kutyniok,~Raffaele_Paolino1; ~Sohir_Maskey1; ~Pascal_Welke1; ~Gitta_Kutyniok2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/160b0368f27f6ae00575a4abc8d44870237c95f9.pdf,2024-05-15T12:14:25.158000,2024-09-25T18:15:40.316000,2024-11-06T06:19:42.261000,https://openreview.net/forum?id=9O2sVnEHor,Ludwig-Maximilians-Universität München; University of Munich; TU Wien; Ludwig-Maximilians-Universität München
646,pC44UMwy2v,pC44UMwy2v,16884,Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought,"Chain-of-Thought (CoT) reasoning has emerged as a promising approach for enhancing the performance of large language models (LLMs) on complex reasoning tasks. Recently, a series of studies attempt to explain the mechanisms underlying CoT, aiming to deepen the understanding of its efficacy. Nevertheless, the existing research faces two major challenges: (1) a lack of quantitative metrics to assess CoT capabilities and (2) a dearth of guidance on optimizing CoT performance. Motivated by this, in this work, we introduce a novel reasoning boundary framework (RBF) to address these challenges. To solve the lack of quantification, we first define a reasoning boundary (RB) to quantify the upper-bound of CoT and establish a combination law for RB, enabling a practical quantitative approach applicable to various real-world CoT tasks. To address the lack of optimization, we propose three categories of RBs. We further optimize these categories with combination laws focused on RB promotion and reasoning path optimization for CoT improvement. Through extensive experiments on 27 models and 5 tasks, the study validates the existence and rationality of the proposed framework. Furthermore, it explains the effectiveness of 10 CoT strategies and guides optimization from two perspectives. We hope this work can provide a comprehensive understanding of the boundaries and optimization strategies for reasoning in LLMs. Our code and data are available at https://github.com/LightChen233/reasoning-boundary.",Qiguang Chen; Libo Qin; Jiaqi WANG; Jingxuan Zhou; Wanxiang Che,~Qiguang_Chen1; ~Libo_Qin1; ~Jiaqi_WANG11; ~Jingxuan_Zhou2; ~Wanxiang_Che1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/47a165ca745dea00bf9fe4ba52210932fb6d1787.pdf,2024-05-15T12:13:38.923000,2024-09-25T18:15:39.994000,2024-12-26T05:41:32.619000,https://openreview.net/forum?id=pC44UMwy2v,Harbin Institute of Technology; Chinese University of Hong Kong
654,Y13gSfTjGr,Y13gSfTjGr,16848,Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations,"Scale has become a main ingredient in obtaining strong machine learning models. As a result, understanding a model's scaling properties is key to effectively designing both the right training setup as well as future generations of architectures. In this work, we argue that scale and training research has been needlessly complex due to reliance on the cosine schedule, which prevents training across different lengths for the same model size. We investigate the training behavior of a direct alternative --- constant learning rate and cooldowns --- and find that it scales predictably and reliably similar to cosine. Additionally, we show that stochastic weight averaging yields improved performance along the training trajectory, without additional training costs, across different scales. Importantly, with these findings we demonstrate that scaling experiments can be performed with significantly reduced compute and GPU hours by utilizing fewer but reusable training runs. Our code is available at https://github.com/epfml/schedules-and-scaling/.",Alexander Hägele; Elie Bakouch; Atli Kosson; Loubna Ben allal; Leandro Von Werra; Martin Jaggi,~Alexander_Hägele1; ~Elie_Bakouch1; ~Atli_Kosson1; ~Loubna_Ben_allal1; ~Leandro_Von_Werra1; ~Martin_Jaggi1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/faf94d39312b1ee562966b2527805c1d5aae2f2b.pdf,2024-05-15T12:09:16.285000,2024-09-25T18:15:38.826000,2024-11-06T06:19:41.926000,https://openreview.net/forum?id=Y13gSfTjGr,EPFL - EPF Lausanne; Hugging Face; EPFL - EPF Lausanne; Hugging Face; Hugging Face; EPFL - EPF Lausanne
682,qf2uZAdy1N,qf2uZAdy1N,16721,Reinforcement Learning Under Latent Dynamics: Toward Statistical and Algorithmic Modularity,"Real-world applications of reinforcement learning often involve  environments where agents operate on complex, high-dimensional observations, but the underlying (``latent'')  dynamics are comparatively simple. However, beyond restrictive settings
  such as tabular latent dynamics,  the fundamental statistical requirements and algorithmic principles for *reinforcement learning under latent dynamics* are poorly
  understood.

  This paper addresses the question of reinforcement learning under *general latent dynamics* from a
  statistical and algorithmic perspective.  On the statistical side, our main negative
result shows that *most* well-studied settings for reinforcement learning with function approximation become intractable when composed with rich observations; we complement this with a positive result, identifying *latent pushforward coverability* as a
general condition that enables statistical tractability. Algorithmically, we develop provably efficient *observable-to-latent* reductions ---that is, reductions that transform an arbitrary algorithm for the
  latent MDP into an algorithm that can operate on rich observations--- in two settings: one where the agent has access to hindsight
observations of the latent dynamics (Lee et al., 2023) and one
where the agent can estimate *self-predictive* latent models (Schwarzer et al., 2020). Together, our results serve as a
  first step toward a unified statistical and algorithmic theory for
reinforcement learning under latent dynamics.",Philip Amortila; Dylan J Foster; Nan Jiang; Akshay Krishnamurthy; Zakaria Mhammedi,~Philip_Amortila1; ~Dylan_J_Foster1; ~Nan_Jiang2; ~Akshay_Krishnamurthy1; ~Zakaria_Mhammedi1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/17710a946394531d22cd1cf32e0a7fd7bac1e6ac.pdf,2024-05-15T11:48:24.689000,2024-09-25T18:15:34.152000,2024-11-06T06:19:40.831000,https://openreview.net/forum?id=qf2uZAdy1N,"Microsoft; Department of Computer Science, University of Illinois at Urbana Champaign; Microsoft; Google"
684,m1a4CrRJR7,m1a4CrRJR7,16714,Generalization Error Bounds for Two-stage Recommender Systems with Tree Structure,"Two-stage recommender systems play a crucial role in efficiently identifying relevant items and personalizing recommendations from a vast array of options. This paper, based on an error decomposition framework, analyzes the generalization error for two-stage recommender systems with a tree structure, which consist of an efficient tree-based retriever and a more precise yet time-consuming ranker. We use the Rademacher complexity to establish the generalization upper bound for various tree-based retrievers using beam search, as well as for different ranker models under a shifted training distribution. Both theoretical insights and practical experiments on real-world datasets indicate that increasing the branches in tree-based retrievers and harmonizing distributions across stages can enhance the generalization performance of two-stage recommender systems.",Jin Zhang; Ze Liu; Defu Lian; Enhong Chen,~Jin_Zhang18; ~Ze_Liu4; ~Defu_Lian1; ~Enhong_Chen1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,learning_theory,/pdf/0573ad42adbbc93100e6c898b23c116d78de695b.pdf,2024-05-15T11:47:31.723000,2024-09-25T18:15:34.013000,2024-11-06T06:19:40.776000,https://openreview.net/forum?id=m1a4CrRJR7,University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China
698,3f8i9GlBzu,3f8i9GlBzu,16622,Can Transformers Smell Like Humans?,"The human brain encodes stimuli from the environment into representations that form a sensory perception of the world. Despite recent advances in understanding visual and auditory perception, olfactory perception remains an under-explored topic in the machine learning community due to the lack of large-scale datasets annotated with labels of human olfactory perception. In this work, we ask the question of whether pre-trained transformer models of chemical structures encode representations that are aligned with human olfactory perception, i.e., can transformers smell like humans? We demonstrate that representations encoded from transformers pre-trained on general chemical structures are highly aligned with human olfactory perception.  We use multiple datasets and different types of perceptual representations to show that the representations encoded by transformer models are able to predict: (i) labels associated with odorants‌‌ provided by experts; (ii) continuous ratings provided by human participants with respect to pre-defined descriptors; and (iii) similarity ratings between odorants provided by human participants. Finally, we evaluate the extent to which this alignment is associated with physicochemical features of odorants known to be relevant for olfactory decoding.",Farzaneh Taleb; Miguel Vasco; Antonio H. Ribeiro; Mårten Björkman; Danica Kragic,~Farzaneh_Taleb1; ~Miguel_Vasco1; ~Antonio_H._Ribeiro1; ~Mårten_Björkman2; ~Danica_Kragic1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/acc301b1485bf9469df59a6e4883c22cf5f86b60.pdf,2024-05-15T11:30:29.939000,2024-09-25T18:15:31.691000,2024-11-06T06:19:40.272000,https://openreview.net/forum?id=3f8i9GlBzu,KTH Royal Institute of Technology; KTH Royal Institute of Technology; Uppsala University; KTH Royal Institute of Technology
699,qTypwXvNJa,qTypwXvNJa,16621,Geodesic Optimization for Predictive Shift Adaptation on EEG data,"Electroencephalography (EEG) data is often collected from diverse contexts involving different populations and EEG devices. This variability can induce distribution shifts in the data $X$ and in the biomedical variables of interest $y$, thus limiting the application of supervised machine learning (ML) algorithms. While domain adaptation (DA) methods have been developed to mitigate the impact of these shifts, such methods struggle when distribution shifts occur simultaneously in $X$ and $y$. As state-of-the-art ML models for EEG represent the data by spatial covariance matrices, which lie on the Riemannian manifold of Symmetric Positive Definite (SPD) matrices, it is appealing to study DA techniques operating on the SPD manifold. This paper proposes a novel method termed Geodesic Optimization for Predictive Shift Adaptation (GOPSA) to address test-time multi-source DA for situations in which source domains have distinct $y$ distributions. GOPSA exploits the geodesic structure of the Riemannian manifold to jointly learn a domain-specific re-centering operator representing site-specific intercepts and the regression model. We performed empirical benchmarks on the cross-site generalization of age-prediction models with resting-state EEG data from a large multi-national dataset (HarMNqEEG), which included $14$ recording sites and more than $1500$ human participants. Compared to state-of-the-art methods, our results showed that GOPSA achieved significantly higher performance on three regression metrics ($R^2$, MAE, and Spearman's $\rho$) for several source-target site combinations, highlighting its effectiveness in tackling multi-source DA with predictive shifts in EEG data analysis. Our method has the potential to combine the advantages of mixed-effects modeling with machine learning for biomedical applications of EEG, such as multicenter clinical trials.",Apolline Mellot; Antoine Collas; Sylvain Chevallier; Alexandre Gramfort; Denis Alexander Engemann,~Apolline_Mellot1; ~Antoine_Collas1; ~Sylvain_Chevallier1; ~Alexandre_Gramfort1; ~Denis_Alexander_Engemann1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/cf7f84f31fb960f2d970680577da62f7b2f7ee5d.pdf,2024-05-15T11:30:15.309000,2024-09-25T18:15:31.638000,2024-11-06T06:19:40.237000,https://openreview.net/forum?id=qTypwXvNJa,"Inria, Paris; LISN, Universite Paris-Saclay; Genentech/Roche"
714,Pox8jNQOo5,Pox8jNQOo5,16525,Second-order forward-mode optimization of recurrent neural networks for neuroscience,"A common source of anxiety for the computational neuroscience student is the question “will my recurrent neural network (RNN) model finally learn that task?”. Unlike in machine learning where any architectural modification of an RNN (e.g. GRU or LSTM) is acceptable if it speeds up training, the RNN models trained as _models of brain dynamics_ are subject to plausibility constraints that fundamentally exclude the usual machine learning hacks. The “vanilla” RNNs commonly used in computational neuroscience find themselves plagued by ill-conditioned loss surfaces that complicate training and significantly hinder our capacity to investigate the brain dynamics underlying complex tasks. Moreover, some tasks may require very long time horizons which backpropagation cannot handle given typical GPU memory limits. Here, we develop SOFO, a second-order optimizer that efficiently navigates loss surfaces whilst _not_ requiring backpropagation. By relying instead on easily parallelized batched forward-mode differentiation, SOFO enjoys constant memory cost in time. Morever, unlike most second-order optimizers which involve inherently sequential operations, SOFO's effective use of GPU parallelism yields a per-iteration wallclock time essentially on par with first-order gradient-based optimizers. We show vastly superior performance compared to Adam on a number of RNN tasks, including a difficult double-reaching motor task and the learning of an adaptive Kalman filter algorithm trained over a long horizon.",Youjing Yu; Rui Xia; Qingxi Ma; Máté Lengyel; Guillaume Hennequin,~Youjing_Yu1; ~Rui_Xia2; ~Qingxi_Ma1; ~Máté_Lengyel1; ~Guillaume_Hennequin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/62423d9a8c2b8341d8bce0d3c16d6bae50fd2ed1.pdf,2024-05-15T11:12:47.924000,2024-09-25T18:15:28.738000,2024-11-06T06:19:39.695000,https://openreview.net/forum?id=Pox8jNQOo5,University of Cambridge; University of Cambridge; MediaTek Research; University of Cambridge
735,GTDKo3Sv9p,GTDKo3Sv9p,16380,Discrete Flow Matching,"Despite Flow Matching and diffusion models having emerged as powerful generative paradigms for continuous variables such as images and videos, their application to high-dimensional discrete data, such as language, is still limited.  In this work, we present Discrete Flow Matching, a novel discrete flow paradigm designed specifically for generating discrete data.  Discrete Flow Matching offers several key contributions:  (i) it works with a general family of probability paths interpolating between source and target distributions; (ii) it allows for a generic formula for sampling from these probability paths using learned posteriors such as the probability denoiser ($x$-prediction) and noise-prediction ($\epsilon$-prediction); (iii) practically, focusing on specific probability paths defined with different schedulers improves generative perplexity compared to previous discrete diffusion and flow models; and (iv) by scaling Discrete Flow Matching models up to 1.7B parameters, we reach 6.7% Pass@1 and 13.4% Pass@10 on HumanEval and 6.7% Pass@1 and 20.6% Pass@10 on 1-shot MBPP coding benchmarks. Our approach is capable of generating high-quality discrete data in a non-autoregressive fashion, significantly closing the gap between autoregressive models and discrete flow models.",Itai Gat; Tal Remez; Neta Shaul; Felix Kreuk; Ricky T. Q. Chen; Gabriel Synnaeve; Yossi Adi; Yaron Lipman,~Itai_Gat1; ~Tal_Remez2; ~Neta_Shaul1; ~Felix_Kreuk1; ~Ricky_T._Q._Chen1; ~Gabriel_Synnaeve1; ~Yossi_Adi1; ~Yaron_Lipman1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/a34963d87a6b108de57725388e3e3c36c0fce033.pdf,2024-05-15T10:43:19.456000,2024-09-25T18:15:25.088000,2024-11-06T06:19:38.971000,https://openreview.net/forum?id=GTDKo3Sv9p,Weizmann Institute of Science; Meta; Meta; Hebrew University of Jerusalem; Weizmann Institute of Science; Meta
741,4mxzxYhMuN,4mxzxYhMuN,16339,Motion Forecasting in Continuous Driving,"Motion forecasting for agents in autonomous driving is highly challenging due to the numerous possibilities for each agent's next action and their complex interactions in space and time. 
In real applications, motion forecasting takes place repeatedly and continuously as the self-driving car moves. However, existing forecasting methods typically process each driving scene within a certain range independently, totally ignoring the situational and contextual relationships between successive driving scenes. This significantly simplifies the forecasting task, making the solutions suboptimal and inefficient to use in practice. To address this fundamental limitation, we propose a novel motion forecasting framework for continuous driving, named RealMotion.
It comprises two integral streams both at the scene level:
(1) The scene context stream progressively accumulates historical scene information until the present moment, capturing temporal interactive relationships among scene elements.
(2) The agent trajectory stream optimizes current forecasting by sequentially relaying past predictions.
Besides, a data reorganization strategy is introduced to narrow the gap between existing benchmarks and real-world applications, consistent with our network. These approaches enable exploiting more broadly the situational and progressive insights of dynamic motion across space and time. 
Extensive experiments on Argoverse series with different settings demonstrate that our RealMotion achieves state-of-the-art performance, along with the advantage of efficient real-world inference.",Nan Song; Bozhou Zhang; Xiatian Zhu; Li Zhang,~Nan_Song4; ~Bozhou_Zhang1; ~Xiatian_Zhu3; ~Li_Zhang5,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,robotics,/pdf/2a125e7a1eda481ef4cf87ee407026f462a9ee79.pdf,2024-05-15T10:36:51.459000,2024-09-25T18:15:23.843000,2024-11-06T06:19:38.723000,https://openreview.net/forum?id=4mxzxYhMuN,Fudan University; Fudan University; University of Surrey; Fudan University
758,omyzrkacme,omyzrkacme,16261,Learning to Mitigate Externalities: the Coase Theorem with Hindsight Rationality,"In Economics, the concept of externality refers to any indirect effect resulting from an interaction between players and affecting a third party without compensation. Most of the models within which externality has been studied assume that agents have perfect knowledge of their environment and preferences. This is a major hindrance to the practical implementation of many proposed solutions. To adress this issue, we consider a two-players bandit game setting where the actions of one of the player affect the other one. Building upon this setup, we extend the Coase theorem [Coase, 2013], which suggests that the optimal approach for maximizing the social welfare in the presence of externality is to establish property rights, i.e., enabling transfers and bargaining between the players. Nonetheless, this fundamental result relies on the assumption that bargainers possess perfect knowledge of the underlying game. We first demonstrate that in the absence of property rights in the considered online scenario, the social welfare breaks down. We then provide a policy for the players, which allows them to learn a bargaining strategy which maximizes the total welfare, recovering the Coase theorem under uncertainty.",Antoine Scheid; Aymeric Capitaine; Etienne Boursier; Eric Moulines; Michael Jordan; Alain Oliviero Durmus,~Antoine_Scheid1; ~Aymeric_Capitaine1; ~Etienne_Boursier1; ~Eric_Moulines1; ~Michael_Jordan1; ~Alain_Oliviero_Durmus1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/cfe82f182f81ae3a6a8939ea1eda0a5b491dcba6.pdf,2024-05-15T10:21:58.301000,2024-09-25T18:15:21.508000,2024-11-06T06:19:38.103000,https://openreview.net/forum?id=omyzrkacme,"École Polytechnique; École Polytechnique; Inria, Paris; École Polytechnique; University of California, Berkeley"
762,rjSPDVdUaw,rjSPDVdUaw,16239,Moving Off-the-Grid: Scene-Grounded Video Representations,"Current vision models typically maintain a fixed correspondence between their representation structure and image space.
Each layer comprises a set of tokens arranged “on-the-grid,” which biases patches or tokens to encode information at a specific spatio(-temporal) location. In this work we present *Moving Off-the-Grid* (MooG), a self-supervised video representation model that offers an alternative approach, allowing tokens to move “off-the-grid” to better enable them to represent scene elements consistently, even as they move across the image plane through time. By using a combination of cross-attention and positional embeddings we disentangle the representation structure and image structure. We find that a simple self-supervised objective—next frame prediction—trained on video data, results in a set of latent tokens which bind to specific scene structures and track them as they move. We demonstrate the usefulness of MooG’s learned representation both qualitatively and quantitatively by training readouts on top of the learned representation on a variety of downstream tasks. We show that MooG can provide a strong foundation for different vision tasks when compared to “on-the-grid” baselines.",Sjoerd van Steenkiste; Daniel Zoran; Yi Yang; Yulia Rubanova; Rishabh Kabra; Carl Doersch; Dilara Gokay; Joseph Heyward; Etienne Pot; Klaus Greff; Drew A. Hudson; Thomas Albert Keck; Joao Carreira; Alexey Dosovitskiy; Mehdi S. M. Sajjadi; Thomas Kipf,~Sjoerd_van_Steenkiste1; ~Daniel_Zoran1; ~Yi_Yang10; ~Yulia_Rubanova2; ~Rishabh_Kabra1; ~Carl_Doersch1; ~Dilara_Gokay1; ~Joseph_Heyward2; ~Etienne_Pot1; ~Klaus_Greff1; ~Drew_Arad_Hudson1; ~Thomas_Albert_Keck1; ~Joao_Carreira1; ~Alexey_Dosovitskiy1; ~Mehdi_S._M._Sajjadi1; ~Thomas_Kipf2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/c573a5173a879863c518a1ab5e47992488c04e5c.pdf,2024-05-15T10:18:42.312000,2024-09-25T18:15:20.859000,2024-11-06T06:19:37.961000,https://openreview.net/forum?id=rjSPDVdUaw,Google; Google; Google; Google; University College London; Google; Google; Google; Google; Google; Google; Google; Google; Google; Google; Inceptive; Google; Google
770,kq166jACVP,kq166jACVP,16191,Aligner: Efficient Alignment by Learning to Correct,"With the rapid development of large language models (LLMs) and ever-evolving practical requirements, finding an efficient and effective alignment method has never been more critical. However, the tension between the complexity of current alignment methods and the need for rapid iteration in deployment scenarios necessitates the development of a model-agnostic alignment approach that can operate under these constraints. In this paper, we introduce Aligner, a novel and simple alignment paradigm that learns the correctional residuals between preferred and dispreferred answers using a small model. Designed as a model-agnostic, plug-and-play module, Aligner can be directly applied to various open-source and API-based models with only one-off training, making it suitable for rapid iteration. Notably, Aligner can be applied to any powerful, large-scale upstream models. Moreover, it can even iteratively bootstrap the upstream models using corrected responses as synthetic human preference data, breaking through the model's performance ceiling. Our experiments demonstrate performance improvements by deploying the same Aligner model across 11 different LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and honesty). Specifically, Aligner-7B has achieved an average improvement of 68.9% in helpfulness and 22.8% in harmlessness across the tested LLMs while also effectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking Aligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%, surpassing GPT-4 Omni's 57.5% Win Rate (community report).",Jiaming Ji; Boyuan Chen; Hantao Lou; Donghai Hong; Borong Zhang; Xuehai Pan; Tianyi Qiu; Juntao Dai; Yaodong Yang,~Jiaming_Ji2; ~Boyuan_Chen4; ~Hantao_Lou1; ~Donghai_Hong1; ~Borong_Zhang1; ~Xuehai_Pan1; ~Tianyi_Qiu1; ~Juntao_Dai1; ~Yaodong_Yang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/8413cbc690f0263fff27f69ca2e9ae16dcdb584d.pdf,2024-05-15T10:06:46.194000,2024-09-25T18:15:19.293000,2025-01-17T15:07:38.522000,https://openreview.net/forum?id=kq166jACVP,"Peking University; Peking University; Peking University; Peking University; Nanjing University; Jilin University; Peking University; Peking University; University of California, Berkeley; Zhejiang University; Peking University"
780,Oo7dlLgqQX,Oo7dlLgqQX,16093,Questioning the Survey Responses of Large Language Models,"Surveys have recently gained popularity as a tool to study large language models. By comparing models’ survey responses to those of different human reference populations, researchers aim to infer the demographics, political opinions, or values best represented by current language models. In this work, we critically examine language models' survey responses on the basis of the well-established American Community Survey by the U.S. Census Bureau. Evaluating 43 different language models using de-facto standard prompting methodologies, we establish two dominant patterns. First, models' responses are governed by ordering and labeling biases, for example, towards survey responses labeled with the letter “A”. Second, when adjusting for these systematic biases through randomized answer ordering, models across the board trend towards uniformly random survey responses, irrespective of model size or training data. As a result, models consistently appear to better represent subgroups whose aggregate statistics are closest to uniform for the survey under consideration, leading to potentially misguided conclusions about model alignment.",Ricardo Dominguez-Olmedo; Moritz Hardt; Celestine Mendler-Dünner,~Ricardo_Dominguez-Olmedo1; ~Moritz_Hardt1; ~Celestine_Mendler-Dünner1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/6a9813651d8de7fdc565ddb5dacecf057526a29a.pdf,2024-05-15T09:48:25.527000,2024-09-25T18:15:16.368000,2024-11-06T06:19:37.257000,https://openreview.net/forum?id=Oo7dlLgqQX,Max Planck Institute for Software Systems; Max Planck Institute for Software Systems
781,8KkBxzn0km,8KkBxzn0km,16088,Saliency-driven Experience Replay for Continual Learning,"We present Saliency-driven Experience Replay - SER - a biologically-plausible approach based on replicating human visual saliency to enhance classification models in continual learning settings. Inspired by neurophysiological evidence that the primary visual cortex does not contribute to object manifold untangling for categorization and that primordial saliency biases are still embedded in the modern brain, we propose to employ auxiliary saliency prediction features as a modulation signal to drive and stabilize the learning of a sequence of non-i.i.d. classification tasks. Experimental results confirm that SER effectively enhances the performance (in some cases up to about twenty percent points) of state-of-the-art continual learning methods, both in class-incremental and task-incremental settings. Moreover, we show that saliency-based modulation successfully encourages the learning of features that are more robust to the presence of spurious features and to adversarial attacks than baseline methods. Code is available at: https://github.com/perceivelab/SER",Giovanni Bellitto; Federica Proietto Salanitri; Matteo Pennisi; Matteo Boschini; Lorenzo Bonicelli; Angelo Porrello; Simone Calderara; Simone Palazzo; Concetto Spampinato,~Giovanni_Bellitto1; ~Federica_Proietto_Salanitri1; ~Matteo_Pennisi1; ~Matteo_Boschini1; ~Lorenzo_Bonicelli1; ~Angelo_Porrello1; ~Simone_Calderara1; ~Simone_Palazzo2; ~Concetto_Spampinato1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,online_learning,/pdf/26c565d2a0b64322caa72aee69fae8e023e337b9.pdf,2024-05-15T09:47:47.084000,2024-09-25T18:15:16.148000,2025-01-08T09:07:11.322000,https://openreview.net/forum?id=8KkBxzn0km,University of Catania; University of Catania; Campus Bio-Medico University of Rome; University of Catania; University of Modena and Reggio Emilia; University of Modena and Reggio Emilia; University of Modena and Reggio Emilia; University of Catania; University of Catania
786,eezCLKwx6T,eezCLKwx6T,16058,Adversarial Environment Design via Regret-Guided Diffusion Models,"Training agents that are robust to environmental changes remains a significant challenge in deep reinforcement learning (RL). Unsupervised environment design (UED) has recently emerged to address this issue by generating a set of training environments tailored to the agent's capabilities. While prior works demonstrate that UED has the potential to learn a robust policy, their performance is constrained by the capabilities of the environment generation. To this end, we propose a novel UED algorithm, adversarial environment design via regret-guided diffusion models (ADD). The proposed method guides the diffusion-based environment generator with the regret of the agent to produce environments that the agent finds challenging but conducive to further improvement. By exploiting the representation power of diffusion models, ADD can directly generate adversarial environments while maintaining the diversity of training environments, enabling the agent to effectively learn a robust policy. Our experimental results demonstrate that the proposed method successfully generates an instructive curriculum of environments, outperforming UED baselines in zero-shot generalization across novel, out-of-distribution environments.",Hojun Chung; Junseo Lee; Minsoo Kim; Dohyeong Kim; Songhwai Oh,~Hojun_Chung1; ~Junseo_Lee3; ~Minsoo_Kim4; ~Dohyeong_Kim1; ~Songhwai_Oh1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/07684aef33b424850702b780b6d8d2b231bacae9.pdf,2024-05-15T09:41:39.516000,2024-09-25T18:15:15.168000,2024-12-26T01:14:56.497000,https://openreview.net/forum?id=eezCLKwx6T,Seoul National University; Seoul National University
789,hS1jvV3Dk3,hS1jvV3Dk3,16043,Localized Zeroth-Order Prompt Optimization,"The efficacy of large language models (LLMs) in understanding and generating natural language has aroused a wide interest in developing prompt-based methods to harness the power of black-box LLMs. Existing methodologies usually prioritize a global optimization for finding the global optimum, which however will perform poorly in certain tasks. This thus motivates us to re-think the necessity of finding a global optimum in prompt optimization. To answer this, we conduct a thorough empirical study on prompt optimization and draw two major insights. Contrasting with the rarity of global optimum, local optima are usually prevalent and well-performed, which can be more worthwhile for efficient prompt optimization (**Insight I**). The choice of the input domain, covering both the generation and the representation of prompts, affects the identification of well-performing local optima (**Insight II**). Inspired by these insights, we propose a novel algorithm, namely localized zeroth-order prompt optimization (ZOPO), which incorporates a Neural Tangent Kernel-based derived Gaussian process into standard zeroth-order optimization for an efficient search of well-performing local optima in prompt optimization. Remarkably, ZOPO outperforms existing baselines in terms of both the optimization performance and the query efficiency, which we demonstrate through extensive experiments.",Wenyang Hu; Yao Shu; Zongmin Yu; Zhaoxuan Wu; Xiaoqiang Lin; Zhongxiang Dai; See-Kiong Ng; Bryan Kian Hsiang Low,~Wenyang_Hu1; ~Yao_Shu1; ~Zongmin_Yu1; ~Zhaoxuan_Wu1; ~Xiaoqiang_Lin1; ~Zhongxiang_Dai1; ~See-Kiong_Ng1; ~Bryan_Kian_Hsiang_Low1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/49f16c5b6e548016111d912835d15ae0a38ce762.pdf,2024-05-15T09:39:31.721000,2024-09-25T18:15:14.699000,2024-11-06T06:19:36.910000,https://openreview.net/forum?id=hS1jvV3Dk3,National University of Singapore; Guangming Lab; National University of Singapore; Singapore-MIT Alliance for Research and Technology; National University of Singapore; National University of Singapore; CUHK(Shenzhen); Massachusetts Institute of Technology; National University of Singapore; National University of Singapore
790,dg3tI3c2B1,dg3tI3c2B1,16042,Molecule Design by Latent Prompt Transformer,"This work explores the challenging problem of molecule design by framing it as a conditional generative modeling task, where target biological properties or desired chemical constraints serve as conditioning variables.
We propose the Latent Prompt Transformer (LPT), a novel generative model comprising three components: (1) a latent vector with a learnable prior distribution modeled by a neural transformation of Gaussian white noise; (2) a molecule generation model based on a causal Transformer, which uses the latent vector as a prompt; and (3) a property prediction model that predicts a molecule's target properties and/or constraint values using the latent prompt. LPT can be learned by maximum likelihood estimation on molecule-property pairs. During property optimization, the latent prompt is inferred from target properties and constraints through posterior sampling and then used to guide the autoregressive molecule generation.
After initial training on existing molecules and their properties, we adopt an online learning algorithm to progressively shift the model distribution towards regions that support desired target properties. Experiments demonstrate that LPT not only effectively discovers useful molecules across single-objective, multi-objective, and structure-constrained optimization tasks, but also exhibits strong sample efficiency.",Deqian Kong; Yuhao Huang; Jianwen Xie; Edouardo Honig; Ming Xu; Shuanghong Xue; Pei Lin; Sanping Zhou; Sheng Zhong; Nanning Zheng; Ying Nian Wu,~Deqian_Kong1; ~Yuhao_Huang3; ~Jianwen_Xie1; ~Edouardo_Honig1; ~Ming_Xu11; ~Shuanghong_Xue1; ~Pei_Lin2; ~Sanping_Zhou1; ~Sheng_Zhong12; ~Nanning_Zheng1; ~Ying_Nian_Wu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/e7eaaedb41ae00a838add8075c7268647e02467d.pdf,2024-05-15T09:39:27.888000,2024-09-25T18:15:14.645000,2024-11-06T06:19:36.809000,https://openreview.net/forum?id=dg3tI3c2B1,"University of California, Los Angeles; Akool; BioMap Research; University of California, Los Angeles; University of California, San Diego; University of California, San Diego; University of California, San Diego; Xi'an Jiaotong University; Xi'an Jiaotong University; University of California, Los Angeles"
792,YbxFwaSA9Z,YbxFwaSA9Z,16020,Can Learned Optimization Make Reinforcement Learning Less Difficult?,"While reinforcement learning (RL) holds great potential for decision making in the real world, it suffers from a number of unique difficulties which often need specific consideration. In particular: it is highly non-stationary; suffers from high degrees of plasticity loss; and requires exploration to prevent premature convergence to local optima and maximize return. In this paper, we consider whether learned optimization can help overcome these problems. Our method, Learned **O**ptimization for **P**lasticity, **E**xploration and **N**on-stationarity (*OPEN*), meta-learns an update rule whose input features and output structure are informed by previously proposed solutions to these difficulties. We show that our parameterization is flexible enough to enable meta-learning in diverse learning contexts, including the ability to use stochasticity for exploration. Our experiments demonstrate that when meta-trained on single and small sets of environments, *OPEN* outperforms or equals traditionally used optimizers. Furthermore, *OPEN* shows strong generalization characteristics across a range of environments and agent architectures.",Alexander D. Goldie; Chris Lu; Matthew Thomas Jackson; Shimon Whiteson; Jakob Nicolaus Foerster,~Alexander_D._Goldie1; ~Chris_Lu1; ~Matthew_Thomas_Jackson1; ~Shimon_Whiteson1; ~Jakob_Nicolaus_Foerster1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/97f6ce0d3187f9e369cbc7f1fa708e40d2a34e19.pdf,2024-05-15T09:37:02.887000,2024-09-25T18:15:14.055000,2024-11-06T06:19:36.760000,https://openreview.net/forum?id=YbxFwaSA9Z,University of Oxford; University of Oxford; Wayve; University of Oxford
797,U4BC0GrFAz,U4BC0GrFAz,16003,Do causal predictors generalize better to new domains?,"We study how well machine learning models trained on causal features generalize across domains. We consider 16 prediction tasks on tabular datasets covering applications in health, employment, education, social benefits, and politics. Each dataset comes with multiple domains, allowing us to test how well a model trained in one domain performs in another. For each prediction task, we select features that have a causal influence on the target of prediction. Our goal is to test the hypothesis that models trained on causal features generalize better across domains. Without exception, we find that predictors using all available features, regardless of causality, have better in-domain and out-of-domain accuracy than predictors using causal features. Moreover, even the absolute drop in accuracy from one domain to the other is no better for causal predictors than for models that use all features.  In addition, we show that recent causal machine learning methods for domain generalization do not perform better in our evaluation than standard predictors trained on the set of causal features. Likewise, causal discovery algorithms either fail to run or select causal variables that perform no better than our selection. Extensive robustness checks confirm that our findings are stable under variable misclassification.",Vivian Yvonne Nastl; Moritz Hardt,~Vivian_Yvonne_Nastl1; ~Moritz_Hardt1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,causal_inference,/pdf/3b0ea03559d5853f7212159e6e37c9fc4c09afeb.pdf,2024-05-15T09:34:47.890000,2024-09-25T18:15:13.586000,2024-11-06T06:19:36.485000,https://openreview.net/forum?id=U4BC0GrFAz,Max Planck Institute for Software Systems
831,C2xCLze1kS,C2xCLze1kS,15826,Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference,"To generate data from trained diffusion models, most inference algorithms, such as DDPM, DDIM, and other variants, rely on discretizing the reverse SDEs or their equivalent ODEs. In this paper, we view such approaches as decomposing the entire denoising diffusion process into several segments, each corresponding to a reverse transition kernel (RTK) sampling subproblem. Specifically, DDPM uses a Gaussian approximation for the RTK, resulting in low per-subproblem complexity but requiring a large number of segments (i.e., subproblems), which is conjectured to be inefficient. To address this, we develop a general RTK framework that enables a more balanced subproblem decomposition, resulting in $\tilde O(1)$ subproblems, each with strongly log-concave targets. We then propose leveraging two fast sampling algorithms, the Metropolis-Adjusted Langevin Algorithm (MALA) and Underdamped Langevin Dynamics (ULD), for solving these strongly log-concave subproblems. This gives rise to the RTK-MALA and RTK-ULD algorithms for diffusion inference. In theory, we further develop the convergence guarantees for  RTK-MALA and RTK-ULD in total variation (TV) distance: RTK-ULD can achieve $\epsilon$ target error within $\tilde{\mathcal O}(d^{1/2}\epsilon^{-1})$ under mild conditions, and  RTK-MALA enjoys a $\mathcal{O}(d^{2}\log(d/\epsilon))$   convergence rate under slightly stricter conditions. These theoretical results surpass the state-of-the-art convergence rates for diffusion inference and are well supported by numerical experiments.",Xunpeng Huang; Difan Zou; Hanze Dong; Yi Zhang; Yian Ma; Tong Zhang,~Xunpeng_Huang2; ~Difan_Zou1; ~Hanze_Dong1; ~Yi_Zhang94; ~Yian_Ma1; ~Tong_Zhang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/3b567855ed00c5a08b85aee9882b806a0958b583.pdf,2024-05-15T09:07:04.342000,2024-09-25T18:15:08.067000,2025-01-14T06:58:33.966000,https://openreview.net/forum?id=C2xCLze1kS,"Hong Kong University of Science and Technology(Guangzhou); University of Hong Kong; Salesforce Research Asia; University of Hong Kong; University of California, San Diego; Department of Computer Science, University of Illinois at Urbana Champaign"
839,tPgagXpvcV,tPgagXpvcV,15793,Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss,"We propose Any2graph, a generic framework for end-to-end Supervised Graph Prediction (SGP) i.e. a deep learning model that predicts an entire graph for any kind of input. The framework is built on a novel Optimal Transport loss, the Partially-Masked Fused Gromov-Wasserstein, that exhibits all necessary properties (permutation invariance, differentiability and scalability) and is designed to handle any-sized graphs. Numerical experiments showcase the versatility of the approach that outperform existing competitors on a novel challenging synthetic dataset and a variety of real-world tasks such as map construction from satellite image (Sat2Graph) or molecule prediction from fingerprint (Fingerprint2Graph).",Paul KRZAKALA; Junjie Yang; Rémi Flamary; Florence d'Alché-Buc; Charlotte Laclau; Matthieu Labeau,~Paul_KRZAKALA1; ~Junjie_Yang3; ~Rémi_Flamary1; ~Florence_d'Alché-Buc2; ~Charlotte_Laclau2; ~Matthieu_Labeau2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/2da8ac1a2d0e07ab727eb467d8d3907addafb2ca.pdf,2024-05-15T09:01:15.870000,2024-09-25T18:15:07.124000,2024-11-06T06:19:34.689000,https://openreview.net/forum?id=tPgagXpvcV,Télécom Paris; Télécom Paris; École Polytechnique; Télécom Paris; Télécom Paris
847,fPBACAbqSN,fPBACAbqSN,15724,MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention,"The computational challenges of Large Language Model (LLM) inference remain a significant barrier to their widespread deployment, especially as prompt lengths continue to increase. Due to the quadratic complexity of the attention computation, it takes 30 minutes for an 8B LLM to process a prompt of 1M tokens (i.e., the pre-filling stage) on a single A100 GPU. Existing methods for speeding up prefilling often fail to maintain acceptable accuracy or efficiency when applied to long-context LLMs. To address this gap, we introduce MInference (Milliontokens Inference), a sparse calculation method designed to accelerate pre-filling of long-sequence processing. Specifically, we identify three unique patterns in long-context attention matrices-the A-shape, Vertical-Slash, and Block-Sparse-that can be leveraged for efficient sparse computation on GPUs. We determine the optimal pattern for each attention head offline and dynamically build sparse
indices based on the assigned pattern during inference. With the pattern and sparse indices, we perform efficient sparse attention calculations via our optimized GPU kernels to significantly reduce the latency in the pre-filling stage of longcontext LLMs. Our proposed technique can be directly applied to existing LLMs without any modifications to the pre-training setup or additional fine-tuning. By
evaluating on a wide range of downstream tasks, including InfiniteBench, RULER, PG-19, and Needle In A Haystack, and models including LLaMA-3-1M, GLM-4-1M, Yi-200K, Phi-3-128K, and Qwen2-128K, we demonstrate that MInference effectively reduces inference latency by up to 10x for pre-filling on an A100, while maintaining accuracy. Our code is available at https://aka.ms/MInference.",Huiqiang Jiang; YUCHENG LI; Chengruidong Zhang; Qianhui Wu; Xufang Luo; Surin Ahn; Zhenhua Han; Amir H. Abdi; Dongsheng Li; Chin-Yew Lin; Yuqing Yang; Lili Qiu,~Huiqiang_Jiang2; ~YUCHENG_LI2; ~Chengruidong_Zhang1; ~Qianhui_Wu1; ~Xufang_Luo1; ~Surin_Ahn1; ~Zhenhua_Han1; ~Amir_H._Abdi1; ~Dongsheng_Li2; ~Chin-Yew_Lin1; ~Yuqing_Yang1; ~Lili_Qiu3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/f310c4e86a654f90ec6db3b665c2a7e79ec888a2.pdf,2024-05-15T08:50:02.814000,2024-09-25T18:15:05.275000,2025-01-15T03:35:30.182000,https://openreview.net/forum?id=fPBACAbqSN,Microsoft; University of Surrey; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; The University of Texas at Austin
862,7arAADUK6D,7arAADUK6D,15618,Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration,"Large language models (LLMs) exhibit complementary strengths in various tasks, motivating the research of LLM ensembling.
However, existing work focuses on training an extra reward model or fusion model to select or combine all candidate answers, posing a great challenge to the generalization on unseen data distributions.
Besides, prior methods use textual responses as communication media, ignoring the valuable information in the internal representations.
In this work, we propose a training-free ensemble framework \textsc{DeePEn}, fusing the informative probability distributions yielded by different LLMs at each decoding step.
Unfortunately, the vocabulary discrepancy between heterogeneous LLMs directly makes averaging the distributions unfeasible due to the token misalignment.
To address this challenge, \textsc{DeePEn} maps the probability distribution of each model from its own probability space to a universal \textit{relative space} based on the relative representation theory, and performs aggregation.
Next, we devise a search-based inverse transformation to transform the aggregated result back to the probability space of one of the ensembling LLMs (main model), in order to determine the next token.
We conduct extensive experiments on ensembles of different number of LLMs, ensembles of LLMs with different architectures, and ensembles between the LLM and the specialist model.
Experimental results show that (i) \textsc{DeePEn} achieves consistent improvements across six benchmarks covering subject examination, reasoning, and knowledge, (ii) a well-performing specialist model can benefit from a less effective LLM through distribution fusion, and (iii) \textsc{DeePEn} has complementary strengths with other ensemble methods such as voting.",Yichong Huang; Xiaocheng Feng; Baohang Li; Yang Xiang; Hui Wang; Ting Liu; Bing Qin,~Yichong_Huang1; ~Xiaocheng_Feng1; ~Baohang_Li1; ~Yang_Xiang4; ~Hui_Wang13; ~Ting_Liu2; ~Bing_Qin2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/4f1e94d2e04c04725fc7f351d7d0330a23d3e27e.pdf,2024-05-15T08:35:24.285000,2024-09-25T18:15:02.397000,2024-11-06T06:19:33.776000,https://openreview.net/forum?id=7arAADUK6D,Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology; Peng Cheng Laboratory; Cloud Computing; Harbin Institute of Technology; Harbin Institute of Technology
868,GrMczQGTlA,GrMczQGTlA,15598,Humanoid Locomotion as Next Token Prediction,"We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal transformer trained via autoregressive prediction of sensorimotor sequences. To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, such as videos without actions. We train our model on a dataset of sequences from a prior neural network policy, a model-based controller, motion capture, and YouTube videos of humans. We show that our model enables a real humanoid robot to walk in San Francisco zero-shot. Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training. These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor sequences.",Ilija Radosavovic; Bike Zhang; Baifeng Shi; Jathushan Rajasegaran; Sarthak Kamat; Trevor Darrell; Koushil Sreenath; Jitendra Malik,~Ilija_Radosavovic1; ~Bike_Zhang1; ~Baifeng_Shi1; ~Jathushan_Rajasegaran2; ~Sarthak_Kamat1; ~Trevor_Darrell2; ~Koushil_Sreenath1; ~Jitendra_Malik2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,robotics,/pdf/2f48ec003c19b29d4023a570d0f23d939a099cb2.pdf,2024-05-15T08:33:04.139000,2024-09-25T18:15:01.750000,2025-01-16T01:46:47.091000,https://openreview.net/forum?id=GrMczQGTlA,"University of California, Berkeley; NVIDIA; University of California, Berkeley; University of California, Berkeley; Electrical Engineering & Computer Science Department; University of California, Berkeley; Meta; University of California, Berkeley"
895,ZWNdgc13aw,ZWNdgc13aw,15369,NeoRL: Efficient Exploration for Nonepisodic RL,"We study the problem of nonepisodic reinforcement learning (RL) for nonlinear dynamical systems, where the system dynamics are unknown and the RL agent has to learn from a single trajectory, i.e., without resets. We propose **N**on**e**pisodic **O**ptistmic **RL** (NeoRL), an approach based on the principle of optimism in the face of uncertainty. NeoRL uses well-calibrated probabilistic models and plans optimistically w.r.t. the epistemic uncertainty about the unknown dynamics. Under continuity and bounded energy assumptions on the system, we
provide a first-of-its-kind regret bound of  $\mathcal{O}(\beta_T \sqrt{T \Gamma_T})$ for general nonlinear systems with Gaussian process dynamics. We compare NeoRL to other baselines on several deep RL environments and empirically demonstrate that NeoRL achieves the optimal average cost while incurring the least regret.",Bhavya Sukhija; Lenart Treven; Florian Dorfler; Stelian Coros; Andreas Krause,~Bhavya_Sukhija1; ~Lenart_Treven1; ~Florian_Dorfler1; ~Stelian_Coros1; ~Andreas_Krause1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/48e0e53d557dc2db24cd64ea33611329103f1d32.pdf,2024-05-15T07:52:42.763000,2024-09-25T18:14:55.850000,2024-11-06T06:19:32.492000,https://openreview.net/forum?id=ZWNdgc13aw,ETH Zurich; ETH Zurich
914,5a27EE8LxX,5a27EE8LxX,15278,Toxicity Detection for Free,"Current LLMs are generally aligned to follow safety requirements and tend to refuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be overcautious and refuse benign examples. In addition, state-of-the-art toxicity detectors have low TPRs at low FPR, incurring high costs in real-world applications where toxic examples are rare. In this paper, we introduce Moderation Using LLM Introspection (MULI), which detects toxic prompts using the information extracted directly from LLMs themselves. We found we can distinguish between benign and toxic prompts from the distribution of the first response token's logits. Using this idea, we build a robust detector of toxic prompts using a sparse logistic regression model on the first response token logits. Our scheme outperforms SOTA detectors under multiple metrics.",Zhanhao Hu; Julien Piet; Geng Zhao; Jiantao Jiao; David Wagner,~Zhanhao_Hu1; ~Julien_Piet1; ~Geng_Zhao2; ~Jiantao_Jiao1; ~David_Wagner3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/a85ec0acbdd1c3e1839c2cf699e5472f0aef1ea6.pdf,2024-05-15T07:39:10.880000,2024-09-25T18:14:53.217000,2024-11-06T06:19:31.761000,https://openreview.net/forum?id=5a27EE8LxX,"University of California, Berkeley; University of California, Berkeley; University of California, Berkeley"
916,FV4an2OuFM,FV4an2OuFM,15272,Conditioning non-linear and infinite-dimensional diffusion processes,"Generative diffusion models and many stochastic models in science and engineering naturally live in infinite dimensions before discretisation. To incorporate observed data for statistical and learning tasks, one needs to condition on observations. While recent work has treated conditioning linear processes in infinite dimensions, conditioning non-linear processes in infinite dimensions has not been explored. This paper conditions function valued stochastic processes without prior discretisation. To do so, we use an infinite-dimensional version of Girsanov's theorem to condition a function-valued stochastic process, leading to a stochastic differential equation (SDE) for the conditioned process involving the score. We apply this technique to do time series analysis for shapes of organisms in evolutionary biology, where we discretise via the Fourier basis and then learn the coefficients of the score function with score matching methods.",Elizabeth Louise Baker; Gefan Yang; Michael Lind Severinsen; Christy Anna Hipsley; Stefan Sommer,~Elizabeth_Louise_Baker1; ~Gefan_Yang1; ~Michael_Lind_Severinsen1; ~Christy_Anna_Hipsley1; ~Stefan_Sommer1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/96c35a8b6778720c6768e3e810953b5b7100e767.pdf,2024-05-15T07:37:50.468000,2024-09-25T18:14:53.087000,2024-11-06T06:19:31.675000,https://openreview.net/forum?id=FV4an2OuFM,University of Copenhagen; University of Copenhagen; University of Copenhagen
918,AqcPvWwktK,AqcPvWwktK,15265,Semi-supervised Multi-label Learning with Balanced Binary Angular Margin Loss,"Semi-supervised multi-label learning (SSMLL) refers to inducing classifiers using a small number of samples with multiple labels and many unlabeled samples. The prevalent solution of SSMLL involves forming pseudo-labels for unlabeled samples and inducing classifiers using both labeled and pseudo-labeled samples in a self-training manner. Unfortunately, with the commonly used binary type of loss and negative sampling, we have empirically found that learning with labeled and pseudo-labeled samples can result in the variance bias problem between the feature distributions of positive and negative samples for each label. To alleviate this problem, we aim to balance the variance bias between positive and negative samples from the perspective of the feature angle distribution for each label. Specifically, we extend the traditional binary angular margin loss to a balanced extension with feature angle distribution transformations under the Gaussian assumption, where the distributions are iteratively updated during classifier training. We also suggest an efficient prototype-based negative sampling method to maintain high-quality negative samples for each label. With this insight, we propose a novel SSMLL method, namely Semi-Supervised Multi-Label Learning with Balanced Binary Angular Margin loss (S$^2$ML$^2$-BBAM). To evaluate the effectiveness of S$^2$ML$^2$-BBAM, we compare it with existing competitors on benchmark datasets. The experimental results validate that S$^2$ML$^2$-BBAM can achieve very competitive performance.",Ximing Li; Silong Liang; Changchun Li; pengfei wang; Fangming Gu,~Ximing_Li1; ~Silong_Liang2; ~Changchun_Li1; ~pengfei_wang6; ~Fangming_Gu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/1d6daf36152918dba4956ece861d6bbe77864f05.pdf,2024-05-15T07:37:04.252000,2024-09-25T18:14:52.854000,2024-11-06T06:19:31.627000,https://openreview.net/forum?id=AqcPvWwktK,Jilin University; Jilin University; University of Chinese Academy of Sciences; Jilin University
950,2wfd3pti8v,2wfd3pti8v,15085,Automated Efficient Estimation using Monte Carlo Efficient Influence Functions,"Many practical problems involve estimating low dimensional statistical quantities with high-dimensional models and datasets. Several approaches address these estimation tasks based on the theory of influence functions, such as debiased/double ML or targeted minimum loss estimation. We introduce \textit{Monte Carlo Efficient Influence Functions} (MC-EIF), a fully automated technique for approximating efficient influence functions that integrates seamlessly with existing differentiable probabilistic programming systems. MC-EIF automates efficient statistical estimation for a broad class of models and functionals that previously required rigorous custom analysis. We prove that MC-EIF is consistent, and that estimators using MC-EIF achieve optimal $\sqrt{N}$ convergence rates. We show empirically that estimators using MC-EIF are at parity with estimators using analytic EIFs. Finally, we present a novel capstone example using MC-EIF for optimal portfolio selection.",Raj Agrawal; Sam Witty; Andy Zane; Eli Bingham,~Raj_Agrawal3; ~Sam_Witty1; ~Andy_Zane1; ~Eli_Bingham1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,causal_inference,/pdf/e95941278303ffa2127543bfe847d067d4d1bc9c.pdf,2024-05-15T07:07:48.662000,2024-09-25T18:14:47.103000,2024-11-06T06:19:30.428000,https://openreview.net/forum?id=2wfd3pti8v,Basis Research Institute; Basis
966,74B6qX62vW,74B6qX62vW,14990,Sample-Efficient Private Learning of Mixtures of Gaussians,"We study the problem of learning mixtures of Gaussians with approximate differential privacy. We prove that roughly $kd^2 + k^{1.5} d^{1.75} + k^2 d$ samples suffice to learn a mixture of $k$ arbitrary $d$-dimensional Gaussians up to low total variation distance, with differential privacy. Our work improves over the previous best result (which required roughly $k^2 d^4$ samples) and is provably optimal when $d$ is much larger than $k^2$. Moreover, we give the first optimal bound for privately learning mixtures of $k$ univariate (i.e., $1$-dimensional) Gaussians. Importantly, we show that the sample complexity for learning mixtures of univariate Gaussians is linear in the number of components $k$, whereas the previous best sample complexity was quadratic in $k$. Our algorithms utilize various techniques, including the inverse sensitivity mechanism, sample compression for distributions, and methods for bounding volumes of sumsets.",Hassan Ashtiani; Mahbod Majid; Shyam Narayanan,~Hassan_Ashtiani1; ~Mahbod_Majid1; ~Shyam_Narayanan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/4592d1b02a295331e6502c770e99a21953f21126.pdf,2024-05-15T06:52:47.612000,2024-09-25T18:14:44.697000,2024-11-06T06:19:29.705000,https://openreview.net/forum?id=74B6qX62vW,McMaster University
971,opt72TYzwZ,opt72TYzwZ,14963,Optimal ablation for interpretability,"Interpretability studies often involve tracing the flow of information through machine learning models to identify specific model components that perform relevant computations for tasks of interest. Prior work quantifies the importance of a model component on a particular task by measuring the impact of performing ablation on that component, or simulating model inference with the component disabled.
 We propose a new method, optimal ablation (OA), and show that OA-based component importance has theoretical and empirical advantages over measuring importance via other ablation methods. We also show that OA-based component importance can benefit several downstream interpretability tasks, including circuit discovery, localization of factual recall, and latent prediction.",Maximilian Li; Lucas Janson,~Maximilian_Li1; ~Lucas_Janson2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/2575d807ee7d657841c4bdd5cfdaed85cb895f09.pdf,2024-05-15T06:47:17.253000,2024-09-25T18:14:43.958000,2024-11-06T06:19:29.558000,https://openreview.net/forum?id=opt72TYzwZ,
973,ZGN8dOhpi6,ZGN8dOhpi6,14957,A Pairwise Pseudo-likelihood Approach for Matrix Completion with Informative Missingness,"While several recent matrix completion methods are developed to deal with non-uniform observation probabilities across matrix entries, very few allow the missingness to depend on the mostly unobserved matrix measurements, which is generally ill-posed. We aim to tackle a subclass of these ill-posed settings, characterized by a flexible separable observation probability assumption that can depend on the matrix measurements. We propose a regularized pairwise pseudo-likelihood approach for matrix completion and prove that the proposed estimator can asymptotically recover the low-rank parameter matrix up to an identifiable equivalence class of a constant shift and scaling, at a near-optimal asymptotic convergence rate of the standard well-posed (non-informative missing) setting, while effectively mitigating the impact of informative missingness. The efficacy of our method is validated via numerical experiments, positioning it as a robust tool for matrix completion to mitigate data bias.",Jiangyuan Li; Jiayi Wang; Raymond K. W. Wong; Kwun Chuen Gary Chan,~Jiangyuan_Li1; ~Jiayi_Wang7; ~Raymond_K._W._Wong1; ~Kwun_Chuen_Gary_Chan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/d59a20f2b5c00a556978bb63368060eeb5e41f8f.pdf,2024-05-15T06:46:00.834000,2024-09-25T18:14:43.764000,2025-01-06T02:34:12.708000,https://openreview.net/forum?id=ZGN8dOhpi6,"Google; University of Texas, Dallas; Texas A&M University"
989,uCZI8gSfD4,uCZI8gSfD4,14879,Training Compute-Optimal Protein Language Models,"We explore optimally training protein language models, an area of significant interest in biological research where guidance on best practices is limited.
Most models are trained with extensive compute resources until performance gains plateau, focusing primarily on increasing model sizes rather than optimizing the efficient compute frontier that balances performance and compute budgets.
Our investigation is grounded in a massive dataset consisting of 939 million protein sequences. 
We trained over 300 models ranging from 3.5 million to 10.7 billion parameters on 5 to 200 billion unique tokens, to investigate the relations between model sizes, training token numbers, and objectives.
First, we observed the effect of diminishing returns for the Causal Language Model (CLM) and that of overfitting for Masked Language Model (MLM) when repeating the commonly used Uniref database. To address this, we included metagenomic protein sequences in the training set to increase the diversity and avoid the plateau or overfitting effects. 
Second, we obtained the scaling laws of CLM and MLM on Transformer, tailored to the specific characteristics of protein sequence data. 
Third, we observe a transfer scaling phenomenon from CLM to MLM, further demonstrating the effectiveness of transfer through scaling behaviors based on estimated Effectively Transferred Tokens.
Finally, to validate our scaling laws, we compare the large-scale versions of ESM-2 and PROGEN2 on downstream tasks, encompassing evaluations of protein generation as well as structure- and function-related tasks, all within less or equivalent pre-training compute budgets.",Xingyi Cheng; Bo Chen; Pan Li; Jing Gong; Jie Tang; Le Song,~Xingyi_Cheng3; ~Bo_Chen11; ~Pan_Li11; ~Jing_Gong1; ~Jie_Tang1; ~Le_Song1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/5b6ca1e41c84b9d1e3cae244f0de73392b8e685d.pdf,2024-05-15T06:34:42.670000,2024-09-25T18:14:41.650000,2024-12-19T03:10:10.927000,https://openreview.net/forum?id=uCZI8gSfD4,"BioMap Research; Tsinghua University, Beijing"
993,J2wI2rCG2u,J2wI2rCG2u,14856,Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators,"Optimizing neural networks with loss that contain high-dimensional and high-order differential operators
  is expensive to evaluate with back-propagation due to $\mathcal{O}(d^{k})$ scaling of the derivative tensor size and the $\mathcal{O}(2^{k-1}L)$ scaling in the computation graph, where $d$ is the dimension of the domain, $L$ is the number of ops in the forward computation graph, and $k$ is the derivative order. In previous works, the polynomial scaling in $d$ was addressed by amortizing the computation over the optimization process via randomization. Separately, the exponential scaling in $k$ for univariate functions ($d=1$) was addressed with high-order auto-differentiation (AD). In this work, we show how to efficiently perform arbitrary contraction of the derivative tensor of arbitrary order for multivariate functions, by properly constructing the input tangents to univariate high-order AD, which can be used to efficiently randomize any differential operator.
  When applied to Physics-Informed Neural Networks (PINNs), our method provides >1000$\times$ speed-up and >30$\times$ memory reduction over randomization with first-order AD, and we can now solve 1-million-dimensional PDEs in 8 minutes on a single NVIDIA A100 GPU. This work opens the possibility of using high-order differential operators in large-scale problems.",Zekun Shi; Zheyuan Hu; Min Lin; Kenji Kawaguchi,~Zekun_Shi3; ~Zheyuan_Hu1; ~Min_Lin1; ~Kenji_Kawaguchi1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/8df82199f3b7e09ca3d98f528bb665d7c735933d.pdf,2024-05-15T06:29:46.923000,2024-09-25T18:14:41.130000,2025-01-17T13:36:05.617000,https://openreview.net/forum?id=J2wI2rCG2u,"National University of Singapore; Sea AI Lab, Sea, Singapore; National University of Singapore; Sea AI Lab, Sea, Singapore; National University of Singapore"
1000,4rCZeCZAON,4rCZeCZAON,14776,Do Finetti: On Causal Effects for Exchangeable Data,"We study causal effect estimation in a setting where the data are not i.i.d.$\ $(independent and identically distributed). We focus on exchangeable data satisfying an assumption of independent causal mechanisms. Traditional causal effect estimation frameworks, e.g., relying on structural causal models and do-calculus, are typically limited to i.i.d. data and do not extend to more general exchangeable generative processes, which naturally arise in multi-environment data. To address this gap, we develop a generalized framework for exchangeable data and introduce a truncated factorization formula that facilitates both the identification and estimation of causal effects in our setting. To illustrate potential applications, we introduce a causal Pólya urn model and demonstrate how intervention propagates effects in exchangeable data settings. Finally, we develop an algorithm that performs simultaneous causal discovery and effect estimation given multi-environment data.",Siyuan Guo; Chi Zhang; Karthika Mohan; Ferenc Huszár; Bernhard Schölkopf,~Siyuan_Guo1; ~Chi_Zhang23; ~Karthika_Mohan1; ~Ferenc_Huszár1; ~Bernhard_Schölkopf1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,causal_inference,/pdf/8f348634669f055ea725df69d4de4fac31b49194.pdf,2024-05-15T06:13:20.360000,2024-09-25T18:14:38.991000,2024-11-06T06:19:28.394000,https://openreview.net/forum?id=4rCZeCZAON,"Max Planck Institute for Software Systems; University of Cambridge; Toyota Research Institute; ELLIS Institute, Tübingen; Max Planck Institute for Software Systems"
1010,fykjplMc0V,fykjplMc0V,14711,ReFT: Representation Finetuning for Language Models,"Parameter-efficient finetuning (PEFT) methods seek to adapt large neural models via updates to a small number of *weights*. However, much prior interpretability work has shown that *representations* encode rich semantic information, suggesting that editing representations might be a more powerful alternative. We pursue this hypothesis by developing a family of **Representation Finetuning (ReFT)** methods. ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations. We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT), and we identify an ablation of this method that trades some performance for increased efficiency. Both are drop-in replacements for existing PEFTs and learn interventions that are 15x--65x more parameter-efficient than LoRA. We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, instruction-tuning, and GLUE. In all these evaluations, our ReFTs deliver the best balance of efficiency and performance, and almost always outperform state-of-the-art PEFTs. Upon publication, we will publicly release our generic ReFT training library.",Zhengxuan Wu; Aryaman Arora; Zheng Wang; Atticus Geiger; Dan Jurafsky; Christopher D Manning; Christopher Potts,~Zhengxuan_Wu1; ~Aryaman_Arora1; ~Zheng_Wang41; ~Atticus_Geiger1; ~Dan_Jurafsky1; ~Christopher_D_Manning1; ~Christopher_Potts1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/b8ce3ebf55fb6d6b3d11a228b12750efc960059f.pdf,2024-05-15T06:00:30.745000,2024-09-25T18:14:37.402000,2024-11-06T06:19:28.019000,https://openreview.net/forum?id=fykjplMc0V,Stanford University; Stanford University; Pr(Ai)²R Group; Stanford University; Stanford University
1011,4NJBV6Wp0h,4NJBV6Wp0h,14702,LLM Evaluators Recognize and Favor Their Own Generations,"Self-evaluation using large language models (LLMs) has proven valuable not only in benchmarking but also methods like reward modeling, constitutional AI, and self-refinement. But new biases are introduced due to the same LLM acting as both the evaluator and the evaluatee. One such bias is self-preference, where an LLM evaluator scores its own outputs higher than others’ while human annotators consider them of equal quality. But do LLMs actually recognize their own outputs when they give those texts higher scores, or is it just a coincidence? In this paper, we investigate if self-recognition capability contributes to self-preference. We discover that, out of the box, LLMs such as GPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from other LLMs and humans. By finetuning LLMs, we discover a linear correlation between self-recognition capability and the strength of self-preference bias; using controlled experiments, we show that the causal explanation resists straightforward confounders. We discuss how self-recognition can interfere with unbiased evaluations and AI safety more generally.",Arjun Panickssery; Samuel R. Bowman; Shi Feng,~Arjun_Panickssery1; ~Samuel_R._Bowman1; ~Shi_Feng1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/17f3e3ce067de145352b0881a5a5a351cfcceac4.pdf,2024-05-15T05:59:19.696000,2024-09-25T18:14:37.167000,2024-11-06T06:19:27.996000,https://openreview.net/forum?id=4NJBV6Wp0h,New York University; Anthropic; New York University; George Washington University
1030,tUpcRQNvVM,tUpcRQNvVM,14619,Deep Submodular Peripteral Networks,"Submodular functions, crucial for various applications, often lack practical learning methods for their acquisition.  Seemingly unrelated, learning a scaling from oracles offering graded pairwise preferences (GPC) is underexplored, despite a rich history in psychometrics. In this paper, we introduce deep submodular peripteral networks (DSPNs), a novel parametric family of submodular functions, and methods for their training using a GPC-based strategy to connect and then tackle both of the above challenges.  We introduce newly devised GPC-style ``peripteral'' loss which leverages numerically graded relationships between pairs of objects (sets in our case). Unlike traditional contrastive learning, or RHLF preference ranking, our method utilizes graded comparisons, extracting more nuanced information than just binary-outcome comparisons, and contrasts sets of any size (not just two). We also define a novel suite of automatic sampling strategies for training, including active-learning inspired submodular feedback.  We demonstrate DSPNs' efficacy in learning submodularity from a costly target submodular function and demonstrate its superiority both for experimental design and online streaming applications.",Gantavya Bhatt; Arnav Mohanty Das; Jeff Bilmes,~Gantavya_Bhatt1; ~Arnav_Mohanty_Das1; ~Jeff_Bilmes1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,active_learning,/pdf/172483363c72a00d7bbe1d70ca8e1b45baeb3889.pdf,2024-05-15T05:43:58.811000,2024-09-25T18:14:34.778000,2024-11-06T06:19:27.242000,https://openreview.net/forum?id=tUpcRQNvVM,University of Washington; University of Washington; University of Washington
1032,8on9dIUh5v,8on9dIUh5v,14607,Provable Benefit of Cutout and CutMix for Feature Learning,"Patch-level data augmentation techniques such as Cutout and CutMix have demonstrated significant efficacy in enhancing the performance of vision tasks. However, a comprehensive theoretical understanding of these methods remains elusive. In this paper, we study two-layer neural networks trained using three distinct methods: vanilla training without augmentation, Cutout training, and CutMix training. Our analysis focuses on a feature-noise data model, which consists of several label-dependent features of varying rarity and label-independent noises of differing strengths. Our theorems demonstrate that Cutout training can learn low-frequency features that vanilla training cannot, while CutMix training can learn even rarer features that Cutout cannot capture. From this, we establish that CutMix yields the highest test accuracy among the three. Our novel analysis reveals that CutMix training makes the network learn all features and noise vectors ""evenly"" regardless of the rarity and strength, which provides an interesting insight into understanding patch-level augmentation.",Junsoo Oh; Chulhee Yun,~Junsoo_Oh1; ~Chulhee_Yun1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/335004e49a3ba0f8a1f3e10f5b65da7bb40571f9.pdf,2024-05-15T05:41:55.950000,2024-09-25T18:14:34.331000,2024-11-06T06:19:27.123000,https://openreview.net/forum?id=8on9dIUh5v,Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology
1033,pR37AmwbOt,pR37AmwbOt,14597,Leveraging Catastrophic Forgetting to Develop Safe Diffusion Models against Malicious Finetuning,"Diffusion models (DMs) have demonstrated remarkable proficiency in producing images based on textual prompts. Numerous methods have been proposed to ensure these models generate safe images. Early methods attempt to incorporate safety filters into models to mitigate the risk of generating harmful images but such external filters do not inherently detoxify the model and can be easily bypassed. Hence, model unlearning and data cleaning are the most essential methods for maintaining the safety of models, given their impact on model parameters.
However, malicious fine-tuning can still make models prone to generating harmful or undesirable images even with these methods.
Inspired by the phenomenon of catastrophic forgetting, we propose a training policy using contrastive learning to increase the latent space distance between clean and harmful data distribution, thereby protecting models from being fine-tuned to generate harmful images due to forgetting.
The experimental results demonstrate that our methods not only maintain clean image generation capabilities before malicious fine-tuning but also effectively prevent DMs from producing harmful images after malicious fine-tuning. Our method can also be combined with other safety methods to maintain their safety against malicious fine-tuning further.",Jiadong Pan; Hongcheng Gao; Zongyu Wu; taihang Hu; Li Su; Qingming Huang; Liang Li,~Jiadong_Pan1; ~Hongcheng_Gao1; ~Zongyu_Wu1; ~taihang_Hu1; ~Li_Su4; ~Qingming_Huang2; ~Liang_Li3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/93f012b5feddc8835a7a126bda5778236ec74ce2.pdf,2024-05-15T05:40:20.153000,2024-09-25T18:14:34.024000,2024-11-06T06:19:27.106000,https://openreview.net/forum?id=pR37AmwbOt,University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Pennsylvania State University; Nankai University; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences
1045,pGEY8JQ3qx,pGEY8JQ3qx,14527,Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs,"We study the sample complexity of learning an $\varepsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. For weakly communicating MDPs, we establish the complexity bound $\widetilde{O}\left(SA\frac{\mathsf{H}}{\varepsilon^2} \right)$, where $\mathsf{H}$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,\mathsf{H}$, and $\varepsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. We also initiate the study of sample complexity in general (multichain) average-reward MDPs. We argue a new transient time parameter $\mathsf{B}$ is necessary, establish an $\widetilde{O}\left(SA\frac{\mathsf{B} + \mathsf{H}}{\varepsilon^2} \right)$ complexity bound, and prove a matching (up to log factors) minimax lower bound. Both results are based on reducing the average-reward MDP to a discounted MDP, which requires new ideas in the general setting. To optimally analyze this reduction, we develop improved bounds for $\gamma$-discounted MDPs, showing that $\widetilde{O}\left(SA\frac{\mathsf{H}}{(1-\gamma)^2\varepsilon^2} \right)$ and $\widetilde{O}\left(SA\frac{\mathsf{B} + \mathsf{H}}{(1-\gamma)^2\varepsilon^2} \right)$ samples suffice to learn $\varepsilon$-optimal policies in weakly communicating and in general MDPs, respectively. Both these results circumvent the well-known minimax lower bound of $\widetilde{\Omega}\left(SA\frac{1}{(1-\gamma)^3\varepsilon^2} \right)$ for $\gamma$-discounted MDPs, and establish a quadratic rather than cubic horizon dependence for a fixed MDP instance.",Matthew Zurek; Yudong Chen,~Matthew_Zurek1; ~Yudong_Chen1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/2ff245e09d2ec82378e2aa6ffea57a9ec01c043c.pdf,2024-05-15T05:28:23.496000,2024-09-25T18:14:31.896000,2024-11-06T06:19:26.574000,https://openreview.net/forum?id=pGEY8JQ3qx,University of Wisconsin - Madison; University of Wisconsin - Madison
1066,uNKlTQ8mBD,uNKlTQ8mBD,14424,Learning Formal Mathematics From Intrinsic Motivation,"How did humanity coax mathematics from the aether? We explore the Platonic view that mathematics can be discovered from its axioms---a game of conjecture and proof. We describe an agent that jointly learns to pose challenging problems for itself (conjecturing) and solve them (theorem proving). Given a mathematical domain axiomatized in dependent type theory, we first combine methods for constrained decoding and type-directed synthesis to sample valid conjectures from a language model. Our method guarantees well-formed conjectures by construction, even as we start with a randomly initialized model. We use the same model to represent a policy and value function for guiding proof search. Our agent targets generating hard but provable conjectures --- a moving target, since its own theorem proving ability also improves as it trains. We propose novel methods for hindsight relabeling on proof search trees to significantly improve the agent's sample efficiency in both tasks. Experiments on 3 axiomatic domains (propositional logic, arithmetic and group theory) demonstrate that our agent can bootstrap from only the axioms, self-improving in generating true and challenging conjectures and in finding proofs.",Gabriel Poesia; David Broman; Nick Haber; Noah Goodman,~Gabriel_Poesia1; ~David_Broman1; ~Nick_Haber1; ~Noah_Goodman1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/42d3b14720041d447c657071a08de640733954a0.pdf,2024-05-15T05:10:48.858000,2024-09-25T18:14:29.029000,2024-11-06T06:19:25.709000,https://openreview.net/forum?id=uNKlTQ8mBD,Stanford University; KTH Royal Institute of Technology; Stanford University; Stanford University
1075,JyWAFGCJPl,JyWAFGCJPl,14368,Fine Tuning Out-of-Vocabulary Item Recommendation with User Sequence Imagination,"Recommending out-of-vocabulary (OOV) items is a challenging problem since the in-vocabulary (IV) items have well-trained behavioral embeddings but the OOV items only have content features. Current OOV recommendation models often generate 'makeshift' embeddings for OOV items from content features and then jointly recommend with the `makeshift' OOV item embeddings and the behavioral IV item embeddings. However, merely using the 'makeshift' embedding will result in suboptimal recommendation performance due to the substantial gap between the content feature and the behavioral embeddings. To bridge the gap, we propose a novel **User Sequence IMagination (USIM)** fine-tuning framework, which first imagines the user sequences and then refines the generated OOV embeddings with the user behavioral embeddings. Specifically, we frame the user sequence imagination as a reinforcement learning problem and develop a recommendation-focused reward function to evaluate to what extent a user can help recommend the OOV items. Besides, we propose an embedding-driven transition function to model the embedding transition after imaging a user. USIM has been deployed on a prominent e-commerce platform for months, offering recommendations for millions of OOV items and billions of users. Extensive experiments demonstrate that USIM outperforms traditional generative models in OOV item recommendation performance across traditional collaborative filtering and GNN-based collaborative filtering models.",Ruochen Liu; Hao Chen; Yuanchen Bei; Qijie Shen; Fangwei Zhong; Senzhang Wang; Jianxin Wang,~Ruochen_Liu5; ~Hao_Chen18; ~Yuanchen_Bei1; ~Qijie_Shen1; ~Fangwei_Zhong3; ~Senzhang_Wang2; ~Jianxin_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/bce6d564cb85e7281193357b8911576c79355256.pdf,2024-05-15T04:59:09.102000,2024-09-25T18:14:27.447000,2024-12-24T11:35:01.899000,https://openreview.net/forum?id=JyWAFGCJPl,Central South University; City University of Macao; Hong Kong Polytechnic University; Zhejiang University; Alibaba Group; Beijing Normal University; Peking University; Central South University; Central South University
1076,dlCTmEyq6y,dlCTmEyq6y,14367,Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data,"The premise of semi-supervised learning (SSL) is that combining labeled and unlabeled data yields significantly more accurate models.
Despite empirical successes, the theoretical understanding of SSL is still far from complete. 
In this work, we study SSL for high dimensional sparse Gaussian classification. 
To construct an accurate classifier a  key task is feature selection, detecting the few variables that separate the two classes.
For this SSL setting, we analyze information theoretic lower bounds for accurate feature selection as well as computational lower bounds, 
assuming the low-degree likelihood hardness conjecture. 
Our key contribution is the identification of a regime in the problem parameters (dimension, sparsity, number of labeled and unlabeled samples) where SSL is guaranteed to be advantageous for classification.
Specifically, there is a regime where it is possible to construct in polynomial time an accurate SSL classifier.
However, any computationally efficient supervised or unsupervised learning schemes, that separately use only the labeled or unlabeled data would fail.  
Our work highlights the provable benefits of combining labeled and unlabeled data for classification and feature selection in high dimensions. 
We present simulations that complement our theoretical analysis.",Eyar Azar; Boaz Nadler,~Eyar_Azar1; ~Boaz_Nadler2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/266ad38dd7db36a6cc250200fbe2a1107a08fc97.pdf,2024-05-15T04:58:56.732000,2024-09-25T18:14:27.387000,2024-11-06T06:19:25.245000,https://openreview.net/forum?id=dlCTmEyq6y,Weizmann Institute of Science; Weizmann Institute of Science
1103,b1ggjW00NI,b1ggjW00NI,14182,Don't Look Twice: Faster Video Transformers with Run-Length Tokenization,"Video transformers are slow to train due to extremely large numbers of input tokens, even though many video tokens are repeated over time. Existing methods to remove uninformative tokens either have significant overhead, negating any speedup, or require tuning for different datasets and examples. We present Run-Length Tokenization (RLT), a simple approach to speed up video transformers inspired by run-length encoding for data compression. RLT efficiently finds and removes `runs' of patches that are repeated over time before model inference, then replaces them with a single patch and a positional encoding to represent the resulting token's new length. 
Our method is content-aware, requiring no tuning for different datasets, and fast, incurring negligible overhead. 
RLT yields a large speedup in training, reducing the wall-clock time to fine-tune a video transformer by 30% while matching baseline model performance. RLT also works without training, increasing model throughput by 35% with only 0.1% drop in accuracy.
RLT speeds up training at 30 FPS by more than 100%, and on longer video datasets, can reduce the token count by up to 80\%. Our project page is at  rccchoudhury.github.io/projects/rlt.",Rohan Choudhury; Guanglei Zhu; Sihan Liu; Koichiro Niinuma; Kris M. Kitani; Laszlo Attila Jeni,~Rohan_Choudhury1; ~Guanglei_Zhu1; ~Sihan_Liu3; ~Koichiro_Niinuma1; ~Kris_M._Kitani1; ~Laszlo_Attila_Jeni1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/dd99432c8f2dff551850e041e3841a2d75932e8c.pdf,2024-05-15T04:24:58.426000,2024-09-25T18:14:22.567000,2024-11-06T06:19:24.102000,https://openreview.net/forum?id=b1ggjW00NI,Meta; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Fujitsu Research and Development Center; Meta; Carnegie Mellon University; Carnegie Mellon University
1105,ektPEcqGLb,ektPEcqGLb,14174,Poisson Variational Autoencoder,"Variational autoencoders (VAE) employ Bayesian inference to interpret sensory inputs, mirroring processes that occur in primate vision across both ventral (Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways. Despite their success, traditional VAEs rely on continuous latent variables, which significantly deviates from the discrete nature of biological neurons. Here, we developed the Poisson VAE (P-VAE), a novel architecture that combines principles of predictive coding with a VAE that encodes inputs into discrete spike counts. Combining Poisson-distributed latent variables with predictive coding introduces a metabolic cost term in the model loss function, suggesting a relationship with sparse coding which we verify empirically. Additionally, we analyze the geometry of learned representations, contrasting the P-VAE to alternative VAE models. We find that the P-VAE encodes its inputs in relatively higher dimensions, facilitating linear separability of categories in a downstream classification task with a much better (5x) sample efficiency. Our work provides an interpretable computational framework to study brain-like sensory processing and paves the way for a deeper understanding of perception as an inferential process.",Hadi Vafaii; Dekel Galor; Jacob L. Yates,~Hadi_Vafaii1; ~Dekel_Galor1; ~Jacob_L._Yates1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/69d52ba3321603d15a0f74c21d108f4a11c54a36.pdf,2024-05-15T04:23:40.535000,2024-09-25T18:14:22.342000,2024-12-18T19:19:21.107000,https://openreview.net/forum?id=ektPEcqGLb,"University of California, Berkeley; University of California, Berkeley"
1119,181llen2gw,181llen2gw,14102,A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks,"Recent advancements in Vision-Language Models (VLMs) have enabled complex multimodal tasks by processing text and image data simultaneously, significantly enhancing the field of artificial intelligence. However, these models often exhibit biases that can skew outputs towards societal stereotypes, thus necessitating debiasing strategies. Existing debiasing methods focus narrowly on specific modalities or tasks, and require extensive retraining. To address these limitations, this paper introduces Selective Feature Imputation for Debiasing (SFID), a novel methodology that integrates feature pruning and low confidence imputation (LCI) to effectively reduce biases in VLMs. SFID is versatile, maintaining the semantic integrity of outputs and costly effective by eliminating the need for retraining. Our experimental results demonstrate SFID's effectiveness across various VLMs tasks including zero-shot classification, text-to-image retrieval, image captioning, and text-to-image generation, by significantly reducing gender biases without compromising performance. This approach not only enhances the fairness of VLMs applications but also preserves their efficiency and utility across diverse scenarios.",Hoin Jung; Taeuk Jang; Xiaoqian Wang,~Hoin_Jung1; ~Taeuk_Jang1; ~Xiaoqian_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,fairness,/pdf/8d1d58bf7953e0d1fc2af278c6cf93dc439fa093.pdf,2024-05-15T04:07:24.328000,2024-09-25T18:14:20.292000,2024-11-06T06:19:23.399000,https://openreview.net/forum?id=181llen2gw,Purdue University; Amazon; Purdue University; Purdue University
1129,ziehA15y8k,ziehA15y8k,14020,Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement Learning,"Adversarial attacks against graph neural networks (GNNs) through perturbations of the graph structure are increasingly common in social network tasks like rumor detection. Social media platforms capture diverse attack sequence samples through both machine and manual screening processes. Investigating effective ways to leverage these adversarial samples to enhance robustness is imperative. We improve the maximum entropy inverse reinforcement learning (IRL) method with the mixture-of-experts approach to address multi-source graph adversarial attacks. This method reconstructs the attack policy, integrating various attack models and providing feature-level explanations, subsequently generating additional adversarial samples to fortify the robustness of detection models. We develop precise sample guidance and a bidirectional update mechanism to reduce the deviation caused by imprecise feature representation and negative sampling within the large action space of social graphs, while also accelerating policy learning. We take rumor detector as an example targeted GNN model on real-world rumor datasets. By utilizing a small subset of samples generated by various graph adversarial attack methods, we reconstruct the attack policy, closely approximating the performance of the original attack method. We validate that samples generated by the learned policy enhance model robustness through adversarial training and data augmentation.",Yuefei Lyu; Chaozhuo Li; Sihong Xie; Xi Zhang,~Yuefei_Lyu1; ~Chaozhuo_Li1; ~Sihong_Xie1; ~Xi_Zhang12,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/8a54fe72827cc6095b89937198d8112de7d53f3d.pdf,2024-05-15T03:54:17.269000,2024-09-25T18:14:17.858000,2024-11-06T06:19:22.996000,https://openreview.net/forum?id=ziehA15y8k,Beijing University of Posts and Telecommunications; Hong Kong University of Science and Technology(Guangzhou); Beijing University of Posts and Telecommunications
1151,fqmSGK8C0B,fqmSGK8C0B,13914,Deep Learning for Computing Convergence Rates of Markov Chains,"Convergence rate analysis for general state-space Markov chains is fundamentally important in operations research (stochastic systems) and machine learning (stochastic optimization). This problem, however, is notoriously difficult because traditional analytical methods often do not generate practically useful convergence bounds for realistic Markov chains. We propose the Deep Contractive Drift Calculator (DCDC), the first general-purpose sample-based algorithm for bounding the convergence of Markov chains to stationarity in Wasserstein distance. The DCDC has two components. First, inspired by the new convergence analysis framework in (Qu et.al, 2023), we introduce the Contractive Drift Equation (CDE), the solution of which leads to an explicit convergence bound. Second, we develop an efficient neural-network-based CDE solver. Equipped with these two components, DCDC solves the CDE and converts the solution into a convergence bound. We analyze the sample complexity of the algorithm and further demonstrate the effectiveness of the DCDC by generating convergence bounds for realistic Markov chains arising from stochastic processing networks as well as constant step-size stochastic optimization.",Yanlin Qu; Jose Blanchet; Peter Glynn,~Yanlin_Qu1; ~Jose_Blanchet1; ~Peter_Glynn2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/71520aac56c6d400a454b10c65ff7bfb01f09cd3.pdf,2024-05-15T03:35:23.830000,2024-09-25T18:14:14.560000,2024-11-06T06:19:22.119000,https://openreview.net/forum?id=fqmSGK8C0B,Stanford University; Columbia Business School
1173,loMa99A4p8,loMa99A4p8,13843,Diffusion Models With Learned Adaptive Noise,"Diffusion models have gained traction as powerful algorithms for synthesizing high-quality images. Central to these algorithms is the diffusion process, a set of equations which maps data to noise 
in a way that can significantly affect performance. 
In this paper, we explore whether the diffusion
process can be learned from data.
Our work is grounded in Bayesian inference and seeks to improve log-likelihood estimation by casting the learned diffusion process as an approximate variational posterior that yields a tighter lower bound (ELBO) on the likelihood.
A widely held assumption is that the ELBO is invariant to the noise process: our work dispels this assumption and proposes multivariate learned adaptive noise (MuLAN), a learned diffusion process that applies noise at different rates across an image. Our method consists of three components: a multivariate noise schedule, adaptive input-conditional diffusion, and auxiliary variables; these components ensure that the ELBO is no longer invariant to the choice of the noise schedule as in previous works.  Empirically, MuLAN sets a new **state-of-the-art** in density estimation on CIFAR-10 and ImageNet while matching the performance of previous state-of-the-art models with **50%** fewer steps.  We provide the code, along with a blog post and video tutorial on the project page: https://s-sahoo.com/MuLAN",Subham Sekhar Sahoo; Aaron Gokaslan; Christopher De Sa; Volodymyr Kuleshov,~Subham_Sekhar_Sahoo1; ~Aaron_Gokaslan1; ~Christopher_De_Sa2; ~Volodymyr_Kuleshov1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/dde73f70550a3352ef5e2ea68d6a2803649c09eb.pdf,2024-05-15T03:24:45.264000,2024-09-25T18:14:12.175000,2024-11-06T06:19:20.985000,https://openreview.net/forum?id=loMa99A4p8,Cornell University; Cornell University; Together AI; Cornell University; Cornell University
1194,seAuMedrm5,seAuMedrm5,13743,Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers,"Modern systems for automatic speech recognition, including the RNN-Transducer and Attention-based Encoder-Decoder (AED), are designed so that the encoder is not required to alter the time-position of information from the audio sequence into the embedding; alignment to the final text output is processed during decoding. We discover that the transformer-based encoder adopted in recent years is actually capable of performing the alignment internally during the forward pass, prior to decoding. This new phenomenon enables a simpler and more efficient model, the ''Aligner-Encoder''. To train it, we discard the dynamic programming of RNN-T in favor of the frame-wise cross-entropy loss of AED, while the decoder employs the lighter text-only recurrence of RNN-T without learned cross-attention---it simply scans embedding frames in order from the beginning, producing one token each until predicting the end-of-message. We conduct experiments demonstrating performance remarkably close to the state of the art, including a special inference configuration enabling long-form recognition. In a representative comparison, we measure the total inference time for our model to be 2x faster than RNN-T and 16x faster than AED.  Lastly, we find that the audio-text alignment is clearly visible in the self-attention weights of a certain layer, which could be said to perform ''self-transduction''.",Adam Stooke; Rohit Prabhavalkar; Khe Chai Sim; Pedro J Moreno Mengibar,~Adam_Stooke3; ~Rohit_Prabhavalkar1; ~Khe_Chai_Sim1; ~Pedro_J_Moreno_Mengibar1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,speech_and_audio,/pdf/11159878c4995c45c2677ccd7b2f5bbccb14fb0b.pdf,2024-05-15T03:09:44.643000,2024-09-25T18:14:08.763000,2024-11-06T06:19:20.092000,https://openreview.net/forum?id=seAuMedrm5,
1205,MN4nt01TeO,MN4nt01TeO,13697,Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences,"We propose Adaptive Randomized Smoothing (ARS) to certify the predictions of our test-time adaptive models against adversarial examples.
ARS extends the analysis of randomized smoothing using $f$-Differential Privacy to certify the adaptive composition of multiple steps.
For the first time, our theory covers the sound adaptive composition of general and high-dimensional functions of noisy inputs.
We instantiate ARS on deep image classification to certify predictions against adversarial examples of bounded $L_{\infty}$ norm.
In the $L_{\infty}$ threat model, ARS enables flexible adaptation through high-dimensional input-dependent masking.
We design adaptivity benchmarks, based on CIFAR-10 and CelebA, and show that ARS improves standard test accuracy by  1 to 15\% points.
On ImageNet, ARS improves certified test accuracy by up to 1.6% points over standard RS without adaptivity. Our code is available at [https://github.com/ubc-systopia/adaptive-randomized-smoothing](https://github.com/ubc-systopia/adaptive-randomized-smoothing).",Saiyue Lyu; Shadab Shaikh; Frederick Shpilevskiy; Evan Shelhamer; Mathias Lécuyer,~Saiyue_Lyu1; ~Shadab_Shaikh1; ~Frederick_Shpilevskiy1; ~Evan_Shelhamer2; ~Mathias_Lécuyer2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/4e8c2eeb8e6a10b583f49ab7ebc7d1be83c64e6f.pdf,2024-05-15T03:03:39.266000,2024-09-25T18:14:07.181000,2025-01-17T22:52:21.719000,https://openreview.net/forum?id=MN4nt01TeO,University of British Columbia; University of British Columbia; University of British Columbia; Google; University of British Columbia
1211,OIsUWQSvkD,OIsUWQSvkD,13635,Identifying Causal Effects Under Functional Dependencies,"We study the identification of causal effects, motivated by two improvements to identifiability which can be attained if one knows that some variables in a causal graph are functionally determined by their parents (without needing to know the specific functions). First, an unidentifiable causal effect may become identifiable when certain variables are functional. Second, certain functional variables can be excluded from being observed without affecting the identifiability of a causal effect, which may significantly reduce the number of needed variables in observational data. Our results are largely based on an elimination procedure which removes functional variables from a causal graph while preserving key properties in the resulting causal graph, including the identifiability of causal effects.",Yizuo Chen; Adnan Darwiche,~Yizuo_Chen1; ~Adnan_Darwiche1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,causal_inference,/pdf/518f2d5734d4a036ab2ea8675c6e83a7c11eb342.pdf,2024-05-15T02:54:04.447000,2024-09-25T18:14:05.407000,2024-11-06T06:19:19.399000,https://openreview.net/forum?id=OIsUWQSvkD,
1223,zeYyq0GpXO,zeYyq0GpXO,13571,Exploring Context Window of Large Language Models via Decomposed Positional Vectors,"Transformer-based large language models (LLMs) typically have a limited context window, resulting in significant performance degradation when processing text beyond the length of the context window. Extensive studies have been proposed to extend the context window and achieve length extrapolation of LLMs, but there is still a lack of in-depth interpretation of these approaches. In this study, we explore the positional information within and beyond the context window for deciphering the underlying mechanism of LLMs. By using a mean-based decomposition method, we disentangle positional vectors from hidden states of LLMs and analyze their formation and effect on attention. Furthermore, when texts exceed the context window, we analyze the change of positional vectors in two settings, i.e., direct extrapolation and context window extension. Based on our findings, we design two training-free context window extension methods, positional vector replacement and attention window extension. Experimental results show that our methods can effectively extend the context window length.",zican Dong; Junyi Li; Xin Men; Xin Zhao; Bingning Wang; Zhen Tian; weipeng chen; Ji-Rong Wen,~zican_Dong1; ~Junyi_Li4; ~Xin_Men1; ~Xin_Zhao10; ~Bingning_Wang3; ~Zhen_Tian1; ~weipeng_chen2; ~Ji-Rong_Wen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/93def3ab0f03ff754a0ecc781166fd37fd5b563c.pdf,2024-05-15T02:40:52.372000,2024-09-25T18:14:03.517000,2024-11-06T06:19:18.840000,https://openreview.net/forum?id=zeYyq0GpXO,Renmin University of China; National University of Singapore; Renmin University of China; Renmin University of China; Baichuan Inc.; Renmin University of China; Baichuan Inc.; Renmin University of China
1227,kEQFjKqiqM,kEQFjKqiqM,13553,Distributed-Order Fractional Graph Operating Network,"We introduce the Distributed-order fRActional Graph Operating Network (DRAGON), a novel continuous Graph Neural Network (GNN) framework that incorporates distributed-order fractional calculus. 
Unlike traditional continuous GNNs that utilize integer-order or single fractional-order differential equations, DRAGON uses a learnable probability distribution over a range of real numbers for the derivative orders. 
By allowing a flexible and learnable superposition of multiple derivative orders, our framework captures complex graph feature updating dynamics beyond the reach of conventional models.
We provide a comprehensive interpretation of our framework's capability to capture intricate dynamics through the lens of a non-Markovian graph random walk with node feature updating driven by an anomalous diffusion process over the graph. 
Furthermore, to highlight the versatility of the DRAGON framework, we conduct empirical evaluations across a range of graph learning tasks. The results consistently demonstrate superior performance when compared to traditional continuous GNN models. The implementation code is available at \url{https://github.com/zknus/NeurIPS-2024-DRAGON}.",Kai Zhao; Xuhao Li; Qiyu Kang; Feng Ji; Qinxu Ding; Yanan Zhao; Wenfei Liang; Wee Peng Tay,~Kai_Zhao7; ~Xuhao_Li2; ~Qiyu_Kang2; ~Feng_Ji2; ~Qinxu_Ding1; ~Yanan_Zhao1; ~Wenfei_Liang1; ~Wee_Peng_Tay1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/c82624477e33c3427be1e4c8b9093f4e5714ff96.pdf,2024-05-15T02:38:29.615000,2024-09-25T18:14:02.842000,2024-11-06T06:19:18.665000,https://openreview.net/forum?id=kEQFjKqiqM,Nanyang Technological University; University of Science and Technology of China; Nanyang Technological University; Singapore University of Social Sciences; Nanyang Technological University; Nanyang Technological University; Nanyang Technological University
1234,XCkII8nCt3,XCkII8nCt3,13512,Non-asymptotic Approximation Error Bounds of Parameterized Quantum Circuits,"Understanding the power of parameterized quantum circuits (PQCs) in accomplishing machine learning tasks is one of the most important questions in quantum machine learning. In this paper, we focus on the PQC expressivity for general multivariate function classes. Previously established Universal Approximation Theorems for PQCs are either nonconstructive or assisted with parameterized classical data processing, making it hard to justify whether the expressive power comes from the classical or quantum parts. We explicitly construct data re-uploading PQCs for approximating multivariate polynomials and smooth functions and establish the first non-asymptotic approximation error bounds for such functions in terms of the number of qubits, the quantum circuit depth and the number of trainable parameters of the PQCs. Notably, we show that for multivariate polynomials and multivariate smooth functions, the quantum circuit size and the number of trainable parameters of our proposed PQCs can be smaller than the deep ReLU neural networks. We further demonstrate the approximation capability of PQCs via numerical experiments. Our results pave the way for designing practical PQCs that can be implemented on near-term quantum devices with limited resources.",Zhan Yu; Qiuhao Chen; Yuling Jiao; Yinan Li; Xiliang Lu; Xin Wang; Jerry Zhijian Yang,~Zhan_Yu3; ~Qiuhao_Chen1; ~Yuling_Jiao1; ~Yinan_Li7; ~Xiliang_Lu1; ~Xin_Wang48; ~Jerry_Zhijian_Yang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/1ee8ed6762c51163b940cb8aa20cebc8452854aa.pdf,2024-05-15T02:31:39.636000,2024-09-25T18:14:01.321000,2024-11-06T06:19:18.391000,https://openreview.net/forum?id=XCkII8nCt3,National University of Singapore; Wuhan University; Wuhan University; Hong Kong University of Science and Technology(Guangzhou)
1236,aeYNVtTo7o,aeYNVtTo7o,13499,Cell ontology guided transcriptome foundation model,"Transcriptome foundation models (TFMs) hold great promises of deciphering the transcriptomic language that dictate diverse cell functions by self-supervised learning on large-scale single-cell gene expression data, and ultimately unraveling the complex mechanisms of human diseases. However, current TFMs treat cells as independent samples and ignore the taxonomic relationships between cell types, which are available in cell ontology graphs. We argue that effectively leveraging this ontology information during the TFM pre-training can improve learning biologically meaningful gene co-expression patterns while preserving TFM as a general purpose foundation model for downstream zero-shot and fine-tuning tasks. To this end, we present **s**ingle **c**ell, **Cell**-**o**ntology guided TFM (scCello). We introduce cell-type coherence loss and ontology alignment loss, which are minimized along with the masked gene expression prediction loss during the pre-training. The novel loss component guide scCello to learn the cell-type-specific representation and the structural relation between cell types from the cell ontology graph, respectively. We pre-trained scCello on 22 million cells from CellxGene database leveraging their cell-type labels mapped to the cell ontology graph from Open Biological and Biomedical Ontology Foundry. Our TFM demonstrates competitive generalization and transferability performance over the existing TFMs on biologically important tasks including identifying novel cell types of unseen cells, prediction of cell-type-specific marker genes, and cancer drug responses. Source code and model
weights are available at https://github.com/DeepGraphLearning/scCello.",Xinyu Yuan; Zhihao Zhan; Zuobai Zhang; Manqi Zhou; Jianan Zhao; Boyu Han; Yue Li; Jian Tang,~Xinyu_Yuan2; ~Zhihao_Zhan1; ~Zuobai_Zhang1; ~Manqi_Zhou1; ~Jianan_Zhao2; ~Boyu_Han2; ~Yue_Li15; ~Jian_Tang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_healthcare,/pdf/919042e739897111ff32bf1d14ee96491face15e.pdf,2024-05-15T02:30:20.017000,2024-09-25T18:14:01.038000,2024-12-21T17:06:58.398000,https://openreview.net/forum?id=aeYNVtTo7o,Montreal Institute of Learning Algorithms; Montreal Institute of Learning Algorithms; NVIDIA; Montreal Institute of Learning Algorithms; Stanford University; McGill University
1240,S2P6KPLtm8,S2P6KPLtm8,13457,Identification and Estimation of the Bi-Directional MR with Some Invalid Instruments,"We consider the challenging problem of estimating causal effects from purely observational data in the bi-directional Mendelian randomization (MR), where some invalid instruments, as well as unmeasured confounding, usually exist. 
To address this problem, most existing methods attempt to find proper valid instrumental variables (IVs) for the target causal effect by expert knowledge or by assuming that the causal model is a one-directional MR model. 
As such, in this paper, we first theoretically investigate the identification of the bi-directional MR from observational data. In particular, we provide necessary and sufficient conditions under which valid IV sets are correctly identified such that the bi-directional MR model is identifiable, including the causal directions of a pair of phenotypes (i.e., the treatment and outcome).
Moreover, based on the identification theory, we develop a cluster fusion-like method to discover valid IV sets and estimate the causal effects of interest.
We theoretically demonstrate the correctness of the proposed algorithm.
Experimental results show the effectiveness of our method for estimating causal effects in both one-directional and bi-directional MR models.",Feng Xie; Zhen Yao; Lin Xie; Yan Zeng; Zhi Geng,~Feng_Xie1; ~Zhen_Yao3; ~Lin_Xie2; ~Yan_Zeng2; ~Zhi_Geng1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,causal_inference,/pdf/dcf44aa45df10d6f2ff0dfe02f73d706b6c8b903.pdf,2024-05-15T02:23:36.084000,2024-09-25T18:14:00.115000,2025-01-14T08:36:22.772000,https://openreview.net/forum?id=S2P6KPLtm8,Beijing University of Technology; Beijing University of Technology; Beijing University of Technology; Peking University; Beijing University of Technology
1248,eNM94i7R3A,eNM94i7R3A,13402,Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning,"While the impressive performance of modern neural networks is often attributed to their capacity to efficiently extract task-relevant features from data, the mechanisms underlying this *rich feature learning regime* remain elusive, with much of our theoretical understanding stemming from the opposing *lazy regime*. In this work, we derive exact solutions to a minimal model that transitions between lazy and rich learning, precisely elucidating how unbalanced *layer-specific* initialization variances and learning rates determine the degree of feature learning. Our analysis reveals that they conspire to influence the learning regime through a set of conserved quantities that constrain and modify the geometry of learning trajectories in parameter and function space. We extend our analysis to more complex linear models with multiple neurons, outputs, and layers and to shallow nonlinear networks with piecewise linear activation functions. In linear networks, rapid feature learning only occurs from balanced initializations, where all layers learn at similar speeds. While in nonlinear networks, unbalanced initializations that promote faster learning in earlier layers can accelerate rich learning. Through a series of experiments, we provide evidence that this unbalanced rich regime drives feature learning in deep finite-width networks, promotes interpretability of early layers in CNNs, reduces the sample complexity of learning hierarchical data, and decreases the time to grokking in modular arithmetic. Our theory motivates further exploration of unbalanced initializations to enhance efficient feature learning.",Daniel Kunin; Allan Raventos; Clémentine Carla Juliette Dominé; Feng Chen; David Klindt; Andrew M Saxe; Surya Ganguli,~Daniel_Kunin1; ~Allan_Raventos1; ~Clémentine_Carla_Juliette_Dominé1; ~Feng_Chen13; ~David_Klindt1; ~Andrew_M_Saxe1; ~Surya_Ganguli1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/b9cb4ee2820cac616b46d51306aa640e3b799c66.pdf,2024-05-15T02:14:20.558000,2024-09-25T18:13:58.290000,2024-11-06T06:19:17.825000,https://openreview.net/forum?id=eNM94i7R3A,University College London; Stanford University; University College London
1261,V0oJaLqY4E,V0oJaLqY4E,13338,Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models,"We present a maximum entropy inverse reinforcement learning (IRL) approach for improving the sample quality of diffusion generative models, especially when the number of generation time steps is small. Similar to how IRL trains a policy based on the reward function learned from expert demonstrations, we train (or fine-tune) a diffusion model using the log probability density estimated from training data. 
Since we employ an energy-based model (EBM) to represent the log density, our approach boils down to the joint training of a diffusion model and an EBM. Our IRL formulation, named Diffusion by Maximum Entropy IRL (DxMI), is a minimax problem that reaches equilibrium when both models converge to the data distribution. The entropy maximization plays a key role in DxMI, facilitating the exploration of the diffusion model and ensuring the convergence of the EBM. We also propose Diffusion by Dynamic Programming (DxDP), a novel reinforcement learning algorithm for diffusion models, as a subroutine in DxMI. DxDP makes the diffusion model update in DxMI efficient by transforming the original problem into an optimal control formulation where value functions replace back-propagation in time. Our empirical studies show that diffusion models fine-tuned using DxMI can generate high-quality samples in as few as 4 and 10 steps.  Additionally, DxMI enables the training of an EBM without MCMC, stabilizing EBM training dynamics and enhancing anomaly detection performance.",Sangwoong Yoon; Himchan Hwang; Dohyun Kwon; Yung-Kyun Noh; Frank C. Park,~Sangwoong_Yoon1; ~Himchan_Hwang1; ~Dohyun_Kwon1; ~Yung-Kyun_Noh1; ~Frank_C._Park1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,generative_models,/pdf/fbd48eb1b53fd48de22ddd59edf0d18875315635.pdf,2024-05-15T02:02:05.168000,2024-09-25T18:13:56.280000,2024-11-06T06:19:17.320000,https://openreview.net/forum?id=V0oJaLqY4E,Korea Institute for Advanced Study; University of Seoul; Seoul National University
1280,lV4kTHTgpJ,lV4kTHTgpJ,13260,Model Fusion through Bayesian Optimization in Language Model Fine-Tuning,"Fine-tuning pre-trained models for downstream tasks is a widely adopted technique known for its adaptability and reliability across various domains. Despite its conceptual simplicity, fine-tuning entails several troublesome engineering choices, such as selecting hyperparameters and determining checkpoints from an optimization trajectory. To tackle the difficulty of choosing the best model, one effective solution is model fusion, which combines multiple models in a parameter space. However, we observe a large discrepancy between loss and metric landscapes during the fine-tuning of pre-trained language models. Building on this observation, we introduce a novel model fusion technique that optimizes both the desired metric and loss through multi-objective Bayesian optimization. In addition, to effectively select hyperparameters, we establish a two-stage procedure by integrating Bayesian optimization processes into our framework. Experiments across various downstream tasks show considerable performance improvements using our Bayesian optimization-guided method.",Chaeyun Jang; Hyungi Lee; Jungtaek Kim; Juho Lee,~Chaeyun_Jang1; ~Hyungi_Lee1; ~Jungtaek_Kim1; ~Juho_Lee2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/a0c73d1c1962cefda48e9b0e93288b862aad428a.pdf,2024-05-15T01:45:46.471000,2024-09-25T18:13:53.552000,2024-12-27T04:23:04.248000,https://openreview.net/forum?id=lV4kTHTgpJ,Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; University of Pittsburgh; University of Wisconsin - Madison; Korea Advanced Institute of Science and Technology
1281,8KPyJm4gt5,8KPyJm4gt5,13257,Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning,"Imitation learning (IL) aims to mimic the behavior of an expert in a sequential decision making task by learning from demonstrations, and has been widely applied to robotics, autonomous driving, and autoregressive text generation. The simplest approach to IL, behavior cloning (BC) is thought to incur sample complexity with unfavorable quadratic dependence on the problem horizon, motivating a variety of different online algorithms that attain improved linear horizon dependence under stronger assumptions on the data and the learner’s access to the expert. 

We revisit the apparent gap between offline and online IL from a learning-theoretic perspective, with a focus on general policy classes up to and including deep neural networks. Through a new analysis of BC with the logarithmic loss, we show that it is possible to achieve horizon-independent sample complexity in offline IL whenever (i) the range of the cumulative payoffs is controlled, and (ii) an appropriate notion of supervised learning complexity for the policy class is controlled. Specializing our results to deterministic, stationary policies, we show that the gap between offline and online IL is not fundamental: (i) it is possible to achieve linear dependence on horizon in offline IL under dense rewards (matching what was previously only known to be achievable in online IL); and (ii) without further assumptions on the policy class, online IL cannot improve over offline IL with the logarithmic loss, even in benign MDPs. We complement our theoretical results with experiments on standard RL tasks and autoregressive language generation to validate the practical relevance of our findings.",Dylan J Foster; Adam Block; Dipendra Misra,~Dylan_J_Foster1; ~Adam_Block1; ~Dipendra_Misra1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/35b6f0ccafd8894a3060f640ea7a24f2f4a405ba.pdf,2024-05-15T01:44:43.955000,2024-09-25T18:13:53.367000,2024-11-06T06:19:16.468000,https://openreview.net/forum?id=8KPyJm4gt5,"Microsoft; Microsoft; Massachusetts Institute of Technology; Microsoft; Databricks, Databricks"
1288,UdxpjKO2F9,UdxpjKO2F9,13226,Improving Environment Novelty Quantification for Effective Unsupervised Environment Design,"Unsupervised Environment Design (UED) formalizes the problem of autocurricula through interactive training between a teacher agent and a student agent. The teacher generates new training environments with high learning potential, curating an adaptive curriculum that strengthens the student's ability to handle unseen scenarios. Existing UED methods mainly rely on *regret*, a metric that measures the difference between the agent's optimal and actual performance, to guide curriculum design. Regret-driven methods generate curricula that progressively increase environment complexity for the student but overlook environment *novelty* — a critical element for enhancing an agent's generalizability. Measuring environment novelty is especially challenging due to the underspecified nature of environment parameters in UED, and existing approaches face significant limitations. To address this, this paper introduces the *Coverage-based Evaluation of Novelty In Environment* (CENIE) framework. CENIE proposes a scalable, domain-agnostic, and curriculum-aware approach to quantifying environment novelty by leveraging the student's state-action space coverage from previous curriculum experiences. We then propose an implementation of CENIE that models this coverage and measures environment novelty using Gaussian Mixture Models. By integrating both regret and novelty as complementary objectives for curriculum design, CENIE facilitates effective exploration across the state-action space while progressively increasing curriculum complexity. Empirical evaluations demonstrate that augmenting existing regret-based UED algorithms with CENIE achieves state-of-the-art performance across multiple benchmarks, underscoring the effectiveness of novelty-driven autocurricula for robust generalization.",Jayden Teoh; Wenjun Li; Pradeep Varakantham,~Jayden_Teoh1; ~Wenjun_Li1; ~Pradeep_Varakantham1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/395c3c5df43310736f6134ab07ff32330b2a8f45.pdf,2024-05-15T01:36:22.886000,2024-09-25T18:13:52.479000,2024-12-18T20:56:41.685000,https://openreview.net/forum?id=UdxpjKO2F9,Singapore Management University; Singapore Management University; Singapore Management University
1306,LnNfwc2Ah1,LnNfwc2Ah1,13143,Tolerant Algorithms for Learning with Arbitrary Covariate Shift,"We study the problem of learning under arbitrary distribution shift, where the learner is trained on a labeled set from one distribution but evaluated on a different, potentially adversarially generated test distribution. We focus on two frameworks: *PQ learning* [GKKM'20], allowing abstention on adversarially generated parts of the test distribution, and *TDS learning* [KSV'23], permitting abstention on the entire test distribution if distribution shift is detected. All prior known algorithms either rely on learning primitives that are computationally hard even for simple function classes, or end up abstaining entirely even in the presence of a tiny amount of distribution shift.
   
   We address both these challenges for natural function classes, including intersections of halfspaces and decision trees, and standard training distributions, including Gaussians. For PQ learning, we give efficient learning algorithms, while for TDS learning, our algorithms can tolerate moderate amounts of distribution shift. At the core of our approach is an improved analysis of spectral outlier-removal techniques from learning with nasty noise. 
   Our analysis can (1) handle arbitrarily large fraction of outliers, which is crucial for handling arbitrary distribution shifts, and (2) obtain stronger bounds on polynomial moments of the distribution after outlier removal, yielding new insights into polynomial regression under distribution shifts. Lastly, our techniques lead to novel results for tolerant *testable learning* [RV'23], and learning with nasty noise.",Surbhi Goel; Abhishek Shetty; Konstantinos Stavropoulos; Arsen Vasilyan,~Surbhi_Goel1; ~Abhishek_Shetty1; ~Konstantinos_Stavropoulos1; ~Arsen_Vasilyan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/c52fe2324af069b899b2e4514c1334dd932eb7f0.pdf,2024-05-15T01:13:37.162000,2024-09-25T18:13:49.910000,2024-11-06T06:19:15.386000,https://openreview.net/forum?id=LnNfwc2Ah1,"University of Pennsylvania; Massachusetts Institute of Technology; The University of Texas at Austin; Massachusetts Institute of Technology; University of California, Berkeley"
1322,SxRblm9aMs,SxRblm9aMs,13057,Are Graph Neural Networks Optimal Approximation Algorithms?,"In this work we design graph neural network architectures that capture optimal
approximation algorithms for a large class of combinatorial optimization problems,
using powerful algorithmic tools from semidefinite programming (SDP). Concretely, we prove that polynomial-sized message-passing algorithms can represent
the most powerful polynomial time algorithms for Max Constraint Satisfaction
Problems assuming the Unique Games Conjecture. We leverage this result to
construct efficient graph neural network architectures, OptGNN, that obtain high quality approximate solutions on landmark combinatorial optimization problems
such as Max-Cut, Min-Vertex-Cover, and Max-3-SAT. Our approach achieves
strong empirical results across a wide range of real-world and synthetic datasets
against solvers and neural baselines. Finally, we take advantage of OptGNN’s
ability to capture convex relaxations to design an algorithm for producing bounds
on the optimal solution from the learned embeddings of OptGNN.",Morris Yau; Nikolaos Karalias; Eric Hanqing Lu; Jessica Xu; Stefanie Jegelka,~Morris_Yau3; ~Nikolaos_Karalias1; ~Eric_Hanqing_Lu1; ~Jessica_Xu1; ~Stefanie_Jegelka3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/651568ff30d22d475ca6e3ed3d7fe34d455359df.pdf,2024-05-15T00:49:22.106000,2024-09-25T18:13:47.249000,2024-11-06T06:19:14.777000,https://openreview.net/forum?id=SxRblm9aMs,Massachusetts Institute of Technology; Harvard University; Technical University of Munich; Massachusetts Institute of Technology
1324,dA7hUm4css,dA7hUm4css,13052,One-Shot Safety Alignment for Large Language Models via Optimal Dualization,"The growing safety concerns surrounding large language models raise an urgent need to align them with diverse human preferences to simultaneously enhance their helpfulness and safety. A promising approach is to enforce safety constraints through Reinforcement Learning from Human Feedback (RLHF). For such constrained RLHF, typical Lagrangian-based primal-dual policy optimization methods are computationally expensive and often unstable. This paper presents a perspective of dualization that  reduces constrained alignment to an equivalent unconstrained alignment problem. We do so by pre-optimizing a smooth and convex dual function that has a closed form. This shortcut eliminates the need for cumbersome primal-dual policy iterations, greatly reducing the computational burden and improving training stability. Our strategy leads to two practical algorithms in model-based and preference-based settings (MoCAN and PeCAN, respectively). A broad range of experiments demonstrate the effectiveness and merits of our algorithms.",Xinmeng Huang; Shuo Li; Edgar Dobriban; Osbert Bastani; Hamed Hassani; Dongsheng Ding,~Xinmeng_Huang1; ~Shuo_Li7; ~Edgar_Dobriban2; ~Osbert_Bastani1; ~Hamed_Hassani2; ~Dongsheng_Ding1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/fdc7e583d336527af558bd637debab384dcf6c50.pdf,2024-05-15T00:48:06.248000,2024-09-25T18:13:47.071000,2024-11-06T06:19:14.659000,https://openreview.net/forum?id=dA7hUm4css,University of Pennsylvania; Amazon; University of Pennsylvania; University of Pennsylvania; University of Pennsylvania; University of Pennsylvania
1329,TBVLQjdFcA,TBVLQjdFcA,13022,Generated and Pseudo Content guided Prototype Refinement for Few-shot Point Cloud Segmentation,"Few-shot 3D point cloud semantic segmentation aims to segment query point clouds with only a few annotated support point clouds. Existing prototype-based methods learn prototypes from the 3D support set to guide the segmentation of query point clouds. However, they encounter the challenge of low prototype quality due to constrained semantic information in the 3D support set and class information bias between support and query sets. To address these issues, in this paper, we propose a novel framework called Generated and Pseudo Content guided Prototype Refinement (GPCPR), which explicitly leverages LLM-generated content and reliable query context to enhance prototype quality. GPCPR achieves prototype refinement through two core components: LLM-driven Generated Content-guided Prototype Refinement (GCPR) and Pseudo Query Context-guided Prototype Refinement (PCPR). Specifically, GCPR integrates diverse and differentiated class descriptions generated by large language models to enrich prototypes with comprehensive semantic knowledge. PCPR further aggregates reliable class-specific pseudo-query context to mitigate class information bias and generate more suitable query-specific prototypes. Furthermore, we introduce a dual-distillation regularization term, enabling knowledge transfer between early-stage entities (prototypes or pseudo predictions) and their deeper counterparts to enhance refinement. Extensive experiments demonstrate the superiority of our method, surpassing the state-of-the-art methods by up to 12.10% and 13.75% mIoU on S3DIS and ScanNet, respectively.",Lili Wei; Congyan Lang; Ziyi Chen; Tao Wang; Yidong Li; Jun Liu,~Lili_Wei1; ~Congyan_Lang2; ~Ziyi_Chen15; ~Tao_Wang1; ~Yidong_Li1; ~Jun_Liu8,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/ed1cf9f12addc98d134186a5995e10524659f015.pdf,2024-05-15T00:41:38.708000,2024-09-25T18:13:45.898000,2024-11-14T12:55:09.050000,https://openreview.net/forum?id=TBVLQjdFcA,Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University; Beijing Jiaotong University; Lancaster University; Singapore University of Technology and Design
1334,lG1VEQJvUH,lG1VEQJvUH,13004,Unitary Convolutions for Learning on Graphs and Groups,"Data with geometric structure is ubiquitous in machine learning often arising from fundamental symmetries in a domain, such as permutation-invariance in graphs and translation-invariance in images. Group-convolutional architectures, which encode symmetries as inductive bias, have shown great success in applications, but can suffer from instabilities as their depth increases and often struggle to learn long range dependencies in data. For instance, graph neural networks experience instability due to the convergence of node representations (over-smoothing), which can occur after only a few iterations of message-passing, reducing their effectiveness in downstream tasks. Here, we propose and study unitary group convolutions, which allow for deeper networks that are more stable during training. The main focus of the paper are graph neural networks, where we show that unitary graph convolutions provably avoid over-smoothing. Our experimental results confirm that unitary graph convolutional networks achieve competitive performance on benchmark datasets compared to state-of-the-art graph neural networks. We complement our analysis of the graph domain with the study of general unitary convolutions and analyze their role in enhancing stability in general group convolutional architectures.",Bobak Kiani; Lukas Fesser; Melanie Weber,~Bobak_Kiani1; ~Lukas_Fesser1; ~Melanie_Weber1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/de7d409d57d061cb57fc4fec5f73651167e8f042.pdf,2024-05-15T00:35:29.269000,2024-09-25T18:13:45.330000,2024-12-19T13:07:03.186000,https://openreview.net/forum?id=lG1VEQJvUH,Harvard University; Harvard University
1336,dkkgKzMni7,dkkgKzMni7,12997,Hardness of Learning Neural Networks under the Manifold Hypothesis,"The manifold hypothesis presumes that high-dimensional data lies on or near a low-dimensional manifold. 
While the utility of encoding geometric structure has been demonstrated empirically, rigorous analysis of its impact on the learnability of neural networks is largely missing. Several recent results have established hardness results for learning feedforward and equivariant neural networks under i.i.d. Gaussian or uniform Boolean data distributions. In this paper, we investigate the hardness of learning under the manifold hypothesis. We ask, which minimal assumptions on the curvature and regularity of the manifold, if any, render the learning problem efficiently learnable. We prove that learning is hard under input manifolds of bounded curvature by extending proofs of hardness in the SQ and cryptographic settings for boolean data inputs to the geometric setting. On the other hand, we show that additional assumptions on the volume of the data manifold alleviate these fundamental limitations and guarantee learnability via a simple interpolation argument. Notable instances of this regime are manifolds which can be reliably reconstructed via manifold learning. 
Looking forward, we comment on and empirically explore intermediate regimes of manifolds, which have heterogeneous features commonly found in real world data.",Bobak Kiani; Jason Wang; Melanie Weber,~Bobak_Kiani1; ~Jason_Wang3; ~Melanie_Weber1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/c78412c451f511b90a295fa521f079fa6c3e9013.pdf,2024-05-15T00:33:01.346000,2024-09-25T18:13:45.107000,2024-11-06T06:19:14.185000,https://openreview.net/forum?id=dkkgKzMni7,Harvard University; Harvard University
1344,jXs6Cvpe7k,jXs6Cvpe7k,12968,Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks,"Despite advances in AI alignment, large language models (LLMs) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries can modify prompts to induce unwanted behavior. While some defenses have been proposed, they have not been adapted to newly proposed attacks and more challenging threat models. To address this, we propose an optimization-based objective for defending LLMs against jailbreaking attacks and an algorithm, Robust Prompt Optimization (RPO), to create robust system-level defenses. Our approach directly incorporates the adversary into the defensive objective and optimizes a lightweight and transferable suffix, enabling RPO to adapt to worst-case adaptive attacks. Our theoretical and experimental results show improved robustness to both jailbreaks seen during optimization and unknown jailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2 to 0% on JailbreakBench, setting the state-of-the-art.",Andy Zhou; Bo Li; Haohan Wang,~Andy_Zhou2; ~Bo_Li19; ~Haohan_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/898677a5a7c1ad1e799be7fb9f52bd15e7c53680.pdf,2024-05-15T00:22:08.332000,2024-09-25T18:13:43.782000,2024-11-06T06:19:13.866000,https://openreview.net/forum?id=jXs6Cvpe7k,"Department of Computer Science, University of Illinois at Urbana Champaign; Department of Computer Science, University of Illinois at Urbana Champaign"
1349,gRG6SzbW9p,gRG6SzbW9p,12935,Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning,"Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences. However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population. When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups. To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods. Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data. While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling. To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions. Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy. We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences. This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment.",Sriyash Poddar; Yanming Wan; Hamish Ivison; Abhishek Gupta; Natasha Jaques,~Sriyash_Poddar1; ~Yanming_Wan1; ~Hamish_Ivison1; ~Abhishek_Gupta1; ~Natasha_Jaques1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/100f9da6a2c6f9d3d08c26432688a8a57f9cbd85.pdf,2024-05-15T00:09:35.562000,2024-09-25T18:13:42.823000,2024-11-06T06:19:13.633000,https://openreview.net/forum?id=gRG6SzbW9p,University of Washington; University of Washington; University of Washington; Google; University of Washington
1350,eDNslSwQIj,eDNslSwQIj,12934,Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models,"We address the problem of multi-object 3D pose control in image diffusion models. Instead of conditioning on a sequence of text tokens, we propose to use a set of per-object representations, *Neural Assets*, to control the 3D pose of individual objects in a scene. Neural Assets are obtained by pooling visual representations of objects from a reference image, such as a frame in a video, and are trained to reconstruct the respective objects in a different image, e.g., a later frame in the video. Importantly, we encode object visuals from the reference image while conditioning on object poses from the target frame, which enables learning disentangled appearance and position features. Combining visual and 3D pose representations in a sequence-of-tokens format allows us to keep the text-to-image interface of existing models, with Neural Assets in place of text tokens. By fine-tuning a pre-trained text-to-image diffusion model with this information, our approach enables fine-grained 3D pose and placement control of individual objects in a scene. We further demonstrate that Neural Assets can be transferred and recomposed across different scenes. Our model achieves state-of-the-art multi-object editing results on both synthetic 3D scene datasets, as well as two real-world video datasets (Objectron, Waymo Open).",Ziyi Wu; Yulia Rubanova; Rishabh Kabra; Drew A. Hudson; Igor Gilitschenski; Yusuf Aytar; Sjoerd van Steenkiste; Kelsey R Allen; Thomas Kipf,~Ziyi_Wu1; ~Yulia_Rubanova2; ~Rishabh_Kabra1; ~Drew_Arad_Hudson1; ~Igor_Gilitschenski1; ~Yusuf_Aytar1; ~Sjoerd_van_Steenkiste1; ~Kelsey_R_Allen1; ~Thomas_Kipf2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/4a9f84cb77a4ab3e0fb3d4d67cdb5cd778cad514.pdf,2024-05-15T00:09:31.319000,2024-09-25T18:13:42.688000,2024-11-06T06:19:13.679000,https://openreview.net/forum?id=eDNslSwQIj,York University; Snap Inc.; Google; University College London; Google; Google; University of Toronto; Google; Google; Google; Google
1357,TXsRGrzICz,TXsRGrzICz,12894,What type of inference is planning?,"Multiple types of inference are available for probabilistic graphical models, e.g., marginal, maximum-a-posteriori, and even marginal maximum-a-posteriori. Which one do researchers mean when they talk about ``planning as inference''? There is no consistency in the literature, different types are used, and their ability to do planning is further entangled with specific approximations or additional constraints. In this work we use the variational framework to show that, just like all commonly used types of inference correspond to different weightings of the entropy terms in the variational problem, planning corresponds _exactly_ to a _different_ set of weights. This means that all the tricks of variational inference are readily applicable to planning. We develop an analogue of loopy belief propagation that allows us to perform approximate planning in factored-state Markov decisions processes without incurring intractability due to the exponentially large state space. The variational perspective shows that the previous types of inference for planning are only adequate in environments with low stochasticity, and allows us to characterize each type by its own merits, disentangling the type of inference from the additional approximations that its practical use requires. We validate these results empirically on synthetic MDPs and tasks posed in the International Planning Competition.",Miguel Lazaro-Gredilla; Li Yang Ku; Kevin Patrick Murphy; Dileep George,~Miguel_Lazaro-Gredilla1; ~Li_Yang_Ku1; ~Kevin_Patrick_Murphy1; ~Dileep_George1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/8c8323aea284a7f25b2e6c2e49de2edd0b188afb.pdf,2024-05-14T23:55:17.023000,2024-09-25T18:13:41.385000,2025-01-14T07:10:46.386000,https://openreview.net/forum?id=TXsRGrzICz,Google; Google; Google
1362,aIPwlkdOut,aIPwlkdOut,12882,Enhancing Preference-based Linear Bandits via Human Response Time,"Interactive preference learning systems infer human preferences by presenting queries as pairs of options and collecting binary choices. Although binary choices are simple and widely used, they provide limited information about preference strength. To address this, we leverage human response times, which are inversely related to preference strength, as an additional signal. We propose a computationally efficient method that combines choices and response times to estimate human utility functions, grounded in the EZ diffusion model from psychology. Theoretical and empirical analyses show that for queries with strong preferences, response times complement choices by providing extra information about preference strength, leading to significantly improved utility estimation. We incorporate this estimator into preference-based linear bandits for fixed-budget best-arm identification. Simulations on three real-world datasets demonstrate that using response times significantly accelerates preference learning compared to choice-only approaches. Additional materials, such as code, slides, and talk video, are available at https://shenlirobot.github.io/pages/NeurIPS24.html.",Shen Li; Yuyang Zhang; Zhaolin Ren; Claire Liang; Na Li; Julie Shah,~Shen_Li1; ~Yuyang_Zhang4; ~Zhaolin_Ren1; ~Claire_Liang1; ~Na_Li3; ~Julie_Shah2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,bandits,/pdf/b32d10afd0c5117bb0b9ac42cf07b7786e40cbd9.pdf,2024-05-14T23:49:31.204000,2024-09-25T18:13:40.877000,2025-01-02T11:29:18.834000,https://openreview.net/forum?id=aIPwlkdOut,Harvard University; Massachusetts Institute of Technology
1379,t7euV5dl5M,t7euV5dl5M,12818,Approximation-Aware Bayesian Optimization,"High-dimensional Bayesian optimization (BO) tasks such as molecular design often require $>10,$$000$ function evaluations before obtaining meaningful results. While methods like sparse variational Gaussian processes (SVGPs) reduce computational requirements in these settings, the underlying approximations result in suboptimal data acquisitions that slow the progress of optimization. In this paper we modify SVGPs to better align with the goals of BO: targeting informed data acquisition over global posterior fidelity. Using the framework of utility-calibrated variational inference (Lacoste–Julien et al., 2011), we unify GP approximation and data acquisition into a joint optimization problem, thereby ensuring optimal decisions under a limited computational budget. Our approach can be used with any decision-theoretic acquisition function and is readily compatible with trust region methods like TuRBO (Eriksson et al., 2019). We derive efficient joint objectives for the expected improvement (EI) and knowledge gradient (KG) acquisition functions in both the standard and batch BO settings. On a variety of recent high dimensional benchmark tasks in control and molecular design, our approach significantly outperforms standard SVGPs and is capable of achieving comparable rewards with up to $10\times$ fewer function evaluations.",Natalie Maus; Kyurae Kim; David Eriksson; Geoff Pleiss; John Patrick Cunningham; Jacob R. Gardner,~Natalie_Maus1; ~Kyurae_Kim1; ~David_Eriksson2; ~Geoff_Pleiss1; ~John_Patrick_Cunningham1; ~Jacob_R._Gardner1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/2ca4a8f0e8762d4239df7e343b5fac191fa32a86.pdf,2024-05-14T23:24:30.531000,2024-09-25T18:13:38.571000,2025-01-15T13:38:42.019000,https://openreview.net/forum?id=t7euV5dl5M,University of Pennsylvania; University of Pennsylvania; Meta; Vector Institute; University of British Columbia; University of Pennsylvania
1386,8jB6sGqvgQ,8jB6sGqvgQ,12790,Efficient Adversarial Training in LLMs with Continuous Attacks,"Large language models (LLMs) are vulnerable to adversarial attacks that can bypass their safety guardrails. In many domains, adversarial training has proven to be one of the most promising methods to reliably improve robustness against such attacks. Yet, in the context of LLMs, current methods for adversarial training are hindered by the high computational costs required to perform discrete adversarial attacks at each training iteration. We address this problem by instead calculating adversarial attacks in the continuous embedding space of the LLM, which is orders of magnitudes more efficient. We propose a fast adversarial training algorithm (C-AdvUL) composed of two losses: the first makes the model robust on continuous embedding attacks computed on an adversarial behaviour dataset; the second ensures the usefulness of the final model by fine-tuning on utility data. Moreover, we introduce C-AdvIPO, an adversarial variant of IPO that does not require utility data for adversarially robust alignment. Our empirical evaluation on five models from different families (Gemma, Phi3, Mistral, Zephyr, Llama2) and at different scales (2B, 3.8B, 7B) shows that both algorithms substantially enhance LLM robustness against discrete attacks (GCG, AutoDAN, PAIR), while maintaining utility. Our results demonstrate that robustness to continuous perturbations can extrapolate to discrete threat models. Thereby, we present a path toward scalable adversarial training algorithms for robustly aligning LLMs.",Sophie Xhonneux; Alessandro Sordoni; Stephan Günnemann; Gauthier Gidel; Leo Schwinn,~Sophie_Xhonneux1; ~Alessandro_Sordoni2; ~Stephan_Günnemann1; ~Gauthier_Gidel1; ~Leo_Schwinn1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/d6a785ac1ba01ae027569c81a9ec10565ccf5942.pdf,2024-05-14T23:14:12.814000,2024-09-25T18:13:37.735000,2024-11-06T06:19:12.094000,https://openreview.net/forum?id=8jB6sGqvgQ,Montreal Institute of Learning Algorithms; Technical University of Munich; Montreal Institute of Learning Algorithms; Technical University of Munich
1397,L86glqNCUj,L86glqNCUj,12760,Symmetries in Overparametrized Neural Networks: A Mean Field View,"We develop a Mean-Field (MF) view of the learning dynamics of overparametrized Artificial Neural Networks (NN) under distributional symmetries of the data w.r.t. the action of a general compact group $G$. We consider for this a class of  generalized shallow NNs given by an ensemble of  $N$ multi-layer units, jointly trained  using stochastic gradient descent (SGD) and possibly symmetry-leveraging (SL) techniques, such as Data Augmentation (DA), Feature Averaging  (FA) or Equivariant Architectures (EA).  We introduce the notions of weakly and strongly invariant  laws (WI and SI) on the parameter space of each single unit, corresponding, respectively, to $G$-invariant distributions, and to distributions supported on parameters fixed by the group action (which encode EA). This allows us to define symmetric models compatible with taking $N\to\infty$ and  give an interpretation of the asymptotic dynamics of DA, FA and EA in terms of Wasserstein Gradient Flows describing their MF limits. When activations respect the group action, we show that, for  symmetric data, DA, FA and freely-trained models obey the exact same MF  dynamic, which stays in the space of WI parameter laws and attains therein the population risk's minimizer. We also provide a counterexample to the general attainability of such an optimum over SI laws.
Despite this,  and quite remarkably, we show that the space of SI laws  is also preserved by these MF distributional dynamics even when freely trained. This sharply contrasts the finite-$N$ setting, in which EAs are generally not preserved by unconstrained SGD. We illustrate the validity of our findings as $N$ gets larger,  in a teacher-student experimental setting, training a student NN to learn from a WI, SI  or arbitrary teacher model through various SL schemes. We lastly deduce a data-driven heuristic to discover the largest subspace of parameters supporting SI distributions for a problem, that could be used for designing EA with minimal generalization error.",Javier Maass Martínez; Joaquin Fontbona,~Javier_Maass_Martínez1; ~Joaquin_Fontbona1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/59765fb6efd8aa8c9c525a3d726394e310f1a0b1.pdf,2024-05-14T23:04:22.959000,2024-09-25T18:13:36.617000,2024-11-06T06:19:11.590000,https://openreview.net/forum?id=L86glqNCUj,"Universidad de Chile, Universidad de Chile"
1405,ufPPf9ghzP,ufPPf9ghzP,12727,A Neural Network Approach for Efficiently Answering Most Probable Explanation Queries in Probabilistic Models,"We propose a novel neural networks based approach to efficiently answer arbitrary Most Probable Explanation (MPE) queries—a well-known NP-hard task—in large probabilistic models such as 
Bayesian and Markov networks, probabilistic circuits, and neural auto-regressive models. By arbitrary MPE queries, we mean that there is no predefined partition of variables into evidence and non-evidence variables. The key idea is to distill all MPE queries over a given probabilistic model into a neural network and then use the latter for answering queries, eliminating the need for time-consuming inference algorithms that operate directly on the probabilistic model. We improve upon this idea by incorporating inference-time optimization with self-supervised loss to iteratively improve the solutions and employ a teacher-student framework that provides a better initial network, which in turn, helps reduce the number of inference-time optimization steps. The teacher network utilizes a self-supervised loss function optimized for getting the exact MPE solution, while the student network learns from the teacher's near-optimal outputs through supervised loss. We demonstrate the efficacy and scalability of our approach on various datasets and a broad class of probabilistic models, showcasing its practical effectiveness.",Shivvrat Arya; Tahrima Rahman; Vibhav Giridhar Gogate,~Shivvrat_Arya1; ~Tahrima_Rahman1; ~Vibhav_Giridhar_Gogate1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/3c36eee1186a12d49d52d3cabbac6e20dfbc948a.pdf,2024-05-14T22:54:13.425000,2024-09-25T18:13:35.881000,2024-11-06T06:19:11.259000,https://openreview.net/forum?id=ufPPf9ghzP,"University of Texas, Dallas; University of Texas, Dallas"
1428,qvdc0oCX2n,qvdc0oCX2n,12591,CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning,"Data selection has emerged as a core issue for large-scale visual-language model pretaining (e.g., CLIP), particularly with noisy web-curated datasets. Three main data selection approaches are: (1) leveraging external non-CLIP models to aid data selection, (2) training new CLIP-style embedding models that are more effective at selecting high-quality data than the original OpenAI CLIP model, and (3) designing better metrics or strategies universally applicable to any CLIP embedding without requiring specific model properties (e.g., CLIPScore is one popular metric).  While the first two approaches have been extensively studied, the third remains under-explored. In this paper, we advance the third approach by proposing two new methods. Firstly, instead of classical CLIP scores that only consider the alignment between two modalities from a single sample, we introduce $\textbf{negCLIPLoss}$,  a method inspired by CLIP training loss that adds the alignment between one sample and its contrastive pairs as an extra normalization term to CLIPScore for better quality measurement. Secondly, when downstream tasks are known, we propose a new norm-based metric, $\textbf{NormSim}$, to measure the similarity between pretraining data and target data. We test our methods on the data selection benchmark, DataComp [Gadre et al., 2023]. Compared to the best baseline using only OpenAI's CLIP-L/14, our methods achieve a 5.3\% improvement on ImageNet-1k and a 2.8\% improvement on 38 downstream evaluation tasks. Moreover, both $\textbf{negCLIPLoss}$ and $\textbf{NormSim}$ are compatible with existing techniques. By combining our methods with the current best methods DFN [Fang et al., 2023] and HYPE [Kim et al., 2024], we can boost average performance on downstream tasks by 0.9\%, achieving a new state-of-the-art on the DataComp-medium benchmark.",Yiping Wang; Yifang Chen; Wendan Yan; Alex Fang; Wenjing Zhou; Kevin Jamieson; Simon Shaolei Du,~Yiping_Wang2; ~Yifang_Chen1; ~Wendan_Yan1; ~Alex_Fang1; ~Wenjing_Zhou2; ~Kevin_Jamieson1; ~Simon_Shaolei_Du1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,active_learning,/pdf/5235d1d349bb8a0f3f2aa81d39b90ef150f6e36e.pdf,2024-05-14T22:11:22.911000,2024-09-25T18:13:31.334000,2024-11-06T06:19:10.290000,https://openreview.net/forum?id=qvdc0oCX2n,University of Washington; University of Washington; Stanford University; University of Washington; Amazon; University of Washington; University of Washington
1429,KY07A73F3Y,KY07A73F3Y,12587,Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control,"Embodied AI agents require a fine-grained understanding of the physical world mediated through visual and language inputs. Such capabilities are difficult to learn solely from task-specific data. This has led to the emergence of pre-trained vision-language models as a tool for transferring representations learned from internet-scale data to downstream tasks and new domains. However, commonly used contrastively trained representations such as in CLIP have been shown to fail at enabling embodied agents to gain a sufficiently fine-grained scene understanding—a capability vital for control. To address this shortcoming, we consider representations from pre-trained text-to-image diffusion models, which are explicitly optimized to generate images from text prompts and as such, contain text-conditioned representations that reflect highly fine-grained visuo-spatial information. Using pre-trained text-to-image diffusion models, we construct Stable Control Representations which allow learning downstream control policies that generalize to complex, open-ended environments. We show that policies learned using Stable Control Representations are competitive with state-of-the-art representation learning approaches across a broad range of simulated control settings, encompassing challenging manipulation and navigation tasks. Most notably, we show that Stable Control Representations enable learning policies that exhibit state-of-the-art performance on OVMM, a difficult open-vocabulary navigation benchmark.",Gunshi Gupta; Karmesh Yadav; Yarin Gal; Dhruv Batra; Zsolt Kira; Cong Lu; Tim G. J. Rudner,~Gunshi_Gupta1; ~Karmesh_Yadav1; ~Yarin_Gal1; ~Dhruv_Batra1; ~Zsolt_Kira1; ~Cong_Lu1; ~Tim_G._J._Rudner2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/e9965fa3272e80dd82a71cd2d4d9f81875b6d8a2.pdf,2024-05-14T22:09:55.247000,2024-09-25T18:13:31.140000,2024-11-06T06:19:10.247000,https://openreview.net/forum?id=KY07A73F3Y,University of Oxford; Georgia Institute of Technology; University of Oxford; Georgia Institute of Technology; Georgia Institute of Technology; University of British Columbia; New York University
1430,XUL75cvHL5,XUL75cvHL5,12582,The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize,"In this work, we investigate stochastic approximation (SA) with Markovian data and nonlinear updates under constant stepsize $\alpha>0$. Existing work has primarily focused on either i.i.d. data or linear update rules. We take a new perspective and carefully examine the simultaneous presence of Markovian dependency of data and nonlinear update rules, delineating how the interplay between these two structures leads to complications that are not captured by prior techniques. By leveraging the smoothness and recurrence properties of the SA updates, we develop a fine-grained analysis of the correlation between the SA iterates $\theta_k$ and Markovian data $x_k$. This enables us to overcome the obstacles in existing analysis and establish for the first time the weak convergence of the joint process $(x_k, \theta_k)$. Furthermore, we present a precise characterization of the asymptotic bias of the SA iterates, given by $\mathbb{E}[\theta_\infty]-\theta^\ast=\alpha(b_\textup{m}+b_\textup{n}+b_\textup{c})+\mathcal{O}(\alpha^{3/2})$. Here, $b_\textup{m}$ is associated with the Markovian noise, $b_\textup{n}$ is tied to the nonlinearity of the SA operator, and notably, $b_\textup{c}$ represents a multiplicative interaction between the Markovian noise and the nonlinearity of the operator, which is absent in previous works. As a by-product of our analysis, we derive finite-time bounds on higher moment $\mathbb{E}[||\theta_k-\theta^\ast||^{2p}]$ and present non-asymptotic geometric convergence rates for the iterates, along with a Central Limit Theorem.",Dongyan Lucy Huo; Yixuan Zhang; Yudong Chen; Qiaomin Xie,~Dongyan_Lucy_Huo1; ~Yixuan_Zhang3; ~Yudong_Chen1; ~Qiaomin_Xie1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/be00e184a4e557a8a0c853e1a8681c3f2610ef93.pdf,2024-05-14T22:08:56.812000,2024-09-25T18:13:31.138000,2024-11-06T06:19:10.173000,https://openreview.net/forum?id=XUL75cvHL5,Cornell University; University of Wisconsin - Madison; University of Wisconsin - Madison; University of Wisconsin - Madison
1432,tVConYid20,tVConYid20,12566,FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision,"Attention, as a core layer of the ubiquitous Transformer architecture, is the bottleneck for large language models and long-context applications. elaborated an approach to speed up attention on GPUs through minimizing memory reads/writes. However, it has yet to take advantage of new capabilities present in recent hardware, with FlashAttention-2 achieving only 35% utilization on the H100 GPU.
We develop three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to (1) overlap overall computation and data movement via warp-specialization and (2) interleave block-wise matmul and softmax operations, and (3) block quantization and incoherent processing that leverages hardware support for FP8 low-precision. We demonstrate that our method, FlashAttention-3, achieves speedup on H100 GPUs by 1.5-2.0$\times$ with BF16 reaching up to 840 TFLOPs/s (85\% utilization), and with FP8 reaching 1.3 PFLOPs/s. We validate that FP8 FlashAttention-3 achieves 2.6$\times$ lower numerical error than a baseline FP8 attention.",Jay Shah; Ganesh Bikshandi; Ying Zhang; Vijay Thakkar; Pradeep Ramani; Tri Dao,~Jay_Shah2; ~Ganesh_Bikshandi1; ~Ying_Zhang34; ~Vijay_Thakkar1; ~Pradeep_Ramani1; ~Tri_Dao1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,infrastructure,/pdf/b6740309eaf98aa3b013a5269784842f1debc392.pdf,2024-05-14T22:04:39.656000,2024-09-25T18:13:30.492000,2024-11-06T06:19:10.130000,https://openreview.net/forum?id=tVConYid20,Colfax Research; Meta; Georgia Institute of Technology; NVIDIA; Princeton University
1446,8Fxqn1tZM1,8Fxqn1tZM1,12488,Scale Equivariant Graph Metanetworks,"This paper pertains to an emerging machine learning paradigm: learning higher- order functions, i.e. functions whose inputs are functions themselves, particularly when these inputs are Neural Networks (NNs). With the growing interest in architectures that process NNs, a recurring design principle has permeated the field: adhering to the permutation symmetries arising from the connectionist structure of
NNs. However, are these the sole symmetries present in NN parameterizations? Zooming into most practical activation functions (e.g. sine, ReLU, tanh) answers this question negatively and gives rise to intriguing new symmetries, which we collectively refer to as scaling symmetries, that is, non-zero scalar multiplications and divisions of weights and biases. In this work, we propose Scale Equivariant Graph MetaNetworks - ScaleGMNs, a framework that adapts the Graph Metanetwork (message-passing) paradigm by incorporating scaling symmetries and thus rendering neuron and edge representations equivariant to valid scalings. We introduce novel building blocks, of independent technical interest, that allow for equivariance or invariance with respect to individual scalar multipliers or their product and use them in all components of ScaleGMN. Furthermore, we prove that, under certain expressivity conditions, ScaleGMN can simulate the forward and backward pass of any input feedforward neural network. Experimental results demonstrate that our method advances the state-of-the-art performance for several datasets and activation functions, highlighting the power of scaling symmetries as an inductive bias for NN processing. The source code is publicly available at https://github.com/jkalogero/scalegmn.",Ioannis Kalogeropoulos; Giorgos Bouritsas; Yannis Panagakis,~Ioannis_Kalogeropoulos1; ~Giorgos_Bouritsas1; ~Yannis_Panagakis1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/6d3b36cd5d6e1acb5d27b18b7da7333f5c075e0e.pdf,2024-05-14T21:41:55.877000,2024-09-25T18:13:27.936000,2024-11-06T06:19:09.548000,https://openreview.net/forum?id=8Fxqn1tZM1,National and Kapodistrian University of Athens; Athena Research and Innovation Center; National and Kapodistrian University of Athens; National and Kapodistrian University of Athens
1468,fNakQltI1N,fNakQltI1N,12359,Trajectory Flow Matching with Applications to Clinical Time Series Modelling,"Modeling stochastic and irregularly sampled time series is a challenging problem found in a wide range of applications, especially in medicine. Neural stochastic differential equations (Neural SDEs) are an attractive modeling technique for this problem, which parameterize the drift and diffusion terms of an SDE with neural networks. However, current algorithms for training Neural SDEs require backpropagation through the SDE dynamics, greatly limiting their scalability and stability. 
To address this, we propose **Trajectory Flow Matching** (TFM), which trains a Neural SDE in a *simulation-free* manner, bypassing backpropagation through the dynamics. TFM leverages the flow matching technique from generative modeling to model time series. In this work we first establish necessary conditions for TFM to learn time series data. Next, we present a reparameterization trick which improves training stability. Finally, we adapt TFM to the clinical time series setting, demonstrating improved performance on four clinical time series datasets both in terms of absolute performance and uncertainty prediction, a crucial parameter in this setting.",Xi Zhang; Yuan Pu; Yuki Kawamura; Andrew Loza; Yoshua Bengio; Dennis Shung; Alexander Tong,~Xi_Zhang18; ~Yuan_Pu4; ~Yuki_Kawamura1; ~Andrew_Loza1; ~Yoshua_Bengio1; ~Dennis_Shung1; ~Alexander_Tong1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_healthcare,/pdf/eccb1e85d348547475213eddd7bd8ddeea27f351.pdf,2024-05-14T21:08:14.990000,2024-09-25T18:13:23.788000,2025-01-15T22:43:58.197000,https://openreview.net/forum?id=fNakQltI1N,McGill University; Yale University; University of Cambridge; Montreal Institute of Learning Algorithms; Yale University; Montreal Institute of Learning Algorithms
1472,61YYSy078Z,61YYSy078Z,12345,ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks,"The Lipschitz constant plays a crucial role in certifying the robustness of neural networks to input perturbations. Since calculating the exact Lipschitz constant is NP-hard, efforts have been made to obtain tight upper bounds on the Lipschitz constant. Typically, this involves solving a large matrix verification problem, the computational cost of which grows significantly for both deeper and wider networks. In this paper, we provide a compositional approach to estimate Lipschitz constants for deep feed-forward neural networks. We first obtain an exact decomposition of the large matrix verification problem into smaller sub-problems. Then, leveraging the underlying cascade structure of the network, we develop two algorithms. The first algorithm explores the geometric features of the problem and enables us to provide Lipschitz estimates that are comparable to existing methods by solving small semidefinite programs (SDPs) that are only as large as the size of each layer. The second algorithm relaxes these sub-problems and provides a closed-form solution to each sub-problem for extremely fast estimation, altogether eliminating the need to solve SDPs. The two algorithms represent different levels of trade-offs between efficiency and accuracy. Finally, we demonstrate that our approach provides a steep reduction in computation time (as much as several thousand times faster, depending on the algorithm for deeper networks) while yielding Lipschitz bounds that are very close to or even better than those achieved by state-of-the-art approaches in a broad range of experiments. In summary, our approach considerably advances the scalability and efficiency of certifying neural network robustness, making it particularly attractive for online learning tasks.",Yuezhu Xu; S Sivaranjani,~Yuezhu_Xu1; ~S_Sivaranjani1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/6bb319b95e4b2b2876e2c7370dfc870a2486e168.pdf,2024-05-14T21:04:32.619000,2024-09-25T18:13:23.403000,2024-12-19T02:59:05.159000,https://openreview.net/forum?id=61YYSy078Z,Purdue University; Purdue University
1515,Ai76ATrb2y,Ai76ATrb2y,12180,Auditing Privacy Mechanisms via Label Inference Attacks,"We propose reconstruction advantage measures to audit label privatization mechanisms. A reconstruction advantage measure quantifies the increase in an attacker's ability to infer the true label of an unlabeled example when provided with a private version of the labels in a dataset (e.g., aggregate of labels from different users or noisy labels output by randomized response), compared to an attacker that only observes the feature vectors, but may have prior knowledge of the correlation between features and labels. We consider two such auditing measures: one additive, and on multiplicative. These cover previous approaches taken in the literature on empirical auditing and differential privacy. These measures allow us to place a variety of proposed privatization schemes---some differentially private, some not---on the same footing. We analyze these measures theoretically under a distributional model which, we claim, encapsulates reasonable adversarial settings. We also quantify their behavior empirically on real and simulated  prediction tasks. Across a range of experimental settings, we find that differentially private schemes dominate or match the privacy-utility tradeoff of more heuristic approaches.",Robert Istvan Busa-Fekete; Travis Dick; Claudio Gentile; Andres Munoz medina; Adam Smith; Marika Swanberg,~Robert_Istvan_Busa-Fekete1; ~Travis_Dick1; ~Claudio_Gentile1; ~Andres_Munoz_medina1; ~Adam_Smith1; ~Marika_Swanberg1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/30f74713b3cc0e6ae9f02677c216896562de24f0.pdf,2024-05-14T20:16:07.671000,2024-09-25T18:13:17.577000,2024-11-06T06:19:06.379000,https://openreview.net/forum?id=Ai76ATrb2y,Google; Boston University; Google; Boston University; Google
1525,Ke40kfOT2E,Ke40kfOT2E,12143,Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits,"Probabilistic integral circuits (PICs) have been recently introduced as probabilistic models enjoying the key ingredient behind expressive generative models: continuous latent variables (LVs). PICs are symbolic computational graphs defining continuous LV models as hierarchies of functions that are summed and multiplied together, or integrated over some LVs. They are tractable if LVs can be analytically integrated out, otherwise they can be approximated by tractable probabilistic circuits (PC) encoding a hierarchical numerical quadrature process, called QPCs.

So far, only tree-shaped PICs have been explored, and training them via numerical quadrature requires memory-intensive processing at scale. In this paper, we address these issues, and present: (i) a pipeline for building DAG-shaped PICs out of arbitrary variable decompositions, (ii) a procedure for training PICs using tensorized circuit architectures, and (iii) neural functional sharing techniques to allow scalable training. In extensive experiments, we showcase the effectiveness of functional sharing and the superiority of QPCs over traditional PCs.",Gennaro Gala; Cassio de Campos; Antonio Vergari; Erik Quaeghebeur,~Gennaro_Gala1; ~Cassio_de_Campos1; ~Antonio_Vergari3; ~Erik_Quaeghebeur2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/1375711caada6ca669b4df7e3f6a61c3c9409a15.pdf,2024-05-14T20:05:47.369000,2024-09-25T18:13:16.089000,2024-12-19T14:10:17.860000,https://openreview.net/forum?id=Ke40kfOT2E,Delft University of Technology; Delft University of Technology; University of Edinburgh; Delft University of Technology
1532,XNpVZ8E1tY,XNpVZ8E1tY,12099,Online Bayesian Persuasion Without a Clue,"We study online Bayesian persuasion problems in which an informed sender repeatedly faces a receiver with the goal of influencing their behavior through the provision of payoff-relevant information. Previous works assume that the sender has knowledge about either the prior distribution over states of nature or receiver's utilities, or both. We relax such unrealistic assumptions by considering settings in which the sender does not know anything about the prior and the receiver. We design an algorithm that achieves sublinear---in the number of rounds T---regret with respect to an optimal signaling scheme, and we also provide a collection of lower bounds showing that the guarantees of such an algorithm are tight. Our algorithm works by searching a suitable space of signaling schemes in order to learn receiver's best responses. To do this, we leverage a non-standard representation of signaling schemes that allows to cleverly overcome the challenge of not knowing anything about the prior over states of nature and receiver's utilities. Finally, our results also allow to derive lower/upper bounds on the sample complexity of learning signaling schemes in a related Bayesian persuasion PAC-learning problem.",Francesco Bacchiocchi; Matteo Bollini; Matteo Castiglioni; Alberto Marchesi; Nicola Gatti,~Francesco_Bacchiocchi1; ~Matteo_Bollini1; ~Matteo_Castiglioni1; ~Alberto_Marchesi1; ~Nicola_Gatti1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/17d1bfac3e1ff480658f0b14ee37e82ae086a1aa.pdf,2024-05-14T19:52:47.957000,2024-09-25T18:13:14.448000,2025-01-15T12:32:28.671000,https://openreview.net/forum?id=XNpVZ8E1tY,Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano
1533,ZEVDMQ6Mu5,ZEVDMQ6Mu5,12096,Curvature Clues: Decoding Deep Learning Privacy with Input Loss Curvature,"In this paper, we explore the properties of loss curvature with respect to input data in deep neural networks. Curvature of loss with respect to input (termed input loss curvature) is the trace of the Hessian of the loss with respect to the input. We investigate how input loss curvature varies between train and test sets, and its implications for train-test distinguishability. We develop a theoretical framework that derives an upper bound on the train-test distinguishability based on privacy and the size of the training set. This novel insight fuels the development of a new black box membership inference attack utilizing input loss curvature. We validate our theoretical findings through experiments in computer vision classification tasks, demonstrating that input loss curvature surpasses existing methods in membership inference effectiveness. Our analysis highlights how the performance of membership inference attack (MIA) methods varies with the size of the training set, showing that curvature-based MIA outperforms other methods on sufficiently large datasets. This condition is often met by real datasets, as demonstrated by our results on CIFAR10, CIFAR100, and ImageNet. These findings not only advance our understanding of deep neural network behavior but also improve the ability to test privacy-preserving techniques in machine learning.",Deepak Ravikumar; Efstathia Soufleri; Kaushik Roy,~Deepak_Ravikumar1; ~Efstathia_Soufleri1; ~Kaushik_Roy1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/16cafd5bfd76bba19e2af0ee2cf8bd9b27a67dad.pdf,2024-05-14T19:51:44.266000,2024-09-25T18:13:14.377000,2024-11-06T06:19:05.518000,https://openreview.net/forum?id=ZEVDMQ6Mu5,Purdue University; Athena Research and Innovation Center; Purdue University; Purdue University
1535,8oSY3rA9jY,8oSY3rA9jY,12092,Finding Transformer Circuits With Edge Pruning,"The path to interpreting a language model often proceeds via analysis of circuits---sparse computational subgraphs of the model that capture specific aspects of its behavior. Recent work has automated the task of discovering circuits. Yet, these methods have practical limitations, as they either rely on inefficient search algorithms or inaccurate approximations. In this paper, we frame circuit discovery as an optimization problem and propose _Edge Pruning_ as an effective and scalable solution. Edge Pruning leverages gradient-based pruning techniques, but instead of removing neurons or components, prunes the _edges_ between components. Our method finds circuits in GPT-2 that use less than half the number of edges than circuits found by previous methods while being equally faithful to the full model predictions on standard circuit-finding tasks. Edge Pruning is efficient on tasks involving up to 100,000 examples, outperforming previous methods in speed and producing substantially better circuits. It also perfectly recovers the ground-truth circuits in two models compiled with Tracr. Thanks to its efficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the size of GPT-2.
We use this setting for a case study, where we compare the mechanisms behind instruction prompting and in-context learning.
We find two circuits with more than 99.96% sparsity that match the performance of the full model. Further analysis reveals that the mechanisms in the two settings overlap substantially. This shows that Edge Pruning is a practical and scalable tool for interpretability, 
which can shed light on behaviors that only emerge in large models.",Adithya Bhaskar; Alexander Wettig; Dan Friedman; Danqi Chen,~Adithya_Bhaskar2; ~Alexander_Wettig1; ~Dan_Friedman2; ~Danqi_Chen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/f03f6075f6988d9f26ac5c0de399b81a5f9a207f.pdf,2024-05-14T19:50:52.758000,2024-09-25T18:13:14.161000,2024-11-06T06:19:05.445000,https://openreview.net/forum?id=8oSY3rA9jY,Princeton University; Allen Institute; Princeton University; Princeton University
1550,0Lb8vZT1DB,0Lb8vZT1DB,12040,Reliable Learning of Halfspaces under Gaussian Marginals,"We study the problem of PAC learning halfspaces in the 
reliable agnostic model of Kalai et al. (2012).
The reliable PAC model  
captures learning scenarios where one type of error is 
costlier than the others. Our main positive result is a 
new algorithm for reliable learning 
of Gaussian halfspaces on 
$\mathbb{R}^d$ with sample and computational complexity 
$d^{O(\log (\min\{1/\alpha, 1/\epsilon\}))}\min (2^{\log(1/\epsilon)^{O(\log (1/\alpha))}},2^{\mathrm{poly}(1/\epsilon)})$, 
where $\epsilon$ is the excess error and $\alpha$ 
is the bias of the optimal halfspace. We complement our upper bound with 
a Statistical Query lower bound 
suggesting that the $d^{\Omega(\log (1/\alpha))}$ dependence is best possible. 
Conceptually, our results imply a strong computational separation 
between reliable agnostic learning and standard agnostic 
learning of halfspaces in the Gaussian setting.",Ilias Diakonikolas; Lisheng Ren; Nikos Zarifis,~Ilias_Diakonikolas1; ~Lisheng_Ren1; ~Nikos_Zarifis1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/4cdcaf263f9d512b95d31f91c8f83ad1f8c92e4f.pdf,2024-05-14T19:33:53.932000,2024-09-25T18:13:12.399000,2025-01-15T21:35:59.511000,https://openreview.net/forum?id=0Lb8vZT1DB,University of Wisconsin - Madison; University of Wisconsin - Madison; University of Wisconsin - Madison
1563,TFZlFRl9Ks,TFZlFRl9Ks,11975,CAT3D: Create Anything in 3D with Multi-View Diffusion Models,"Advances in 3D reconstruction have enabled high-quality 3D capture, but require a user to collect hundreds to thousands of images to create a 3D scene. We present CAT3D, a method for creating anything in 3D by simulating this real-world capture process with a multi-view diffusion model. Given any number of input images and a set of target novel viewpoints, our model generates highly consistent novel views of a scene. These generated views can be used as input to robust 3D reconstruction techniques to produce 3D representations that can be rendered from any viewpoint in real-time. CAT3D can create entire 3D scenes in as little as one minute, and outperforms existing methods for single image and few-view 3D scene creation.",Ruiqi Gao; Aleksander Holynski; Philipp Henzler; Arthur Brussee; Ricardo Martin Brualla; Pratul P. Srinivasan; Jonathan T. Barron; Ben Poole,~Ruiqi_Gao1; ~Aleksander_Holynski1; ~Philipp_Henzler1; ~Arthur_Brussee1; ~Ricardo_Martin_Brualla1; ~Pratul_P._Srinivasan1; ~Jonathan_T._Barron1; ~Ben_Poole1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/a17526d158b6388ba1714b7d1decfdd7ec50e8da.pdf,2024-05-14T19:18:24.183000,2024-09-25T18:13:10.364000,2024-11-06T06:19:04.307000,https://openreview.net/forum?id=TFZlFRl9Ks,"Google; Columbia University; Google; University of California, Berkeley; Google; Google; Google; Google; Google; Google"
1576,ShJWT0n7kX,ShJWT0n7kX,11933,Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling,"Rare event sampling in dynamical systems is a fundamental problem arising in the natural sciences, which poses significant computational challenges due to an exponentially large space of trajectories. For settings where the dynamical system of interest follows a Brownian motion with known drift, the question of conditioning the process to reach a given endpoint or desired rare event is definitively answered by Doob's $h$-transform. However, the naive estimation of this transform is infeasible, as it requires simulating sufficiently many forward trajectories to estimate rare event probabilities. In this work, we propose a variational formulation of Doob's $h$-transform as an optimization problem over trajectories between a given initial point and the desired ending point. To solve this optimization, we propose a simulation-free training objective with a model parameterization that imposes the desired boundary conditions by design. Our approach significantly reduces the search space over trajectories and avoids expensive trajectory simulation and inefficient importance sampling estimators which are required in existing methods. We demonstrate the ability of our method to find feasible transition paths on real-world molecular simulation and protein folding tasks.",Yuanqi Du; Michael Plainer; Rob Brekelmans; Chenru Duan; Frank Noe; Carla P Gomes; Alan Aspuru-Guzik; Kirill Neklyudov,~Yuanqi_Du1; ~Michael_Plainer1; ~Rob_Brekelmans1; ~Chenru_Duan1; ~Frank_Noe1; ~Carla_P_Gomes1; ~Alan_Aspuru-Guzik2; ~Kirill_Neklyudov1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/53bda8ac23be462ad0b7da366a8c85d8410b6aa4.pdf,2024-05-14T19:02:08.169000,2024-09-25T18:13:08.528000,2024-12-27T11:19:06.025000,https://openreview.net/forum?id=ShJWT0n7kX,Cornell University; Freie Universität Berlin; Vector Institute; Deep Principle; Microsoft; Cornell University; University of Toronto; Montreal Institute of Learning Algorithms; Vector Institute
1578,T56j6aV8Oc,T56j6aV8Oc,11921,Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models,"Adam has been shown to outperform gradient descent on large language models by a larger margin than on other tasks, but it is unclear why. We show that a key factor in this performance gap is the heavy-tailed class imbalance found in language tasks. When trained with gradient descent, the loss of infrequent words decreases more slowly than the loss of frequent ones. This leads to a slow decrease on the average loss as most samples come from infrequent words. On the other hand, Adam and sign-based methods are less sensitive to this problem. To establish that this behavior is caused by class imbalance, we show empirically that it can be reproduced across architectures and data types, on language transformers, vision CNNs, and linear models. On a linear model with cross-entropy loss, we show that class imbalance leads to imbalanced, correlated gradients and Hessians that have been hypothesized to benefit Adam. We also prove that, in continuous time, gradient descent converges slowly on low-frequency classes while sign descent does not.",Frederik Kunstner; Alan Milligan; Robin Yadav; Mark Schmidt; Alberto Bietti,~Frederik_Kunstner1; ~Alan_Milligan1; ~Robin_Yadav1; ~Mark_Schmidt1; ~Alberto_Bietti1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/cb0a8b11c4c41f5a138419a244e5cfe75f0059cf.pdf,2024-05-14T18:57:46.884000,2024-09-25T18:13:08.081000,2025-01-14T20:30:28.027000,https://openreview.net/forum?id=T56j6aV8Oc,"University of British Columbia; Inria, Paris; University of British Columbia; University of Alberta; University of British Columbia; Flatiron Institute"
1590,RYQ0KuZvkL,RYQ0KuZvkL,11859,Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning,"In this paper, we study the non-asymptotic sample complexity for the pure exploration problem in contextual bandits and tabular reinforcement learning (RL): identifying an $\epsilon$-optimal policy from a set of policies $\Pi$ with high probability. Existing work in bandits has shown that it is possible to identify the best policy by estimating only the *difference* between the behaviors of individual policies–which can have substantially lower variance than estimating the behavior of each policy directly—yet the best-known complexities in RL fail to take advantage of this, and instead estimate the behavior of each policy directly. Does it suffice to estimate only the differences in the behaviors of policies in RL? We answer this question positively for contextual bandits, but in the negative for tabular RL, showing a separation between contextual bandits and RL. However, inspired by this, we show that it *almost* suffices to estimate only the differences in RL: if we can estimate the behavior of a *single* reference policy, it suffices to only estimate how any other policy deviates from this reference policy. We develop an algorithm which instantiates this principle and obtains, to the best of our knowledge, the tightest known bound on the sample complexity of tabular RL.",Adhyyan Narang; Andrew Wagenmaker; Lillian J. Ratliff; Kevin Jamieson,~Adhyyan_Narang1; ~Andrew_Wagenmaker1; ~Lillian_J._Ratliff1; ~Kevin_Jamieson1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,bandits,/pdf/336a7b4b952246e72e30c7791ef6644d81abe1da.pdf,2024-05-14T18:39:38.855000,2024-09-25T18:13:05.967000,2024-11-06T06:19:03.240000,https://openreview.net/forum?id=RYQ0KuZvkL,"University of Washington; University of California, Berkeley; University of Washington; University of Washington"
1592,3Odq2tGSpp,3Odq2tGSpp,11839,Stylus: Automatic Adapter Selection for Diffusion Models,"Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs. As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adapters—most of which are highly customized with insufficient descriptions. To generate high quality images, this paper explores the problem of matching the prompt to a Stylus of relevant adapters, built on recent work that highlight the performance gains of composing adapters. We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords. Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt. To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP/FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model.",Michael Luo; Justin Wong; Brandon Trabucco; Yanping Huang; Joseph E. Gonzalez; Zhifeng Chen; Russ Salakhutdinov; Ion Stoica,~Michael_Luo2; ~Justin_Wong1; ~Brandon_Trabucco1; ~Yanping_Huang1; ~Joseph_E._Gonzalez1; ~Zhifeng_Chen1; ~Russ_Salakhutdinov1; ~Ion_Stoica1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/b41be568e09a4892b988b18214b6686115e4ccb9.pdf,2024-05-14T18:35:37.758000,2024-09-25T18:13:05.476000,2024-11-06T06:19:03.171000,https://openreview.net/forum?id=3Odq2tGSpp,"University of California, Berkeley; Meta; University of California, Berkeley; Carnegie Mellon University; University of California, Berkeley; Google; Carnegie Mellon University; University of California, Berkeley"
1598,MsUf8kpKTF,MsUf8kpKTF,11816,A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning,"Continual learning with deep neural networks presents challenges distinct from both the fixed-dataset and convex continual learning regimes. One such challenge is plasticity loss, wherein a neural network trained in an online fashion displays a degraded ability to fit new tasks. This problem has been extensively studied in both supervised learning and off-policy reinforcement learning (RL), where a number of remedies have been proposed. Still, plasticity loss has received less attention in the on-policy deep RL setting. Here we perform an extensive set of experiments examining plasticity loss and a variety of mitigation methods in on-policy deep RL. We demonstrate that plasticity loss is pervasive under domain shift in this regime, and that a number of methods developed to resolve it in other settings fail, sometimes even performing worse than applying no intervention at all. In contrast, we find that a class of ``regenerative'' methods are able to consistently mitigate plasticity loss in a variety of contexts, including in gridworld tasks and more challenging environments like Montezuma's Revenge and ProcGen.",Arthur Juliani; Jordan T. Ash,~Arthur_Juliani1; ~Jordan_T._Ash1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/3e83fb6a90121c80576295e22f339ac0cb843a1c.pdf,2024-05-14T18:27:54.205000,2024-09-25T18:13:04.692000,2024-11-06T06:19:02.919000,https://openreview.net/forum?id=MsUf8kpKTF,Microsoft
1601,WTLvXdzhmP,WTLvXdzhmP,11801,Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm,"The quantum approximate optimization algorithm (QAOA) is a general-purpose algorithm for combinatorial optimization that has been a promising avenue for near-term quantum advantage. 
In this paper, we analyze the performance of the QAOA on the spiked tensor model, a statistical estimation problem that exhibits a large computational-statistical gap classically. 
We prove that the weak recovery threshold of $1$-step QAOA matches that of $1$-step tensor power iteration. Additional heuristic calculations suggest that the weak recovery threshold of $p$-step QAOA matches that of $p$-step tensor power iteration when $p$ is a fixed constant. This further implies that multi-step QAOA with tensor unfolding could achieve, but not surpass, the asymptotic classical computation threshold $\Theta(n^{(q-2)/4})$ for spiked $q$-tensors. 
Meanwhile, we characterize the asymptotic overlap distribution for $p$-step QAOA, discovering an intriguing sine-Gaussian law verified through simulations. For some $p$ and $q$, the QAOA has an effective recovery threshold that is a constant factor better than tensor power iteration.
Of independent interest, our proof techniques employ the Fourier transform to handle difficult combinatorial sums, a novel approach differing from prior QAOA analyses on spin-glass models without planted structure.",Leo Zhou; Joao Basso; Song Mei,~Leo_Zhou1; ~Joao_Basso1; ~Song_Mei1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/ad13d9d78eeed74462c450d578d99967947c7df5.pdf,2024-05-14T18:21:35.354000,2024-09-25T18:13:04.133000,2024-11-06T06:19:02.796000,https://openreview.net/forum?id=WTLvXdzhmP,"California Institute of Technology; University of California, Los Angeles"
1642,k29Iv0XrBF,k29Iv0XrBF,11647,Physically Compatible 3D Object Modeling from a Single Image,"We present a computational framework that transforms single images into 3D physical objects. The visual geometry of a physical object in an image is determined by three orthogonal attributes: mechanical properties, external forces, and rest-shape geometry. Existing single-view 3D reconstruction methods often overlook this underlying composition, presuming rigidity or neglecting external forces. Consequently, the reconstructed objects fail to withstand real-world physical forces, resulting in instability or undesirable deformation -- diverging from their intended designs as depicted in the image. Our optimization framework addresses this by embedding physical compatibility into the reconstruction process. We explicitly decompose the three physical attributes and link them through static equilibrium, which serves as a hard constraint, ensuring that the optimized physical shapes exhibit desired physical behaviors. Evaluations on a dataset collected from Objaverse demonstrate that our framework consistently enhances the physical realism of 3D models over existing methods. The utility of our framework extends to practical applications in dynamic simulations and 3D printing, where adherence to physical compatibility is paramount.",Minghao Guo; Bohan Wang; Pingchuan Ma; Tianyuan Zhang; Crystal Elaine Owens; Chuang Gan; Joshua B. Tenenbaum; Kaiming He; Wojciech Matusik,~Minghao_Guo1; ~Bohan_Wang9; ~Pingchuan_Ma3; ~Tianyuan_Zhang2; ~Crystal_Elaine_Owens1; ~Chuang_Gan1; ~Joshua_B._Tenenbaum1; ~Kaiming_He2; ~Wojciech_Matusik2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/3e82eada922f6bd39360615136f2df132ecffbf1.pdf,2024-05-14T17:36:12.246000,2024-09-25T18:12:58.325000,2024-12-31T19:16:51.980000,https://openreview.net/forum?id=k29Iv0XrBF,Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; University of Massachusetts Amherst; Massachusetts Institute of Technology; Meta; Massachusetts Institute of Technology; Massachusetts Institute of Technology
1647,Ib2iHIJRTh,Ib2iHIJRTh,11626,Probablistic Emulation of a Global Climate Model with Spherical DYffusion,"Data-driven deep learning models are transforming global weather forecasting. It is an open question if this success can extend to climate modeling, where the complexity of the data and long inference rollouts pose significant challenges. Here, we present the first conditional generative model that produces accurate and physically consistent global climate ensemble simulations by emulating a coarse version of the United States' primary operational global forecast model, FV3GFS.
Our model integrates the dynamics-informed diffusion framework (DYffusion) with the Spherical Fourier Neural Operator (SFNO) architecture, enabling stable 100-year simulations at 6-hourly timesteps while maintaining low computational overhead compared to single-step deterministic baselines.
The model achieves near gold-standard performance for climate model emulation, outperforming existing approaches and demonstrating promising ensemble skill.
This work represents a significant advance towards efficient, data-driven climate simulations that can enhance our understanding of the climate system and inform adaptation strategies. Code is available at [https://github.com/Rose-STL-Lab/spherical-dyffusion](https://github.com/Rose-STL-Lab/spherical-dyffusion).",Salva Rühling Cachay; Brian Henn; Oliver Watt-Meyer; Christopher S. Bretherton; Rose Yu,~Salva_Rühling_Cachay1; ~Brian_Henn1; ~Oliver_Watt-Meyer1; ~Christopher_S._Bretherton1; ~Rose_Yu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/f0919472c7366fb6166b4788238d1ac541829846.pdf,2024-05-14T17:29:41.119000,2024-09-25T18:12:57.617000,2024-11-06T06:19:00.590000,https://openreview.net/forum?id=Ib2iHIJRTh,"University of California, San Diego"
1648,bMTn8KKrbq,bMTn8KKrbq,11622,Towards training digitally-tied analog blocks via hybrid gradient computation,"Power efficiency is plateauing in the standard digital electronics realm such that new hardware, models, and algorithms are needed to reduce the costs of AI training. The combination of energy-based analog circuits and the Equilibrium Propagation (EP) algorithm constitutes a compelling alternative compute paradigm for gradient-based optimization of neural nets. Existing analog hardware accelerators, however, typically incorporate digital circuitry to sustain auxiliary non-weight-stationary operations, mitigate analog device imperfections, and leverage existing digital platforms. Such heterogeneous hardware lacks a supporting theoretical framework. In this work, we introduce \emph{Feedforward-tied Energy-based Models} (ff-EBMs), a hybrid model comprised of feedforward and energy-based blocks housed on digital and analog circuits. We derive a novel algorithm to compute gradients end-to-end in ff-EBMs by backpropagating and ``eq-propagating'' through feedforward and energy-based parts respectively, enabling EP to be applied flexibly on realistic architectures. We experimentally demonstrate the effectiveness of this approach on ff-EBMs using Deep Hopfield Networks (DHNs)  as energy-based blocks, and show that a standard DHN can be arbitrarily split into any uniform size while maintaining or improving performance with increases in simulation speed of up to four times. We then train ff-EBMs on ImageNet32 where we establish a new state-of-the-art performance for the EP literature (46 top-1 \%). Our approach offers a principled, scalable, and incremental roadmap for the gradual integration of self-trainable analog computational primitives into existing digital accelerators.",Timothy Nest; Maxence Ernoult,~Timothy_Nest1; ~Maxence_Ernoult1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/0ddbc1061ddc500af441f25cf3e183654f4ff4f5.pdf,2024-05-14T17:28:03.084000,2024-09-25T18:12:57.462000,2024-11-06T06:19:00.550000,https://openreview.net/forum?id=bMTn8KKrbq,Montreal Institute of Learning Algorithms; Rain AI
1668,iW0wXE0VyR,iW0wXE0VyR,11550,Induced Model Matching: Restricted Models Help Train Full-Featured Models,"We consider scenarios where a very accurate (often small) predictive model using restricted features is available when training a full-featured (often larger) model. This restricted model may be thought of as ``side-information'', and can come either from an auxiliary dataset or from the same dataset by forcing the restriction. How can the restricted model be useful to the full model? To answer this, we introduce a methodology called Induced Model Matching (IMM). IMM aligns the context-restricted, or induced, version of the large model with the restricted model. We relate IMM to approaches such as noising, which is implicit in addressing the problem, and reverse knowledge distillation from weak teachers, which is explicit but does not exploit restriction being the nature of the weakness. We show that these prior methods can be thought of as approximations to IMM and can be problematic in terms of consistency. Experimentally, we first motivate IMM using logistic regression as a toy example. We then explore it in language modeling, the application that initially inspired it, and demonstrate it on both LSTM and transformer full models, using bigrams as restricted models. We lastly give a simple RL example, which shows that POMDP policies can help learn better MDP policies. The IMM principle is thus generally applicable in common scenarios where restricted data is cheaper to collect or restricted models are easier to learn.",Usama Muneeb; Mesrob I Ohannessian,~Usama_Muneeb1; ~Mesrob_I_Ohannessian1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/483241922a3b026de4170f1c6bf3a4e06a096f35.pdf,2024-05-14T17:07:24.281000,2024-09-25T18:12:54.779000,2025-01-16T05:25:37.680000,https://openreview.net/forum?id=iW0wXE0VyR,University of Illinois at Chicago
1671,L1mMK39Z7P,L1mMK39Z7P,11537,ACES: Generating a Diversity of Challenging Programming Puzzles with Autotelic Generative Models,"The ability to invent novel and interesting problems is a remarkable feature of human intelligence that drives innovation, art, and science. We propose a method that aims to automate this process by harnessing the power of state-of-the-art generative models to produce a diversity of challenging yet solvable problems, here in the context of Python programming puzzles. Inspired by the intrinsically motivated literature, Autotelic CodE Search (ACES) jointly optimizes for the diversity and difficulty of generated problems. We represent problems in a space of LLM-generated semantic descriptors describing the programming skills required to solve them (e.g. string manipulation, dynamic programming, etc.) and measure their difficulty empirically as a linearly decreasing function of the success rate of \textit{Llama-3-70B}, a state-of-the-art LLM problem solver. ACES iteratively prompts a large language model to generate difficult problems achieving a diversity of target semantic descriptors (goal-directed exploration) using previously generated problems as in-context examples. ACES generates problems that are more diverse and more challenging than problems produced by baseline methods and three times more challenging than problems found in existing Python programming benchmarks on average across 11 state-of-the-art code LLMs.",Julien Pourcel; Cédric Colas; Gaia Molinaro; Pierre-Yves Oudeyer; Laetitia Teodorescu,~Julien_Pourcel1; ~Cédric_Colas1; ~Gaia_Molinaro1; ~Pierre-Yves_Oudeyer1; ~Laetitia_Teodorescu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/ebfcd198369769c06e4e8bd93508befd24cd2a69.pdf,2024-05-14T17:03:51.202000,2024-09-25T18:12:54.245000,2024-11-06T06:18:59.483000,https://openreview.net/forum?id=L1mMK39Z7P,"Inria, Paris; Massachusetts Institute of Technology; University of California, Berkeley; Inria, Paris"
1674,VMsHnv8cVs,VMsHnv8cVs,11509,Learning Better Representations From Less Data For Propositional Satisfiability,"Training neural networks on NP-complete problems typically demands very large amounts of training data and often needs to be coupled with computationally expensive symbolic verifiers to ensure output correctness. In this paper, we present NeuRes, a neuro-symbolic approach to address both challenges for propositional satisfiability, being the quintessential NP-complete problem. By combining certificate-driven training and expert iteration, our model learns better representations than models trained for classification only, with a much higher data efficiency -- requiring orders of magnitude less training data. NeuRes employs propositional resolution as a proof system to generate proofs of unsatisfiability and to accelerate the process of finding satisfying truth assignments, exploring both possibilities in parallel. To realize this, we propose an attention-based architecture that autoregressively selects pairs of clauses from a dynamic formula embedding to derive new clauses. Furthermore, we employ expert iteration whereby model-generated proofs progressively replace longer teacher proofs as the new ground truth. This enables our model to reduce a dataset of proofs generated by an advanced solver by $\sim$$32$% after training on it with no extra guidance. This shows that NeuRes is not limited by the optimality of the teacher algorithm owing to its self-improving workflow. We show that our model achieves far better performance than NeuroSAT in terms of both correctly classified and proven instances.",Mohamed Ghanem; Frederik Schmitt; Julian Siber; Bernd Finkbeiner,~Mohamed_Ghanem1; ~Frederik_Schmitt1; ~Julian_Siber1; ~Bernd_Finkbeiner1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/7860cd44d23c18f12544eadc72e6ec7eab69c5fc.pdf,2024-05-14T16:56:13.531000,2024-09-25T18:12:53.398000,2024-11-06T06:18:59.334000,https://openreview.net/forum?id=VMsHnv8cVs,Helmholtz Center CISPA for Information Security; Saarland University; Helmholtz Center CISPA for Information Security
1699,FBLJIfW64D,FBLJIfW64D,11376,Dimension-free deterministic equivalents and scaling laws for random feature regression,"In this work we investigate the generalization performance of random feature ridge regression (RFRR). Our main contribution is a general deterministic equivalent for the test error of RFRR. Specifically, under a certain concentration property, we show that the test error is well approximated by a closed-form expression that only depends on the feature map eigenvalues. Notably, our approximation guarantee is non-asymptotic, multiplicative, and independent of the feature map dimension---allowing for infinite-dimensional features. We expect this deterministic equivalent to hold broadly beyond our theoretical analysis, and we empirically validate its predictions on various real and synthetic datasets. As an application, we derive sharp excess error rates under standard power-law assumptions of the spectrum and target decay. In particular, we provide a tight result for the smallest number of features achieving optimal minimax error rate.",Leonardo Defilippis; Bruno Loureiro; Theodor Misiakiewicz,~Leonardo_Defilippis1; ~Bruno_Loureiro1; ~Theodor_Misiakiewicz1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/d05b8aff77c1d04cb4e154ef105afb96c9204104.pdf,2024-05-14T16:29:34.750000,2024-09-25T18:12:49.482000,2025-01-15T16:17:05.515000,https://openreview.net/forum?id=FBLJIfW64D,Ecole Normale Supérieure
1704,2HvgvB4aWq,2HvgvB4aWq,11365,Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos,"Procedural activities are sequences of key-steps aimed at achieving specific goals. They are crucial to build intelligent agents able to assist users effectively. In this context, task graphs have emerged as a human-understandable representation of procedural activities, encoding a partial ordering over the key-steps. While previous works generally relied on hand-crafted procedures to extract task graphs from videos, in this paper, we propose an approach based on direct maximum likelihood optimization of edges' weights, which allows gradient-based learning of task graphs and can be naturally plugged into neural network architectures. Experiments on the CaptainCook4D dataset demonstrate the ability of our approach to predict accurate task graphs from the observation of action sequences, with an improvement of +16.7% over previous approaches. Owing to the differentiability of the proposed framework, we also introduce a feature-based approach, aiming to predict task graphs from key-step textual or video embeddings, for which we observe emerging video understanding abilities. Task graphs learned with our approach are also shown to significantly enhance online mistake detection in procedural egocentric videos, achieving notable gains of +19.8% and +7.5% on the Assembly101-O and EPIC-Tent-O datasets. Code for replicating the experiments is available at https://github.com/fpv-iplab/Differentiable-Task-Graph-Learning.",Luigi Seminara; Giovanni Maria Farinella; Antonino Furnari,~Luigi_Seminara1; ~Giovanni_Maria_Farinella1; ~Antonino_Furnari1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/e8545aa9cc5e85cbdecbf8cedc425a8db3470a74.pdf,2024-05-14T16:26:52.001000,2024-09-25T18:12:48.978000,2025-01-09T10:19:43.441000,https://openreview.net/forum?id=2HvgvB4aWq,University of Catania; University of Catania; University of Catania
1709,6YIpvnkjUK,6YIpvnkjUK,11334,The Sample-Communication Complexity Trade-off in Federated Q-Learning,"We consider the problem of Federated Q-learning, where $M$ agents aim to collaboratively learn the optimal Q-function of an unknown infinite horizon Markov Decision Process with finite state and action spaces. We investigate the trade-off between sample and communication complexity for the widely used class of intermittent communication algorithms. We first establish the converse result, where we show that any Federated Q-learning that offers a linear speedup with respect to number of agents in sample complexity needs to incur a communication cost of at least $\Omega(\frac{1}{1-\gamma})$, where $\gamma$ is the discount factor. We also propose a new Federated Q-learning algorithm, called Fed-DVR-Q, which is the first Federated Q-learning algorithm to simultaneously achieve order-optimal sample and communication complexities. Thus, together these results provide a complete characterization of the sample-communication complexity trade-off in Federated Q-learning.",Sudeep Salgia; Yuejie Chi,~Sudeep_Salgia1; ~Yuejie_Chi1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/aa89287b43d0d38cc8ef9cd412964652a0b005cb.pdf,2024-05-14T16:20:32.322000,2024-09-25T18:12:47.905000,2024-11-06T06:18:57.786000,https://openreview.net/forum?id=6YIpvnkjUK,Carnegie Mellon University; Meta; Carnegie Mellon University
1710,vt2qkE1Oax,vt2qkE1Oax,11333,Learning Segmentation from Point Trajectories,"We consider the problem of segmenting objects in videos based on their motion and no other forms of supervision. Prior work has often approached this problem by using the principle of common fate, namely the fact that the motion of points that belong to the same object is strongly correlated. However, most authors have only considered instantaneous motion from optical flow. In this work, we present a way to train a segmentation network using long-term point trajectories as a supervisory signal to complement optical flow. The key difficulty is that long-term motion, unlike instantaneous motion, is difficult to model -- any parametric approximation is unlikely to capture complex motion patterns over long periods of time. We instead draw inspiration from subspace clustering approaches, proposing a loss function that seeks to group the trajectories into low-rank matrices where the motion of object points can be approximately explained as a linear combination of other point tracks. Our method outperforms the prior art on motion-based segmentation, which shows the utility of long-term motion and the effectiveness of our formulation.",Laurynas Karazija; Iro Laina; Christian Rupprecht; Andrea Vedaldi,~Laurynas_Karazija1; ~Iro_Laina1; ~Christian_Rupprecht1; ~Andrea_Vedaldi1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/59c057325ef06b75796a650f052e761c2c377f1e.pdf,2024-05-14T16:20:31.958000,2024-09-25T18:12:47.856000,2024-11-06T06:18:57.745000,https://openreview.net/forum?id=vt2qkE1Oax,University of Oxford; University of Oxford; University of Oxford; Meta; University of Oxford
1738,1F32iCJFfa,1F32iCJFfa,11179,Schrodinger Bridge Flow for Unpaired Data Translation,"Mass transport problems arise in many areas of machine learning whereby one wants to compute a map transporting one distribution to another. Generative modeling techniques like Generative Adversarial Networks (GANs) and Denoising Diffusion Models (DMMs) have been successfully adapted to solve such transport problems, resulting in CycleGAN and Bridge Matching respectively. However, these methods do not approximate Optimal Transport (OT) maps, which are known to have desirable properties. Existing techniques approximating OT maps for high-dimensional data-rich problems, including DDMs-based Rectified Flow and Schrodinger bridge procedures, require fully training a DDM-type model at each iteration, or use mini-batch techniques which can introduce significant errors. We propose a novel algorithm to compute the Schrodinger bridge, a dynamic entropy-regularized version of OT, that eliminates the need to train multiple DDMs-like models. This algorithm corresponds to a discretization of a flow of path measures, referred to as the Schrodinger Bridge Flow, whose only stationary point is the Schrodinger bridge. We demonstrate the performance of our algorithm on a variety of unpaired data translation tasks.",Valentin De Bortoli; Iryna Korshunova; Andriy Mnih; Arnaud Doucet,~Valentin_De_Bortoli1; ~Iryna_Korshunova1; ~Andriy_Mnih1; ~Arnaud_Doucet2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/77d93fa2b59a9804b338c11221d5e859e8c0b395.pdf,2024-05-14T15:51:00.591000,2024-09-25T18:12:43.165000,2024-11-06T06:18:55.639000,https://openreview.net/forum?id=1F32iCJFfa,University of Oxford; Google; University of Oxford
1742,nd8Q4a8aWl,nd8Q4a8aWl,11166,A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models,"High-dimensional data commonly lies on low-dimensional submanifolds, and estimating the local intrinsic dimension (LID) of a datum -- i.e. the dimension of the submanifold it belongs to -- is a longstanding problem. LID can be understood as the number of local factors of variation: the more factors of variation a datum has, the more complex it tends to be. Estimating this quantity has proven useful in contexts ranging from generalization in neural networks to detection of out-of-distribution data, adversarial examples, and AI-generated text. The recent successes of deep generative models present an opportunity to leverage them for LID estimation, but current methods based on generative models produce inaccurate estimates, require more than a single pre-trained model, are computationally intensive, or do not exploit the best available deep generative models: diffusion models (DMs). In this work, we show that the Fokker-Planck equation associated with a DM can provide an LID estimator which addresses the aforementioned deficiencies. Our estimator, called FLIPD, is easy to implement and compatible with all popular DMs. Applying FLIPD to synthetic LID estimation benchmarks, we find that DMs implemented as fully-connected networks are highly effective LID estimators that outperform existing baselines. We also apply FLIPD to natural images where the true LID is unknown. Despite being sensitive to the choice of network architecture, FLIPD estimates remain a useful measure of relative complexity; compared to competing estimators, FLIPD exhibits a consistently higher correlation with image PNG compression rate and better aligns with qualitative assessments of complexity. Notably, FLIPD is orders of magnitude faster than other LID estimators, and the first to be tractable at the scale of Stable Diffusion.",Hamidreza Kamkari; Brendan Leigh Ross; Rasa Hosseinzadeh; Jesse C. Cresswell; Gabriel Loaiza-Ganem,~Hamidreza_Kamkari1; ~Brendan_Leigh_Ross1; ~Rasa_Hosseinzadeh2; ~Jesse_C._Cresswell1; ~Gabriel_Loaiza-Ganem1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/2923abb88a8b518f873227827f652a291f04f8ac.pdf,2024-05-14T15:48:48.930000,2024-09-25T18:12:42.662000,2024-11-06T06:18:55.519000,https://openreview.net/forum?id=nd8Q4a8aWl,Department of Computer Science; Layer6; Layer6; Layer6; Layer6
1770,JZHFRLoqDq,JZHFRLoqDq,11017,Energy-Guided Continuous Entropic Barycenter Estimation for General Costs,"Optimal transport (OT) barycenters are a mathematically grounded way of averaging probability distributions while capturing their geometric properties. In short, the barycenter task is to take the average of a collection of probability distributions w.r.t. given OT discrepancies. We propose a novel algorithm for approximating the continuous Entropic OT (EOT) barycenter for arbitrary OT cost functions. Our approach is built upon the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Beyond its novelty, our method enjoys several advantageous properties: (i) we establish quality bounds for the recovered solution; (ii) this approach seamlessly interconnects with the Energy-Based Models (EBMs) learning procedure enabling the use of well-tuned algorithms for the problem of interest; (iii) it provides an intuitive optimization scheme avoiding min-max, reinforce and other intricate technical tricks. For validation, we consider several low-dimensional scenarios and image-space setups, including *non-Euclidean* cost functions. Furthermore, we investigate the practical task of learning the barycenter on an image manifold generated by a pretrained generative model, opening up new directions for real-world applications. Our code is available at https://github.com/justkolesov/EnergyGuidedBarycenters.",Alexander Kolesov; Petr Mokrov; Igor Udovichenko; Milena Gazdieva; Gudmund Pammer; Anastasis Kratsios; Evgeny Burnaev; Alexander Korotin,~Alexander_Kolesov1; ~Petr_Mokrov1; ~Igor_Udovichenko1; ~Milena_Gazdieva1; ~Gudmund_Pammer1; ~Anastasis_Kratsios1; ~Evgeny_Burnaev1; ~Alexander_Korotin2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/8a3d14501d261370c0dc6e3b263ec38030e5e039.pdf,2024-05-14T15:22:19.208000,2024-09-25T18:12:38.017000,2025-01-14T20:48:25.393000,https://openreview.net/forum?id=JZHFRLoqDq,Institute of AI for Industries; The Skolkovo Institute of Science and Technology; Institute of AI for Industries; The Skolkovo Institute of Science and Technology; The Skolkovo Institute of Science and Technology; Lomonosov Moscow State University; The Skolkovo Institute of Science and Technology; Applied AI Institute; McMaster University; Vector Institute; The Skolkovo Institute of Science and Technology; The Skolkovo Institute of Science and Technology
1780,3kDWoqs2X2,3kDWoqs2X2,10953,Fearless Stochasticity in Expectation Propagation,"Expectation propagation (EP) is a family of algorithms for performing approximate inference in probabilistic models. The updates of EP involve the evaluation of moments—expectations of certain functions—which can be estimated from Monte Carlo (MC) samples. However, the updates are not robust to MC noise when performed naively, and various prior works have attempted to address this issue in different ways. In this work, we provide a novel perspective on the moment-matching updates of EP; namely, that they perform natural-gradient-based optimisation of a variational objective. We use this insight to motivate two new EP variants, with updates that are particularly well-suited to MC estimation. They remain stable and are most sample-efficient when estimated with just a single sample. These new variants combine the benefits of their predecessors and address key weaknesses. In particular, they are easier to tune, offer an improved speed-accuracy trade-off, and do not rely on the use of debiasing estimators. We demonstrate their efficacy on a variety of probabilistic inference tasks.",Jonathan So; Richard E. Turner,~Jonathan_So1; ~Richard_E_Turner1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/9f86868adf9d1f6c11405bd0f87e0b55ccf1777a.pdf,2024-05-14T15:10:33.949000,2024-09-25T18:12:36.344000,2024-11-06T06:18:53.836000,https://openreview.net/forum?id=3kDWoqs2X2,Alan Turing Institute; Microsoft; University of Cambridge
1794,aJGKs7QOZM,aJGKs7QOZM,10911,Mechanism design augmented with output advice,"Our work revisits the design of mechanisms via the learning-augmented framework. In this model, the algorithm is enhanced with imperfect (machine-learned) information concerning the input, usually referred to as prediction. The goal is to design algorithms whose performance degrades gently as a function of the prediction error and, in particular, perform well if the prediction is accurate, but also provide a worst-case guarantee under any possible error. This framework has been successfully applied recently to various mechanism design settings, where in most cases the mechanism is provided with a prediction about the types of the players.

We adopt a perspective in which the mechanism is provided with an output recommendation. We make no assumptions about the quality of the suggested outcome, and the goal is to use the recommendation to design mechanisms with low approximation guarantees whenever the recommended outcome is reasonable, but at the same time to provide worst-case guarantees whenever the recommendation significantly deviates from the optimal one. We propose a generic, universal measure, which we call quality of recommendation, to evaluate mechanisms across various information settings. We demonstrate how this new metric can provide refined analysis in existing results.

This model introduces new challenges, as the mechanism receives limited information comparing to settings that use predictions about the types of the agents. We study, through this lens, several well-studied mechanism design paradigms, devising new mechanisms, but also providing refined analysis for existing ones, using as a metric the quality of recommendation. We complement our positive results, by exploring the limitations of known classes of strategyproof mechanisms that can be devised using output recommendation.",George Christodoulou; Alkmini Sgouritsa; Ioannis Vlachos,~George_Christodoulou1; ~Alkmini_Sgouritsa2; ~Ioannis_Vlachos1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/2739d14377dfe60e1d1dd30edf79c73a2d34ddc2.pdf,2024-05-14T15:02:26.555000,2024-09-25T18:12:34.676000,2024-11-06T06:18:53.181000,https://openreview.net/forum?id=aJGKs7QOZM,Aristotle University of Thessaloniki; Athena Research and Innovation Center; Athens University of Economics and Business; Athens University of Economics and Business
1825,NadTwTODgC,NadTwTODgC,10737,Diffusion for World Modeling: Visual Details Matter in Atari,"World models constitute a promising approach for training reinforcement learning agents in a safe and sample-efficient manner. Recent world models predominantly operate on sequences of discrete latent variables to model environment dynamics. However, this compression into a compact discrete representation may ignore visual details that are important for reinforcement learning. Concurrently, diffusion models have become a dominant approach for image generation, challenging well-established methods modeling discrete latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model. We analyze the key design choices that are required to make diffusion suitable for world modeling, and demonstrate how improved visual details can lead to improved agent performance. DIAMOND achieves a mean human normalized score of 1.46 on the competitive Atari 100k benchmark; a new best for agents trained entirely within a world model. We further demonstrate that DIAMOND's diffusion world model can stand alone as an interactive neural game engine by training on static *Counter-Strike: Global Offensive* gameplay. To foster future research on diffusion for world modeling, we release our code, agents, videos and playable world models at https://diamond-wm.github.io.",Eloi Alonso; Adam Jelley; Vincent Micheli; Anssi Kanervisto; Amos Storkey; Tim Pearce; François Fleuret,~Eloi_Alonso1; ~Adam_Jelley1; ~Vincent_Micheli1; ~Anssi_Kanervisto1; ~Amos_Storkey1; ~Tim_Pearce1; ~François_Fleuret2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/1b9c235f902c699233e7888fcac99bfda7b3e134.pdf,2024-05-14T14:32:42.435000,2024-09-25T18:12:29.956000,2024-11-06T06:18:51.770000,https://openreview.net/forum?id=NadTwTODgC,University of Edinburgh; Meta; Microsoft; University of Geneva; Meta
1837,3EREVfwALz,3EREVfwALz,10645,Multiclass Transductive Online Learning,"We consider the problem of multiclass transductive online learning when the number of labels can be unbounded. Previous works by  Ben-David et al. [1997] and Hanneke et al. [2024] only consider the case of binary and finite label spaces respectively.  The latter work determined that their techniques fail to extend to the case of unbounded label spaces, and they pose the question of characterizing the optimal mistake bound for unbounded label spaces. We answer this question, by showing that a new dimension, termed the Level-constrained Littlestone dimension, characterizes online learnability in this setting. Along the way, we show that the trichotomy of possible minimax rates established by Hanneke et al. [2024] for finite label spaces in the realizable setting continues to hold even when the label space is unbounded. In particular, if the learner plays for $T \in \mathbb{N}$ rounds, its minimax expected number of mistakes can only grow like $\Theta(T)$, $\Theta(\log T)$, or $\Theta(1)$. To prove this result, we give another combinatorial dimension, termed the Level-constrained Branching dimension, and show that its finiteness characterizes constant minimax expected mistake-bounds. The trichotomy is then determined by a combination of the Level-constrained Littlestone and Branching dimensions. Quantitatively, our upper bounds improve upon existing multiclass upper bounds in Hanneke et al. [2024] by removing the dependence on the label set size. In doing so, we explicitly construct learning algorithms that can handle extremely large or unbounded label spaces. A key component of our algorithm is a new notion of shattering that exploits the sequential nature of transductive online learning. Finally, we complete our results by proving expected regret bounds in the agnostic setting, extending the result of Hanneke et al. [2024].",Steve Hanneke; Vinod Raman; Amirreza Shaeiri; Unique Subedi,~Steve_Hanneke1; ~Vinod_Raman1; ~Amirreza_Shaeiri1; ~Unique_Subedi2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,online_learning,/pdf/c82a4ade065fe17fce069e9081298a24c00a43ee.pdf,2024-05-14T14:18:14.508000,2024-09-25T18:12:27.295000,2024-11-06T06:18:51.278000,https://openreview.net/forum?id=3EREVfwALz,Purdue University; Apple; University of Michigan - Ann Arbor; Purdue University
1847,OQzCSb6fbl,OQzCSb6fbl,10594,Parallel Backpropagation for Shared-Feature Visualization,"High-level visual brain regions contain subareas in which neurons appear to respond more strongly to examples of a particular semantic category, like faces or bodies, rather than objects. However, recent work has shown that while this finding holds on average, some out-of-category stimuli also activate neurons in these regions. This may be due to visual features common among the preferred class also being present in other images. Here, we propose a deep-learning-based approach for visualizing these features. For each neuron, we identify relevant visual features driving its selectivity by modelling responses to images based on latent activations of a deep neural network. Given an out-of-category image which strongly activates the neuron, our method first identifies a reference image from the preferred category yielding a similar feature activation pattern. We then backpropagate latent activations of both images to the pixel level, while enhancing the identified shared dimensions and attenuating non-shared features. The procedure highlights image regions containing shared features driving responses of the model neuron. We apply the algorithm to novel recordings from body-selective regions in macaque IT cortex in order to understand why some images of objects excite these neurons. Visualizations reveal object parts which resemble parts of a macaque body, shedding light on neural preference of these objects.",Alexander Lappe; Anna Bognár; Ghazaleh Ghamkhari Nejad; Albert Mukovskiy; Lucas Martini; Martin A. Giese; Rufin Vogels,~Alexander_Lappe1; ~Anna_Bognár1; ~Ghazaleh_Ghamkhari_Nejad1; ~Albert_Mukovskiy1; ~Lucas_Martini1; ~Martin_A._Giese1; ~Rufin_Vogels1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/9c9d42ca28caaffd7840c01e93e98f77c1f5ffa0.pdf,2024-05-14T14:07:17.870000,2024-09-25T18:12:25.937000,2024-11-06T06:18:50.742000,https://openreview.net/forum?id=OQzCSb6fbl,University of Tübingen; KU Leuven; University of Tübingen; University of Tübingen; University of Tübingen
1853,FTPDBQuT4G,FTPDBQuT4G,10553,Generalized Linear Bandits with Limited Adaptivity,"We study the generalized linear contextual bandit problem within the constraints of limited adaptivity.  In this paper, we present two algorithms, B-GLinCB and RS-GLinCB, that address, respectively, two prevalent limited adaptivity settings. Given a budget $M$ on the number of policy updates, in the first setting, the algorithm needs to decide upfront $M$ rounds at which it will update its policy, while in the second setting it can adaptively perform $M$ policy updates during its course. For the first setting, we design an algorithm B-GLinCB, that incurs $\tilde{O}(\sqrt{T})$ regret when $M = \Omega( \log{\log T} )$ and the arm feature vectors are generated stochastically. For the second setting, we design an algorithm RS-GLinCB that updates its policy $\tilde{O}(\log^2 T)$ times and achieves a regret of $\tilde{O}(\sqrt{T})$ even when the arm feature vectors are adversarially generated. Notably, in these bounds, we manage to eliminate the dependence on a key instance dependent parameter $\kappa$, that captures non-linearity of the underlying reward model. Our novel approach for removing this dependence for generalized linear contextual bandits might be of independent interest.",Ayush Sawarni; Nirjhar Das; Siddharth Barman; Gaurav Sinha,~Ayush_Sawarni1; ~Nirjhar_Das1; ~Siddharth_Barman1; ~Gaurav_Sinha2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,bandits,/pdf/e2e8732933515749d301bfc2d477bffdf36dc55d.pdf,2024-05-14T14:00:55.993000,2024-09-25T18:12:24.550000,2025-01-15T19:19:04.600000,https://openreview.net/forum?id=FTPDBQuT4G,"Indian Institute of Science, Bangalore; Microsoft; Indian Institute of Science, Bangalore; Microsoft"
1858,bg6fVPVs3s,bg6fVPVs3s,10530,Guiding a Diffusion Model with a Bad Version of Itself,"The primary axes of interest in image-generating diffusion models are image quality, the amount of variation in the results, and how well the results align with a given condition, e.g., a class label or a text prompt. The popular classifier-free guidance approach uses an unconditional model to guide a conditional model, leading to simultaneously better prompt alignment and higher-quality images at the cost of reduced variation. These effects seem inherently entangled, and thus hard to control. We make the surprising observation that it is possible to obtain disentangled control over image quality without compromising the amount of variation by guiding generation using a smaller, less-trained version of the model itself rather than an unconditional model. This leads to significant improvements in ImageNet generation, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using publicly available networks. Furthermore, the method is also applicable to unconditional diffusion models, drastically improving their quality.",Tero Karras; Miika Aittala; Tuomas Kynkäänniemi; Jaakko Lehtinen; Timo Aila; Samuli Laine,~Tero_Karras1; ~Miika_Aittala2; ~Tuomas_Kynkäänniemi1; ~Jaakko_Lehtinen1; ~Timo_Aila1; ~Samuli_Laine1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/9173da6000cdac7dc5129691366a29747954b7ef.pdf,2024-05-14T13:56:47.077000,2024-09-25T18:12:23.796000,2024-12-19T10:32:45.938000,https://openreview.net/forum?id=bg6fVPVs3s,NVIDIA; NVIDIA; Aalto University; Aalto University; NVIDIA; NVIDIA; NVIDIA
1912,ARAxPPIAhq,ARAxPPIAhq,10290,xLSTM: Extended Long Short-Term Memory,"In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models (LLMs). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing LSTMs at scale.  We now raise a simple question: How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these LSTM extensions into residual block backbones yields xLSTM blocks that are then residually stacked into xLSTM architectures. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.",Maximilian Beck; Korbinian Pöppel; Markus Spanring; Andreas Auer; Oleksandra Prudnikova; Michael K Kopp; Günter Klambauer; Johannes Brandstetter; Sepp Hochreiter,~Maximilian_Beck1; ~Korbinian_Pöppel1; ~Markus_Spanring1; ~Andreas_Auer2; ~Oleksandra_Prudnikova1; ~Michael_K_Kopp1; ~Günter_Klambauer1; ~Johannes_Brandstetter1; ~Sepp_Hochreiter1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/894b4a0df8086a0e0ef896f51bcaf46f4bf55caa.pdf,2024-05-14T13:17:26.365000,2024-09-25T18:12:15.268000,2024-11-06T06:18:47.782000,https://openreview.net/forum?id=ARAxPPIAhq,", Johannes Kepler Universität Linz; , Johannes Kepler Universität Linz; , Johannes Kepler Universität Linz; Amazon; , Johannes Kepler Universität Linz; Nirmata Research LLP; , Johannes Kepler Universität Linz; , Johannes Kepler Universität Linz; xAI; Microsoft; , Johannes Kepler Universität Linz"
1922,o4coDIby7e,o4coDIby7e,10250,Measuring Goal-Directedness,"We define maximum entropy goal-directedness (MEG), a formal measure of goal-
directedness in causal models and Markov decision processes, and give algorithms
for computing it. Measuring goal-directedness is important, as it is a critical
element of many concerns about harm from AI. It is also of philosophical interest,
as goal-directedness is a key aspect of agency. MEG is based on an adaptation of
the maximum causal entropy framework used in inverse reinforcement learning. It
can measure goal-directedness with respect to a known utility function, a hypothesis
class of utility functions, or a set of random variables. We prove that MEG satisfies
several desiderata and demonstrate our algorithms with small-scale experiments.",Matt MacDermott; James Fox; Francesco Belardinelli; Tom Everitt,~Matt_MacDermott1; ~James_Fox2; ~Francesco_Belardinelli1; ~Tom_Everitt1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/a707011020a1a19716c8f5b5955810a063baced4.pdf,2024-05-14T13:10:01.764000,2024-09-25T18:12:13.859000,2024-11-06T06:18:47.384000,https://openreview.net/forum?id=o4coDIby7e,Montreal Institute of Learning Algorithms; Imperial College London
1931,qGiZQb1Khm,qGiZQb1Khm,10211,Watermarking Makes Language Models Radioactive,"We investigate the radioactivity of text generated by large language models (LLM), \ie whether it is possible to detect that such synthetic input was used to train a subsequent LLM.
Current methods like membership inference or active IP protection either work only in settings where the suspected text is known or do not provide reliable statistical guarantees.
We discover that, on the contrary, it is possible to reliably determine if a language model was trained on synthetic data if that data is output by a watermarked LLM.
Our new methods, specialized for radioactivity, detects with a provable confidence weak residuals of the watermark signal in the fine-tuned LLM.
We link the radioactivity contamination level to the following properties: the watermark robustness, its proportion in the training set, and the fine-tuning process.
For instance, if the suspect model is open-weight, we demonstrate that training on watermarked instructions can be detected with high confidence ($p$-value $< 10^{-5}$) even when as little as $5\%$ of training text is watermarked.",Tom Sander; Pierre Fernandez; Alain Oliviero Durmus; Matthijs Douze; Teddy Furon,~Tom_Sander1; ~Pierre_Fernandez1; ~Alain_Oliviero_Durmus1; ~Matthijs_Douze1; ~Teddy_Furon1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/c64b470e2896272a99180a7d3ad4df270ed3e516.pdf,2024-05-14T13:01:22.809000,2024-09-25T18:12:12.794000,2024-11-06T06:18:46.927000,https://openreview.net/forum?id=qGiZQb1Khm,"École Polytechnique; Meta; Université Rennes 1; Meta; Meta; Inria, Paris"
1940,4NQ24cHnOi,4NQ24cHnOi,10169,"Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust","We give the first polynomial-time, differentially node-private, and robust algorithm for estimating the edge density of Erdős-Rényi random graphs and their generalization, inhomogeneous random graphs. We further prove information-theoretical lower bounds, showing that the error rate of our algorithm is optimal up to logarithmic factors. Previous algorithms incur either exponential running time or suboptimal error rates.

Two key ingredients of our algorithm are (1) a new sum-of-squares algorithm for robust edge density estimation, and (2) the reduction from privacy to robustness based on sum-of-squares exponential mechanisms due to Hopkins et al. (STOC 2023).",Hongjie Chen; Jingqiu Ding; Yiding Hua; David Steurer,~Hongjie_Chen2; ~Jingqiu_Ding1; ~Yiding_Hua1; ~David_Steurer1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/746023b01d20da2550974768ab0fe6102a7ae315.pdf,2024-05-14T12:53:31.837000,2024-09-25T18:12:11.507000,2024-11-06T06:18:46.479000,https://openreview.net/forum?id=4NQ24cHnOi,ETH Zurich; ETH Zurich
1959,ZZ94aLbMOK,ZZ94aLbMOK,10040,Recurrent neural network dynamical systems for biological vision,"In neuroscience, recurrent neural networks (RNNs) are modeled as continuous-time dynamical systems to more accurately reflect the dynamics inherent in biological circuits. However, convolutional neural networks (CNNs) remain the preferred architecture in vision neuroscience due to their ability to efficiently process visual information, which comes at the cost of the biological realism provided by RNNs. To address this, we introduce a hybrid architecture that integrates the continuous-time recurrent dynamics of RNNs with the spatial processing capabilities of CNNs. Our models preserve the dynamical characteristics typical of RNNs while having comparable performance with their conventional CNN counterparts on benchmarks like ImageNet. Compared to conventional CNNs, our models demonstrate increased robustness to noise due to noise-suppressing mechanisms inherent in recurrent dynamical systems. Analyzing our architecture as a dynamical system is computationally expensive, so we develop a toolkit consisting of iterative methods specifically tailored for convolutional structures. We also train multi-area RNNs using our architecture as the front-end to perform complex cognitive tasks previously impossible to learn or achievable only with oversimplified stimulus representations. In monkey neural recordings, our models capture time-dependent variations in neural activity in higher-order visual areas. Together, these contributions represent a comprehensive foundation to unify the advances of CNNs and dynamical RNNs in vision neuroscience.",Wayne WM Soo; Aldo Battista; Puria Radmard; Xiao-Jing Wang,~Wayne_WM_Soo1; ~Aldo_Battista1; ~Puria_Radmard1; ~Xiao-Jing_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/f14dee881923cdf1c11e22c63ad009adeda19819.pdf,2024-05-14T12:23:38.582000,2024-09-25T18:12:08.242000,2024-12-20T05:13:20.359000,https://openreview.net/forum?id=ZZ94aLbMOK,New York University
1961,6vNPPtWH1Q,6vNPPtWH1Q,10036,Energy-based Epistemic Uncertainty for Graph Neural Networks,"In domains with interdependent data, such as graphs, quantifying the epistemic uncertainty of a Graph Neural Network (GNN) is challenging as uncertainty can arise at different structural scales. Existing techniques neglect this issue or only distinguish between structure-aware and structure-agnostic uncertainty without combining them into a single measure. We propose GEBM, an energy-based model (EBM) that provides high-quality uncertainty estimates by aggregating energy at different structural levels that naturally arise from graph diffusion. In contrast to logit-based EBMs, we provably induce an integrable density in the data space by regularizing the energy function. We introduce an evidential interpretation of our EBM that significantly improves the predictive robustness of the GNN. Our framework is a simple and effective post hoc method applicable to any pre-trained GNN that is sensitive to various distribution shifts. It consistently achieves the best separation of in-distribution and out-of-distribution data on 6 out of 7 anomaly types while having the best average rank over shifts on *all* datasets.",Dominik Fuchsgruber; Tom Wollschläger; Stephan Günnemann,~Dominik_Fuchsgruber1; ~Tom_Wollschläger1; ~Stephan_Günnemann1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/1d717d769b57f5f603b995bc1c814f0ba4f47c2f.pdf,2024-05-14T12:22:33.337000,2024-09-25T18:12:08.118000,2024-11-06T06:18:45.578000,https://openreview.net/forum?id=6vNPPtWH1Q,Technical University of Munich; Valence Labs powered by recursion; Technical University of Munich; Technical University of Munich
1963,5NMbQPY7Bn,5NMbQPY7Bn,10021,TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment,"Recent advancements in image understanding have benefited from the extensive use of web image-text pairs. However, video understanding remains a challenge despite the availability of substantial web video-text data. This difficulty primarily arises from the inherent complexity of videos and the inefficient language supervision in recent web-collected video-text datasets. In this paper, we introduce Text-Only Pre-Alignment (TOPA), a novel approach to extend large language models (LLMs) for video understanding, without the need for pre-training on real video data. Specifically, we first employ an advanced LLM to automatically generate Textual Videos comprising continuous textual frames, along with corresponding annotations to simulate real video-text data. Then, these annotated textual videos are used to pre-align a language-only LLM with the video modality. To bridge the gap between textual and real videos, we employ the CLIP model as the feature extractor to align image and text modalities. During text-only pre-alignment, the continuous textual frames, encoded as a sequence of CLIP text features, are analogous to continuous CLIP image features, thus aligning the LLM with real video representation. Extensive experiments, including zero-shot evaluation and finetuning on various video understanding tasks, demonstrate that TOPA is an effective and efficient framework for aligning video content with LLMs. In particular, without training on any video data, the TOPA-Llama2-13B model achieves a Top-1 accuracy of 51.0% on the challenging long-form video understanding benchmark, Egoschema. This performance surpasses previous video-text pre-training approaches and proves competitive with recent GPT-3.5 based video agents.",Wei Li; Hehe Fan; Yongkang Wong; Mohan Kankanhalli; Yi Yang,~Wei_Li55; ~Hehe_Fan1; ~Yongkang_Wong1; ~Mohan_Kankanhalli1; ~Yi_Yang4,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/6981f892085bf5bded01c7caf3adde407ca7198f.pdf,2024-05-14T12:20:16.387000,2024-09-25T18:12:07.784000,2024-11-06T06:18:45.487000,https://openreview.net/forum?id=5NMbQPY7Bn,Zhejiang University; National University of Singapore; Zhejiang University; National University of Singapore; National University of Singapore; Zhejiang University
1968,p43ObIwJFW,p43ObIwJFW,9995,Learning to Solve Quadratic Unconstrained Binary Optimization in a Classification Way,"The quadratic unconstrained binary optimization (QUBO) is a well-known NP-hard problem that takes an $n\times n$ matrix $Q$ as input and decides an $n$-dimensional 0-1 vector $x$, to optimize a quadratic function. Existing learning-based models that always formulate the solution process as sequential decisions suffer from high computational overload. To overcome this issue, we propose a neural solver called the Value Classification Model (VCM) that formulates the solution process from a classification perspective. It applies a Depth Value Network (DVN) based on graph convolution that exploits the symmetry property in $Q$ to auto-grasp value features. These features are then fed into a Value Classification Network (VCN) which directly generates classification solutions. Trained by a highly efficient model-tailored Greedy-guided Self Trainer (GST) which does not require any priori optimal labels, VCM significantly outperforms competitors in both computational efficiency and solution quality with a remarkable generalization ability. It can achieve near-optimal solutions in milliseconds with an average optimality gap of just 0.362\% on benchmarks with up to 2500 variables. Notably, a VCM trained at a specific DVN depth can steadily find better solutions by simply extending the testing depth, which narrows the gap to 0.034\% on benchmarks. To our knowledge, this is the first learning-based model to reach such a performance.",Ming Chen; Jie Chun; Shang Xiang; Luona Wei; Yonghao Du; Qian Wan; Yuning Chen; Yingwu Chen,~Ming_Chen17; ~Jie_Chun1; ~Shang_Xiang1; ~Luona_Wei1; ~Yonghao_Du1; ~Qian_Wan2; ~Yuning_Chen2; ~Yingwu_Chen2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/5ac36f107f507f095117ea3f08a401ea0fc342a9.pdf,2024-05-14T12:14:51.343000,2024-09-25T18:12:07.007000,2024-11-06T06:18:45.292000,https://openreview.net/forum?id=p43ObIwJFW,National University of Defense Technology; South-Central Minzu University; Central China Normal University
1970,wTIzpqX121,wTIzpqX121,9990,Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks,"In recent years, machine learning has established itself as a powerful tool for high-resolution weather forecasting. While most current machine learning models focus on deterministic forecasts, accurately capturing the uncertainty in the chaotic weather system calls for probabilistic modeling. We propose a probabilistic weather forecasting model called Graph-EFM, combining a flexible latent-variable formulation with the successful graph-based forecasting framework. The use of a hierarchical graph construction allows for efficient sampling of spatially coherent forecasts. Requiring only a single forward pass per time step, Graph-EFM allows for fast generation of arbitrarily large ensembles. We experiment with the model on both global and limited area forecasting. Ensemble forecasts from Graph-EFM achieve equivalent or lower errors than comparable deterministic models, with the added benefit of accurately capturing forecast uncertainty.",Joel Oskarsson; Tomas Landelius; Marc Peter Deisenroth; Fredrik Lindsten,~Joel_Oskarsson1; ~Tomas_Landelius1; ~Marc_Peter_Deisenroth1; ~Fredrik_Lindsten1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/08914a753f1c9eaf87d2102390cab1b1f7a9663e.pdf,2024-05-14T12:13:32.141000,2024-09-25T18:12:06.835000,2024-11-06T06:18:45.232000,https://openreview.net/forum?id=wTIzpqX121,Linköping University; SMHI; Alan Turing Institute; University College London; Linköping University
1973,xabStWAUtr,xabStWAUtr,9984,Co-occurrence is not Factual Association in Language Models,"Pretrained language models can encode a large amount of knowledge and utilize it for various reasoning tasks, yet they can still struggle to learn novel factual knowledge effectively from finetuning on limited textual demonstrations. In this work, we show that the reason for this deficiency is that language models are biased to learn word co-occurrence statistics instead of true factual associations. We identify the differences between two forms of knowledge representation in language models: knowledge in the form of co-occurrence statistics is encoded in the middle layers of the transformer model and does not generalize well to reasoning scenarios beyond simple question answering, while true factual associations are encoded in the lower layers and can be freely utilized in various reasoning tasks. Based on these observations, we propose two strategies to improve the learning of factual associations in language models. We show that training on text with implicit rather than explicit factual associations can force the model to learn factual associations instead of co-occurrence statistics, significantly improving the generalization of newly learned knowledge. We also propose a simple training method to actively forget the learned co-occurrence statistics, which unblocks and enhances the learning of factual associations when training on plain narrative text. On both synthetic and real-world corpora, the two proposed strategies improve the generalization of the knowledge learned during finetuning to reasoning scenarios such as indirect and multi-hop question answering.",Xiao Zhang; Miao Li; Ji Wu,~Xiao_Zhang9; ~Miao_Li10; ~Ji_Wu3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/a05ca368d45ceff595e9950cf21de3cd1baf43fe.pdf,2024-05-14T12:12:41.814000,2024-09-25T18:12:06.504000,2025-01-16T10:20:25.689000,https://openreview.net/forum?id=xabStWAUtr,"Tsinghua University, Beijing; Tsinghua University, Beijing; Tsinghua University, Beijing"
1978,r5spnrY6H3,r5spnrY6H3,9950,RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation,"3D Referring Expression Segmentation (3D-RES) aims to segment 3D objects by correlating referring expressions with point clouds. However, traditional approaches frequently encounter issues like over-segmentation or mis-segmentation, due to insufficient emphasis on spatial information of instances. In this paper, we introduce a Rule-Guided Spatial Awareness Network (RG-SAN) by utilizing solely the spatial information of the target instance for supervision. This approach enables the network to accurately depict the spatial relationships among all entities described in the text, thus enhancing the reasoning capabilities. The RG-SAN consists of the Text-driven Localization Module (TLM) and the Rule-guided Weak Supervision (RWS) strategy. The TLM initially locates all mentioned instances and iteratively refines their positional information. The RWS strategy, acknowledging that only target objects have supervised positional information, employs dependency tree rules to precisely guide the core instance’s positioning. Extensive testing on the ScanRefer benchmark has shown that RG-SAN not only establishes new performance benchmarks, with an mIoU increase of 5.1 points, but also exhibits significant improvements in robustness when processing descriptions with spatial ambiguity. All codes are available at https://github.com/sosppxo/RG-SAN.",Changli Wu; Qi Chen; Jiayi Ji; Haowei Wang; Yiwei Ma; You Huang; Gen Luo; Hao Fei; Xiaoshuai Sun; Rongrong Ji,~Changli_Wu1; ~Qi_Chen17; ~Jiayi_Ji1; ~Haowei_Wang1; ~Yiwei_Ma1; ~You_Huang1; ~Gen_Luo1; ~Hao_Fei1; ~Xiaoshuai_Sun3; ~Rongrong_Ji5,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,human-AI_interaction,/pdf/074c8caaa0b5feabaad18b25db6c0ee86ed09863.pdf,2024-05-14T12:06:19.815000,2024-09-25T18:12:05.616000,2024-12-22T10:46:48.168000,https://openreview.net/forum?id=r5spnrY6H3,Xiamen University; Xiamen University; Xiamen University; National University of Singapore; Xiamen University; Tencent; Xiamen University; Xiamen University; Xiamen University; Shanghai Artificial Intelligence Laboratory; National University of Singapore; Xiamen University; Xiamen University
1980,2bdSnxeQcW,2bdSnxeQcW,9935,Exclusively Penalized Q-learning for Offline Reinforcement Learning,"Constraint-based offline reinforcement learning (RL) involves policy constraints or imposing penalties on the value function to mitigate overestimation errors caused by distributional shift. This paper focuses on a limitation in existing offline RL methods with penalized value function, indicating the potential for underestimation bias due to unnecessary bias introduced in the value function. To address this concern, we propose Exclusively Penalized Q-learning (EPQ), which reduces estimation bias in the value function by selectively penalizing states that are prone to inducing estimation errors. Numerical results show that our method significantly reduces underestimation bias and improves performance in various offline control tasks compared to other offline RL methods.",Junghyuk Yeom; Yonghyeon Jo; Jeongmo Kim; Sanghyeon Lee; Seungyul Han,~Junghyuk_Yeom1; ~Yonghyeon_Jo1; ~Jeongmo_Kim1; ~Sanghyeon_Lee5; ~Seungyul_Han1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/9c3bb8b1a229e4505ddfa9324ce3ec1e8eda68a6.pdf,2024-05-14T12:01:29.871000,2024-09-25T18:12:05.345000,2024-11-06T06:18:44.855000,https://openreview.net/forum?id=2bdSnxeQcW,Ulsan National Institute of Science and Technology; Ulsan National Institute of Science and Technology; Ulsan National Institute of Science and Technology; Ulsan National Institute of Science and Technology; Ulsan National Institute of Science and Technology
1992,shYQXpnBLB,shYQXpnBLB,9888,Association of Objects May Engender Stereotypes: Mitigating Association-Engendered Stereotypes in Text-to-Image Generation,"Text-to-Image (T2I) has witnessed significant advancements, demonstrating superior performance for various generative tasks. However, the presence of stereotypes in T2I introduces harmful biases that require urgent attention as the T2I 
 technology becomes more prominent.
Previous work for stereotype mitigation mainly concentrated on mitigating stereotypes engendered with individual objects within images, which failed to address stereotypes engendered by the association of multiple objects, referred to as *Association-Engendered Stereotypes*. For example, mentioning  ''black people'' and ''houses''  separately in prompts may not exhibit stereotypes. Nevertheless, when these two objects are associated in prompts, the association of ''black people'' with ''poorer houses'' becomes more pronounced. To tackle this issue, we propose a novel framework, MAS, to Mitigate Association-engendered Stereotypes. This framework models the stereotype problem as a probability distribution alignment problem, aiming to align the stereotype probability distribution of the generated image with the stereotype-free distribution. The MAS framework primarily consists of the *Prompt-Image-Stereotype CLIP* (*PIS CLIP*) and *Sensitive Transformer*. The *PIS CLIP* learns the association between prompts, images, and stereotypes, which can establish the mapping of prompts to stereotypes. The *Sensitive Transformer* produces the sensitive constraints, which guide the stereotyped image distribution to align with the stereotype-free probability distribution. Moreover, recognizing that existing metrics are insufficient for accurately evaluating association-engendered stereotypes, we propose a novel metric, *Stereotype-Distribution-Total-Variation*(*SDTV*), to evaluate stereotypes in T2I. Comprehensive experiments demonstrate that our framework effectively mitigates association-engendered stereotypes.",Junlei Zhou; Jiashi Gao; Xiangyu Zhao; Xin Yao; Xuetao Wei,~Junlei_Zhou4; ~Jiashi_Gao1; ~Xiangyu_Zhao1; ~Xin_Yao1; ~Xuetao_Wei2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/204050fa8d15e07a423f0a1184f86bf90d8f7cf8.pdf,2024-05-14T11:50:22.898000,2024-09-25T18:12:03.819000,2025-01-13T01:30:22.167000,https://openreview.net/forum?id=shYQXpnBLB,Southern University of Science and Technology; Southern University of Science and Technology; City University of Hong Kong; Southern University of Science and Technology
2023,5zSCSE0k41,5zSCSE0k41,9714,VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time,"We introduce VASA, a framework for generating lifelike talking faces with appealing visual affective skills (VAS) given a single static image and a speech audio clip. Our premiere model, VASA-1, is capable of not only generating lip movements that are exquisitely synchronized with the audio, but also producing a large spectrum of facial nuances and natural head motions that contribute to the perception of authenticity and liveliness. 
The core innovations include a diffusion-based holistic facial dynamics and head movement generation model that works in a face latent space, and the development of such an expressive and disentangled face latent space using videos.
Through extensive experiments including evaluation on a set of new metrics, we show that our method significantly outperforms previous methods along various dimensions comprehensively. Our method delivers high video quality with realistic facial and head dynamics and also supports the online generation of 512$\times$512 videos at up to 40 FPS with negligible starting latency.
It paves the way for real-time engagements with lifelike avatars that emulate human conversational behaviors.",Sicheng Xu; Guojun Chen; Yu-Xiao Guo; Jiaolong Yang; Chong Li; Zhenyu Zang; Yizhong Zhang; Xin Tong; Baining Guo,~Sicheng_Xu1; ~Guojun_Chen1; ~Yu-Xiao_Guo1; ~Jiaolong_Yang3; ~Chong_Li8; ~Zhenyu_Zang1; ~Yizhong_Zhang1; ~Xin_Tong1; ~Baining_Guo1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,generative_models,/pdf/ccbb9d0f4688567aed95ad757cf65f0dd4538631.pdf,2024-05-14T11:01:02.426000,2024-09-25T18:11:58.879000,2024-11-06T06:18:42.902000,https://openreview.net/forum?id=5zSCSE0k41,Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Anuttacon; Microsoft
2036,1we1V3MAHD,1we1V3MAHD,9629,MotionBooth: Motion-Aware Customized Text-to-Video Generation,"In this work, we present MotionBooth, an innovative framework designed for animating customized subjects with precise control over both object and camera movements. By leveraging a few images of a specific object, we efficiently fine-tune a text-to-video model to capture the object's shape and attributes accurately. Our approach presents subject region loss and video preservation loss to enhance the subject's learning performance, along with a subject token cross-attention loss to integrate the customized subject with motion control signals. Additionally, we propose training-free techniques for managing subject and camera motions during inference. In particular, we utilize cross-attention map manipulation to govern subject motion and introduce a novel latent shift module for camera movement control as well. MotionBooth excels in preserving the appearance of subjects while simultaneously controlling the motions in generated videos. Extensive quantitative and qualitative evaluations demonstrate the superiority and effectiveness of our method. Models and codes will be made publicly available.",Jianzong Wu; Xiangtai Li; Yanhong Zeng; Jiangning Zhang; Qianyu Zhou; Yining Li; Yunhai Tong; Kai Chen,~Jianzong_Wu2; ~Xiangtai_Li1; ~Yanhong_Zeng1; ~Jiangning_Zhang1; ~Qianyu_Zhou1; ~Yining_Li1; ~Yunhai_Tong1; ~Kai_Chen4,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/a3f3aa90fe0891b06247e492408e30d8fb44fe1b.pdf,2024-05-14T10:37:51.727000,2024-09-25T18:11:56.736000,2024-11-06T06:18:42.383000,https://openreview.net/forum?id=1we1V3MAHD,Peking University; Nanyang Technological University; ByteDance Inc.; Shanghai Artificial Intelligence Laboratory; Tencent; Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory; Peking University; Shanghai Artificial Intelligence Laboratory
2059,bhSfbjS6j9,bhSfbjS6j9,9508,Multistable Shape from Shading Emerges from Patch Diffusion,"Models for inferring monocular shape of surfaces with diffuse reflection---shape from shading---ought to produce distributions of outputs, because there are fundamental mathematical ambiguities of both continuous (e.g., bas-relief) and discrete (e.g., convex/concave) types that are also experienced by humans. Yet, the outputs of current models are limited to point estimates or tight distributions around single modes, which prevent them from capturing these effects. We introduce a model that reconstructs a multimodal distribution of shapes from a single shading image, which aligns with the human experience of multistable perception. We train a small denoising diffusion process to generate surface normal fields from $16\times 16$ patches of synthetic images of everyday 3D objects. We deploy this model patch-wise at multiple scales, with guidance from inter-patch shape consistency constraints. Despite its relatively small parameter count and predominantly bottom-up structure, we show that multistable shape explanations emerge from this model for ambiguous test images that humans experience as being multistable. At the same time, the model produces veridical shape estimates for object-like images that include distinctive occluding contours and appear less ambiguous. This may inspire new architectures for stochastic 3D shape perception that are more efficient and better aligned with human experience.",Xinran Han; Todd Zickler; Ko Nishino,~Xinran_Han1; ~Todd_Zickler1; ~Ko_Nishino4,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/c9b76d94959e0592a0305f254bcce8d77a7d3aff.pdf,2024-05-14T10:00:33.823000,2024-09-25T18:11:53.169000,2024-11-06T06:18:41.412000,https://openreview.net/forum?id=bhSfbjS6j9,Harvard University; Harvard University; Kyoto University
2073,QDYts5dYgq,QDYts5dYgq,9449,Learning rigid-body simulators over implicit shapes for large-scale scenes and vision,"Simulating large scenes with many rigid objects is crucial for a variety of applications, such as robotics, engineering, film and video games. Rigid interactions are notoriously hard to model: small changes to the initial state or the simulation parameters can lead to large changes in the final state. Recently, learned simulators based on graph networks (GNNs) were developed as an alternative to hand-designed simulators like MuJoCo and Bullet. They are able to accurately capture dynamics of real objects directly from real-world observations. However, current state-of-the-art learned simulators operate on meshes and scale poorly to scenes with many objects or detailed shapes. Here we present SDF-Sim, the first learned rigid-body simulator designed for scale. We use learned signed-distance functions (SDFs) to represent the object shapes and to speed up distance computation. We design the simulator to leverage SDFs and avoid the fundamental bottleneck of the previous simulators associated with collision detection.
For the first time in literature, we demonstrate that we can scale the GNN-based simulators to scenes with hundreds of objects and up to 1.1 million nodes, where mesh-based approaches run out of memory. Finally, we show that SDF-Sim can be applied to real world scenes by extracting SDFs from multi-view images.",Yulia Rubanova; Tatiana Lopez-Guevara; Kelsey R Allen; William F Whitney; Kim Stachenfeld; Tobias Pfaff,~Yulia_Rubanova2; ~Tatiana_Lopez-Guevara1; ~Kelsey_R_Allen1; ~William_F_Whitney1; ~Kim_Stachenfeld1; ~Tobias_Pfaff1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/a025a4908402e558708ed28771812dd10af193dd.pdf,2024-05-14T09:46:20.370000,2024-09-25T18:11:51.520000,2024-11-06T06:18:40.845000,https://openreview.net/forum?id=QDYts5dYgq,Google; Google; Google; Columbia University; Google; Deepmind
2104,HRkniCWM3E,HRkniCWM3E,9295,Neural Pfaffians: Solving Many Many-Electron Schrödinger Equations,"Neural wave functions accomplished unprecedented accuracies in approximating the ground state of many-electron systems, though at a high computational cost. Recent works proposed amortizing the cost by learning generalized wave functions across different structures and compounds instead of solving each problem independently. Enforcing the permutation antisymmetry of electrons in such generalized neural wave functions remained challenging as existing methods require discrete orbital selection via non-learnable hand-crafted algorithms. This work tackles the problem by defining overparametrized, fully learnable neural wave functions suitable for generalization across molecules. We achieve this by relying on Pfaffians rather than Slater determinants. The Pfaffian allows us to enforce the antisymmetry on arbitrary electronic systems without any constraint on electronic spin configurations or molecular structure. Our empirical evaluation finds that a single neural Pfaffian calculates the ground state and ionization energies with chemical accuracy across various systems. On the TinyMol dataset, we outperform the `gold-standard' CCSD(T) CBS reference energies by 1.9m$E_h$ and reduce energy errors compared to previous generalized neural wave functions by up to an order of magnitude.",Nicholas Gao; Stephan Günnemann,~Nicholas_Gao1; ~Stephan_Günnemann1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/c766b139548380a74ad7a69a3c638798a81d5de3.pdf,2024-05-14T09:12:51.546000,2024-09-25T18:11:46.499000,2024-11-06T06:18:39.638000,https://openreview.net/forum?id=HRkniCWM3E,Technical University of Munich; Technical University of Munich
2107,Pezt0xttae,Pezt0xttae,9280,DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices,"Federated learning (FL) has emerged as a prominent machine learning paradigm in edge computing environments, enabling edge devices to collaboratively optimize a global model without sharing their private data. However, existing FL frameworks suffer from efficacy deterioration due to the system heterogeneity inherent in edge computing, especially in the presence of domain shifts across local data. 
In this paper, we propose a heterogeneous FL framework DapperFL, to enhance model performance across multiple domains. In DapperFL, we introduce a dedicated Model Fusion Pruning (MFP) module to produce personalized compact local models for clients to address the system heterogeneity challenges. The MFP module prunes local models with fused knowledge obtained from both local and remaining domains, ensuring robustness to domain shifts. Additionally, we design a Domain Adaptive Regularization (DAR) module to further improve the overall performance of DapperFL. The DAR module employs regularization generated by the pruned model, aiming to learn robust representations across domains. Furthermore, we introduce a specific aggregation algorithm for aggregating heterogeneous local models with tailored architectures and weights. We implement DapperFL on a real-world FL platform with heterogeneous clients. Experimental results on benchmark datasets with multiple domains demonstrate that DapperFL outperforms several state-of-the-art FL frameworks by up to 2.28%, while significantly achieving model volume reductions ranging from 20% to 80%. Our code is available at: https://github.com/jyzgh/DapperFL.",Yongzhe Jia; Xuyun Zhang; Hongsheng Hu; Kim-Kwang Raymond Choo; Lianyong Qi; Xiaolong Xu; Amin Beheshti; Wanchun Dou,~Yongzhe_Jia1; ~Xuyun_Zhang1; ~Hongsheng_Hu2; ~Kim-Kwang_Raymond_Choo1; ~Lianyong_Qi2; ~Xiaolong_Xu3; ~Amin_Beheshti2; ~Wanchun_Dou1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,infrastructure,/pdf/40235b2ea6b49d81841886f194bd9d4a2897ff15.pdf,2024-05-14T09:09:33.513000,2024-09-25T18:11:46.086000,2024-11-06T06:18:39.490000,https://openreview.net/forum?id=Pezt0xttae,"Nanjing University; Macquarie University; Commonwealth Scientific and Industrial Research Organisation, CSIRO; University of Newcastle; University of Texas, Arlington; Southwest Petroleum University; Nanjing University; Macquarie University; Nanjing University"
2120,OycU0bAus6,OycU0bAus6,9228,DenoiseRep: Denoising Model for Representation Learning,"The denoising model has been proven a powerful generative model but has little exploration of discriminative tasks. Representation learning is important in discriminative tasks, which is defined as *""learning representations (or features) of the data that make it easier to extract useful information when building classifiers or other predictors""*. In this paper, we propose a novel Denoising Model for Representation Learning (*DenoiseRep*) to improve feature discrimination with joint feature extraction and denoising. *DenoiseRep* views each embedding layer in a backbone as a denoising layer, processing the cascaded embedding layers as if we are recursively denoise features step-by-step. This unifies the frameworks of feature extraction and denoising, where the former progressively embeds features from low-level to high-level, and the latter recursively denoises features step-by-step. After that, *DenoiseRep* fuses the parameters of feature extraction and denoising layers, and *theoretically demonstrates* its equivalence before and after the fusion, thus making feature denoising computation-free. *DenoiseRep* is a label-free algorithm that incrementally improves features but also complementary to the label if available. Experimental results on various discriminative vision tasks, including re-identification (Market-1501, DukeMTMC-reID, MSMT17, CUHK-03, vehicleID), image classification (ImageNet, UB200, Oxford-Pet, Flowers), object detection (COCO), image segmentation (ADE20K) show stability and impressive improvements. We also validate its effectiveness on the CNN (ResNet) and Transformer (ViT, Swin, Vmamda) architectures.",zhengrui Xu; Guan'an Wang; Xiaowen Huang; Jitao Sang,~zhengrui_Xu1; ~Guan'an_Wang2; ~Xiaowen_Huang1; ~Jitao_Sang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/b468df410cc1d69f8bb648ff72f1f15c480e01b4.pdf,2024-05-14T08:55:51.543000,2024-09-25T18:11:44.325000,2025-01-21T13:18:10.280000,https://openreview.net/forum?id=OycU0bAus6,Beijing Jiaotong University; Peking University; Beijing Jiaotong University; Beijing Jiaotong University
2155,clBiQUgj4w,clBiQUgj4w,9084,CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns,"The stable periodic patterns present in time series data serve as the foundation for conducting long-horizon forecasts. In this paper, we pioneer the exploration of explicitly modeling this periodicity to enhance the performance of models in long-term time series forecasting (LTSF) tasks. Specifically, we introduce the Residual Cycle Forecasting (RCF) technique, which utilizes learnable recurrent cycles to model the inherent periodic patterns within sequences, and then performs predictions on the residual components of the modeled cycles. Combining RCF with a Linear layer or a shallow MLP forms the simple yet powerful method proposed in this paper, called CycleNet. CycleNet achieves state-of-the-art prediction accuracy in multiple domains including electricity, weather, and energy, while offering significant efficiency advantages by reducing over 90% of the required parameter quantity. Furthermore, as a novel plug-and-play technique, the RCF can also significantly improve the prediction accuracy of existing models, including PatchTST and iTransformer. The source code is available at: https://github.com/ACAT-SCUT/CycleNet.",Shengsheng Lin; Weiwei Lin; Xinyi HU; Wentai Wu; Ruichao Mo; Haocheng Zhong,~Shengsheng_Lin1; ~Weiwei_Lin1; ~Xinyi_HU2; ~Wentai_Wu1; ~Ruichao_Mo1; ~Haocheng_Zhong1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/72268edc46e85d27ead8ece63613a20b383ab36c.pdf,2024-05-14T08:12:57.001000,2024-09-25T18:11:40.568000,2024-11-06T06:18:37.278000,https://openreview.net/forum?id=clBiQUgj4w,South China University; South China University; Department of Computer Science; Chinese University of Hong Kong; Jinan University; South China University
2180,rtz4df9IF1,rtz4df9IF1,8899,Optimal Parallelization of Boosting,"Recent works on the parallel complexity of Boosting have established strong lower bounds on the tradeoff between the number of training rounds $p$ and the total parallel work per round $t$.
These works have also presented highly non-trivial parallel algorithms that shed light on different regions of this tradeoff.
Despite these advancements, a significant gap persists between the theoretical lower bounds and the performance of these algorithms across much of the tradeoff space.
In this work, we essentially close this gap by providing both improved lower bounds on the parallel complexity of weak-to-strong learners, and a parallel Boosting algorithm whose performance matches these bounds across the entire $p$ vs. $t$ compromise spectrum, up to logarithmic factors.
Ultimately, this work settles the parallel complexity of Boosting algorithms that are nearly sample-optimal.",Arthur da Cunha; Mikael Møller Høgsgaard; Kasper Green Larsen,~Arthur_da_Cunha1; ~Mikael_Møller_Høgsgaard1; ~Kasper_Green_Larsen1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,learning_theory,/pdf/ee88d3d4399c417433f97a457dffc6f174cfe576.pdf,2024-05-14T07:25:09.161000,2024-09-25T18:11:34.849000,2025-01-15T12:34:46.041000,https://openreview.net/forum?id=rtz4df9IF1,Aarhus University; Aarhus University; Aarhus University
2186,qZFshkbWDo,qZFshkbWDo,8876,"Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense","Backdoor attacks pose a significant threat to Deep Neural Networks (DNNs) as they allow attackers to manipulate model predictions with backdoor triggers. To address these security vulnerabilities, various backdoor purification methods have been proposed to purify compromised models. Typically, these purified models exhibit low Attack Success Rates (ASR), rendering them resistant to backdoored inputs. However, \textit{Does achieving a low ASR through current safety purification methods truly eliminate learned backdoor features from the pretraining phase?} In this paper, we provide an affirmative answer to this question by thoroughly investigating the \textit{Post-Purification Robustness} of current backdoor purification methods. We find that current safety purification methods are vulnerable to the rapid re-learning of backdoor behavior, even when further fine-tuning of purified models is performed using a very small number of poisoned samples. Based on this, we further propose the practical Query-based Reactivation Attack (QRA) which could effectively reactivate the backdoor by merely querying purified models. We find the failure to achieve satisfactory post-purification robustness stems from the insufficient deviation of purified models from the backdoored model along the backdoor-connected path. To improve the post-purification robustness, we propose a straightforward tuning defense, Path-Aware Minimization (PAM), which promotes deviation along backdoor-connected paths with extra model updates. Extensive experiments demonstrate that PAM significantly improves post-purification robustness while maintaining a good clean accuracy and low ASR. Our work provides a new perspective on understanding the effectiveness of backdoor safety tuning and highlights the importance of faithfully assessing the model's safety.",Rui Min; Zeyu Qin; Nevin L. Zhang; Li Shen; Minhao Cheng,~Rui_Min1; ~Zeyu_Qin1; ~Nevin_L._Zhang1; ~Li_Shen1; ~Minhao_Cheng1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/14f9b5d9e306ef6145cc9fda36c6da97dfecb26a.pdf,2024-05-14T07:15:28.269000,2024-09-25T18:11:33.765000,2024-11-06T06:18:35.986000,https://openreview.net/forum?id=qZFshkbWDo,Hong Kong University of Science and Technology(Guangzhou); Hong Kong University of Science and Technology(Guangzhou); Hong Kong University of Science and Technology(Guangzhou); Kong University of Science and Technology; JD AI Research; Sun Yat-sen University; Pennsylvania State University
2191,On5WIN7xyD,On5WIN7xyD,8852,Observational Scaling Laws and the Predictability of Langauge Model Performance,"Understanding how language model performance varies with scale is critical to benchmark and algorithm development. Scaling laws are one approach to building this understanding, but the requirement of training models across many different scales has limited their use. We propose an alternative, observational approach that bypasses model training and instead builds scaling laws from ~100 publically available models. Building a single scaling law from multiple model families is challenging due to large variations in their training compute efficiencies and capabilities. However, we show that these variations are consistent with a simple, generalized scaling law where language model performance is a function of a low-dimensional capability space, and model families only vary in their efficiency in converting training compute to capabilities. Using this approach, we show the surprising predictability of complex scaling phenomena: we show that several emergent phenomena follow a smooth, sigmoidal behavior and are predictable from small models; we show that the agent performance of models such as GPT-4 can be precisely predicted from simpler non-agentic benchmarks; and we show how to predict the impact of post-training interventions like Chain-of-Thought and Self-Consistency as language model capabilities continue to improve.",Yangjun Ruan; Chris J. Maddison; Tatsunori Hashimoto,~Yangjun_Ruan1; ~Chris_J._Maddison1; ~Tatsunori_Hashimoto1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/901906b67bfc72a2e721a9b7d1d59b8f65af80e4.pdf,2024-05-14T07:08:52.137000,2024-09-25T18:11:32.814000,2024-11-06T06:18:35.758000,https://openreview.net/forum?id=On5WIN7xyD,Stanford University; University of Toronto; University of Toronto; Google
2194,NPKZF1WDjZ,NPKZF1WDjZ,8833,"Decompose, Analyze and Rethink: Solving Intricate Problems with Human-like Reasoning Cycle","In this paper, we introduce DeAR (_Decompose-Analyze-Rethink_), a framework that iteratively builds a reasoning tree to tackle intricate problems within a single large language model (LLM). Unlike approaches that extend or search for rationales, DeAR is featured by 1) adopting a tree-based question decomposition manner to plan the organization of rationales, which mimics the logical planning inherent
in human cognition; 2) globally updating the rationales at each reasoning step through natural language feedback. Specifically, the _Decompose_ stage decomposes the question into simpler sub-questions, storing them as new nodes; the _Analyze_ stage generates and self-checks rationales for sub-questions at each node evel; and the _Rethink_ stage updates parent-node rationales based on feedback from their child nodes. By generating and updating the reasoning process from a more global perspective, DeAR constructs more adaptive and accurate logical structures for complex problems, facilitating timely error correction compared to rationale-extension and search-based approaches such as Tree-of-Thoughts (ToT) and Graph-of-Thoughts (GoT). We conduct extensive experiments on three reasoning benchmarks, including ScienceQA, StrategyQA, and GSM8K, which cover a variety of reasoning tasks, demonstrating that our approach significantly reduces logical errors and enhances performance across various LLMs. Furthermore, we validate that DeAR is an efficient method that achieves a superior trade-off between accuracy and reasoning time compared to ToT and GoT.",Shangzi Xue; Zhenya Huang; Jiayu Liu; Xin Lin; Yuting Ning; Binbin Jin; Xin Li; Qi Liu,~Shangzi_Xue1; ~Zhenya_Huang2; ~Jiayu_Liu2; ~Xin_Lin7; ~Yuting_Ning1; ~Binbin_Jin1; ~Xin_Li56; ~Qi_Liu3,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/acb2a9d4f574358366be48733d2d875403731798.pdf,2024-05-14T07:05:23.189000,2024-09-25T18:11:32.292000,2025-01-14T09:34:27.940000,https://openreview.net/forum?id=NPKZF1WDjZ,University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; The Ohio State University; University of Science and Technology of China; University of Science and Technology of China
2197,YgJPQW0lkO,YgJPQW0lkO,8821,Graph-based Uncertainty Metrics for Long-form Language Model Generations,"Recent advancements in Large Language Models (LLMs) have significantly improved text generation capabilities, but these systems are still known to hallucinate, and granular uncertainty estimation for long-form LLM generations remains challenging. 
In this work, we propose Graph Uncertainty -- which represents the relationship between LLM generations and claims within them as a bipartite graph and estimates the claim-level uncertainty with a family of graph centrality metrics. Under this view, existing uncertainty estimation methods based on the concept of self-consistency can be viewed as using degree centrality as an uncertainty measure, and we show that more sophisticated alternatives such as closeness centrality provide consistent gains at claim-level uncertainty estimation.
Moreover, we present uncertainty-aware decoding techniques that leverage both the graph structure and uncertainty estimates to improve the factuality of LLM generations by preserving only the most reliable claims. Compared to existing methods, our graph-based uncertainty metrics lead to an average of 6.8% relative gains on AUPRC across various long-form generation settings, and our end-to-end system provides consistent 2-4% gains in factuality over existing decoding techniques while significantly improving the informativeness of generated responses.",Mingjian Jiang; Yangjun Ruan; Prasanna Sattigeri; Salim Roukos; Tatsunori Hashimoto,~Mingjian_Jiang1; ~Yangjun_Ruan1; ~Prasanna_Sattigeri1; ~Salim_Roukos1; ~Tatsunori_Hashimoto1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/45c75d7ca6708f124a84bf96fed220a0633fda12.pdf,2024-05-14T07:02:52.967000,2024-09-25T18:11:31.859000,2024-11-06T06:18:35.503000,https://openreview.net/forum?id=YgJPQW0lkO,Stanford University; Stanford University; University of Toronto
2202,eqMNwXvOqn,eqMNwXvOqn,8803,MKGL: Mastery of a Three-Word Language,"Large language models (LLMs) have significantly advanced performance across a spectrum of natural language processing (NLP) tasks. Yet, their application to knowledge graphs (KGs), which describe facts in the form of triplets and allow minimal hallucinations, remains an underexplored frontier. In this paper, we investigate the integration of LLMs with KGs by introducing a specialized KG Language (KGL), where a sentence precisely consists of an entity noun, a relation verb, and ends with another entity noun. Despite KGL's unfamiliar vocabulary to the LLM, we facilitate its learning through a tailored dictionary and illustrative sentences, and enhance context understanding via real-time KG context retrieval and KGL token embedding augmentation. Our results reveal that LLMs can achieve fluency in KGL, drastically reducing errors compared to conventional KG embedding methods on KG completion. Furthermore, our enhanced LLM shows exceptional competence in generating accurate three-word sentences from an initial entity and interpreting new unseen terms out of KGs.",Lingbing Guo; Zhongpu Bo; Zhuo Chen; Yichi Zhang; Jiaoyan Chen; Lan Yarong; Mengshu Sun; Zhiqiang Zhang; Yangyifei Luo; Qian Li; Qiang Zhang; Wen Zhang; Huajun Chen,~Lingbing_Guo1; ~Zhongpu_Bo1; ~Zhuo_Chen3; ~Yichi_Zhang13; ~Jiaoyan_Chen1; ~Lan_Yarong1; ~Mengshu_Sun2; ~Zhiqiang_Zhang4; ~Yangyifei_Luo1; ~Qian_Li8; ~Qiang_Zhang6; ~Wen_Zhang4; ~Huajun_Chen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/ddf40e55c560deaa3bfb5608c5d9f5ccd649815c.pdf,2024-05-14T06:58:24.156000,2024-09-25T18:11:31.291000,2024-11-06T06:18:34.776000,https://openreview.net/forum?id=eqMNwXvOqn,Zhejiang University; Alibaba Group; Zhejiang University; Zhejiang University; University of Manchester; University of Oxford; Zhejiang University; Ant Group; Ant Group; Beihang University; Beijing University of Posts and Telecommunications; Zhejiang University; Zhejiang University
2208,dheDf5EpBT,dheDf5EpBT,8761,Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement,"Machine unlearning (MU) has emerged to enhance the privacy and trustworthiness of deep neural networks. Approximate MU is a practical method for large-scale models. Our investigation into approximate MU starts with identifying the steepest descent direction, minimizing the output Kullback-Leibler divergence to exact MU inside a parameters' neighborhood. This probed direction decomposes into three components: weighted forgetting gradient ascent, fine-tuning retaining gradient descent, and a weight saliency matrix. Such decomposition derived from Euclidean metric encompasses most existing gradient-based MU methods. Nevertheless, adhering to Euclidean space may result in sub-optimal iterative trajectories due to the overlooked geometric structure of the output probability space. We suggest embedding the unlearning update into a manifold rendered by the remaining geometry, incorporating second-order Hessian from the remaining data. It helps prevent effective unlearning from interfering with the retained performance. However, computing the second-order Hessian for large-scale models is intractable. To efficiently leverage the benefits of Hessian modulation, we propose a fast-slow parameter update strategy to implicitly approximate the up-to-date salient unlearning direction.
Free from specific modal constraints, our approach is adaptable across computer vision unlearning tasks, including classification and generation. Extensive experiments validate our efficacy and efficiency. Notably, our method successfully performs class-forgetting on ImageNet using DiT and forgets a class on CIFAR-10 using DDPM in just 50 steps, compared to thousands of steps required by previous methods. Code is available at [Unified-Unlearning-w-Remain-Geometry](https://github.com/K1nght/Unified-Unlearning-w-Remain-Geometry).",Zhehao Huang; Xinwen Cheng; JingHao Zheng; Haoran Wang; Zhengbao He; Tao Li; Xiaolin Huang,~Zhehao_Huang1; ~Xinwen_Cheng1; ~JingHao_Zheng1; ~Haoran_Wang27; ~Zhengbao_He1; ~Tao_Li12; ~Xiaolin_Huang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/1b0b245a192b77c528420ead8cfba54870ad5f69.pdf,2024-05-14T06:44:46.776000,2024-09-25T18:11:30.166000,2024-11-06T06:18:34.555000,https://openreview.net/forum?id=dheDf5EpBT,Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University
2224,RL4FXrGcTw,RL4FXrGcTw,8674,Gradients of Functions of Large Matrices,"Tuning scientific and probabilistic machine learning models - for example, partial differential equations, Gaussian processes, or Bayesian neural networks - often relies on evaluating functions of matrices whose size grows with the data set or the number of parameters.
While the state-of-the-art for _evaluating_ these quantities is almost always based on Lanczos and Arnoldi iterations, the present work is the first to explain how to _differentiate_ these workhorses of numerical linear algebra efficiently.
To get there, we derive previously unknown adjoint systems for Lanczos and Arnoldi iterations, implement them in JAX, and show that the resulting code can compete with Diffrax when it comes to differentiating PDEs, GPyTorch for selecting Gaussian process models and beats standard factorisation methods for calibrating Bayesian neural networks.
All this is achieved without any problem-specific code optimisation.
Find the code at [link redacted] and install the library with *pip install [redacted]*.",Nicholas Krämer; Pablo Moreno-Muñoz; Hrittik Roy; Søren Hauberg,~Nicholas_Krämer1; ~Pablo_Moreno-Muñoz1; ~Hrittik_Roy2; ~Søren_Hauberg1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/91b0ba7ffc2387f44535ee3162801495251ef908.pdf,2024-05-14T06:16:55.829000,2024-09-25T18:11:27.328000,2024-11-06T06:18:33.906000,https://openreview.net/forum?id=RL4FXrGcTw,University of Tübingen; Technical University of Denmark; Technical University of Denmark; Universitat Pompeu Fabra; Technical University of Denmark
2226,1WtEqReCyS,1WtEqReCyS,8659,Multilingual Diversity Improves Vision-Language Representations,"Massive web-crawled image-text datasets lay the foundation for recent progress in multimodal learning. These datasets are designed with the goal of training a model to do well on standard computer vision benchmarks, many of which, however, have been shown to be English-centric (e.g., ImageNet). Consequently, existing data curation techniques gravitate towards using predominantly English image-text pairs and discard many potentially useful non-English samples. Our work questions this practice. Multilingual data is inherently enriching not only because it provides a gateway to learn about culturally salient concepts, but also because it depicts common concepts differently from monolingual data. We thus conduct a systematic study to explore the performance benefits of using more samples of non-English origins with respect to English vision tasks. By translating all multilingual image-text pairs from a raw web crawl to English and re-filtering them, we increase the prevalence of (translated) multilingual data in the resulting training set. Pre-training on this dataset outperforms using English-only or English-dominated datasets on ImageNet, ImageNet distribution shifts, image-English-text retrieval and on average across 38 tasks from the DataComp benchmark. On a geographically diverse task like GeoDE, we also observe improvements across all regions, with the biggest gain coming from Africa. In addition, we quantitatively show that English and non-English data are significantly different in both image and (translated) text space. We hope that our findings motivate future work to be more intentional about including multicultural and multilingual data, not just when non-English or geographically diverse tasks are involved, but to enhance model capabilities at large.",Thao Nguyen; Matthew Wallingford; Sebastin Santy; Wei-Chiu Ma; Sewoong Oh; Ludwig Schmidt; Pang Wei Koh; Ranjay Krishna,~Thao_Nguyen3; ~Matthew_Wallingford1; ~Sebastin_Santy2; ~Wei-Chiu_Ma1; ~Sewoong_Oh3; ~Ludwig_Schmidt1; ~Pang_Wei_Koh1; ~Ranjay_Krishna1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/47a9f932f04a47ac9057fce9ec8f361b20f27565.pdf,2024-05-14T06:14:14.694000,2024-09-25T18:11:26.854000,2024-11-06T06:18:33.795000,https://openreview.net/forum?id=1WtEqReCyS,Meta; University of Washington; University of Washington; University of Washington; Allen Institute; Cornell University; University of Washington; University of Washington; Stanford University; Anthropic; University of Washington; Allen Institute; University of Washington; University of Washington
2231,T5UfIfmDbq,T5UfIfmDbq,8632,Monte Carlo Tree Search based Space Transfer for Black Box Optimization,"Bayesian optimization (BO) is a popular method for computationally expensive black-box optimization. However, traditional BO methods need to solve new problems from scratch, leading to slow convergence. Recent studies try to extend BO to a transfer learning setup to speed up the optimization, where search space transfer is one of the most promising approaches and has shown impressive performance on many tasks. However, existing search space transfer methods either lack an adaptive mechanism or are not flexible enough, making it difficult to efficiently identify promising search space during the optimization process. In this paper, we propose a search space transfer learning method based on Monte Carlo tree search (MCTS), called MCTS-transfer, to iteratively divide, select, and optimize in a learned subspace. MCTS-transfer can not only provide a well-performing search space for warm-start but also adaptively identify and leverage the information of similar source tasks to reconstruct the search space during the optimization process. Experiments on synthetic functions, real-world problems, Design-Bench and hyper-parameter optimization show that MCTS-transfer can demonstrate superior performance compared to other search space transfer methods under different settings. Our code is available at \url{https://github.com/lamda-bbo/mcts-transfer}.",Shukuan Wang; Ke Xue; Lei Song; Xiaobin Huang; Chao Qian,~Shukuan_Wang1; ~Ke_Xue1; ~Lei_Song4; ~Xiaobin_Huang2; ~Chao_Qian1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/84c30c02e0108e7327b3caec9ed8ded6e4305f5d.pdf,2024-05-14T05:59:36.745000,2024-09-25T18:11:25.891000,2024-11-06T06:18:33.587000,https://openreview.net/forum?id=T5UfIfmDbq,Nanjing University; Nanjing University; Nanjing University
2238,v1BIm8wESL,v1BIm8wESL,8599,Skinned Motion Retargeting with Dense Geometric Interaction Perception,"Capturing and maintaining geometric interactions among different body parts is crucial for successful motion retargeting in skinned characters. Existing approaches often overlook body geometries or add a geometry correction stage after skeletal motion retargeting. This results in conflicts between skeleton interaction and geometry correction, leading to issues such as jittery, interpenetration, and contact mismatches. To address these challenges, we introduce a new retargeting framework, MeshRet, which directly models the dense geometric interactions in motion retargeting. Initially, we establish dense mesh correspondences between characters using semantically consistent sensors (SCS), effective across diverse mesh topologies. Subsequently, we develop a novel spatio-temporal representation called the dense mesh interaction (DMI) field. This field, a collection of interacting SCS feature vectors, skillfully captures both contact and non-contact interactions between body geometries. By aligning the DMI field during retargeting, MeshRet not only preserves motion semantics but also prevents self-interpenetration and ensures contact preservation. Extensive experiments on the public Mixamo dataset and our newly-collected ScanRet dataset demonstrate that MeshRet achieves state-of-the-art performance. Code available at https://github.com/abcyzj/MeshRet.",Zijie Ye; Jia-Wei Liu; Jia Jia; Shikun Sun; Mike Zheng Shou,~Zijie_Ye1; ~Jia-Wei_Liu1; ~Jia_Jia1; ~Shikun_Sun1; ~Mike_Zheng_Shou1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/12ebc0df091e4b2c185faf741c87fc6937bb37c5.pdf,2024-05-14T05:45:58.050000,2024-09-25T18:11:24.753000,2024-12-23T03:53:36.172000,https://openreview.net/forum?id=v1BIm8wESL,"Tsinghua University, Beijing; National University of Singapore; Tsinghua University, Beijing; Tsinghua University, Beijing; National University of Singapore"
2279,SQVns9hWJT,SQVns9hWJT,8347,TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control,"Centred on content modification and style preservation, Scene Text Editing (STE) remains a challenging task despite considerable progress in text-to-image synthesis and text-driven image manipulation recently. GAN-based STE methods generally encounter a common issue of model generalization, while Diffusion-based STE methods suffer from undesired style deviations. To address these problems, we propose TextCtrl, a diffusion-based method that edits text with prior guidance control. Our method consists of two key components: (i) By constructing fine-grained text style disentanglement and robust text glyph structure representation,  TextCtrl explicitly incorporates Style-Structure guidance into model design and network training, significantly improving text style consistency and rendering accuracy. (ii) To further leverage the style prior, a Glyph-adaptive Mutual Self-attention mechanism is proposed which deconstructs the implicit fine-grained features of the source image to enhance style consistency and vision quality during inference. Furthermore, to fill the vacancy of the real-world STE evaluation benchmark, we create the first real-world image-pair dataset termed ScenePair for fair comparisons. Experiments demonstrate the effectiveness of TextCtrl compared with previous methods concerning both style fidelity and text accuracy. Project page: https://github.com/weichaozeng/TextCtrl.",Weichao Zeng; Yan Shu; Zhenhang Li; Dongbao Yang; Yu Zhou,~Weichao_Zeng1; ~Yan_Shu3; ~Zhenhang_Li1; ~Dongbao_Yang1; ~Yu_Zhou2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/54defa44a9993f1a3bcc94db4b764e2c4153b3d9.pdf,2024-05-14T03:44:09.693000,2024-09-25T18:11:16.830000,2024-11-06T06:18:31.532000,https://openreview.net/forum?id=SQVns9hWJT,University of Chinese Academy of Sciences; Beijing Academy of Artificial Intelligence; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Nankai University; University of Chinese Academy of Sciences
2280,JvQnJWIj6m,JvQnJWIj6m,8335,Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning,"In recent advancements in unsupervised visual representation learning, the Joint-Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabeled imagery through an innovative masking strategy. Despite its success, two primary limitations have been identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPA in preventing entire collapse and the inadequacy of I-JEPA prediction in accurately learning the mean of patch representations. Addressing these challenges, this study introduces a novel framework, namely C-JEPA (Contrastive-JEPA), which integrates the Image-based Joint-Embedding Predictive Architecture with the Variance-Invariance-Covariance Regularization (VICReg) strategy. This integration is designed to effectively learn the variance/covariance for preventing entire collapse and ensuring invariance in the mean of augmented views, thereby overcoming the identified limitations. Through empirical and theoretical evaluations, our work demonstrates that C-JEPA significantly enhances the stability and quality of visual representation learning. When pre-trained on the ImageNet-1K dataset, C-JEPA exhibits rapid and improved convergence in both linear probing and fine-tuning performance metrics.",Shentong Mo; Shengbang Tong,~Shentong_Mo1; ~Shengbang_Tong1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/127c9d535a303ebee9ec089ac8be397199465114.pdf,2024-05-14T03:38:23.333000,2024-09-25T18:11:16.710000,2024-11-06T06:18:31.490000,https://openreview.net/forum?id=JvQnJWIj6m,Carnegie Mellon University; New York University
2283,ahvOhPkkMx,ahvOhPkkMx,8320,Zipper: Addressing Degeneracy in Algorithm-Agnostic Inference,"The widespread use of black box prediction methods has sparked an increasing interest in algorithm/model-agnostic approaches for quantifying goodness-of-fit, with direct ties to specification testing, model selection and variable importance assessment. A commonly used framework involves defining a predictiveness criterion, applying a cross-fitting procedure to estimate the predictiveness, and utilizing the difference in estimated predictiveness between two models as the test statistic. However, even after standardization, the test statistic typically fails to converge to a non-degenerate distribution under the null hypothesis of equal goodness, leading to what is known as the degeneracy issue. To addresses this degeneracy issue, we present a simple yet effective device, Zipper. It draws inspiration from the strategy of additional splitting of testing data, but encourages an overlap between two testing data splits in predictiveness evaluation. Zipper binds together the two overlapping splits using a slider parameter that controls the proportion of overlap. Our proposed test statistic follows an asymptotically normal distribution under the null hypothesis for any fixed slider value, guaranteeing valid size control while enhancing power by effective data reuse. Finite-sample experiments demonstrate that our procedure, with a simple choice of the slider, works well across a wide range of settings.",Geng Chen; Yinxu Jia; Guanghui Wang; Changliang Zou,~Geng_Chen7; ~Yinxu_Jia1; ~Guanghui_Wang6; ~Changliang_Zou2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/c5392591d245b0cadb154b39399b842980d69a01.pdf,2024-05-14T03:33:49.853000,2024-09-25T18:11:16.293000,2024-11-06T06:18:31.290000,https://openreview.net/forum?id=ahvOhPkkMx,Nankai University
2291,mmSFfib6pI,mmSFfib6pI,8285,Validating Climate Models with Spherical Convolutional Wasserstein Distance,"The validation of global climate models is crucial to ensure the accuracy and efficacy of model output. We introduce the spherical convolutional Wasserstein distance to more comprehensively measure differences between climate models and reanalysis data. This new similarity measure accounts for spatial variability using convolutional projections and quantifies local differences in the distribution of climate variables. We apply this method to evaluate the historical model outputs of the Coupled Model Intercomparison Project (CMIP) members by comparing them to observational and reanalysis data products. Additionally, we investigate the progression from CMIP phase 5 to phase 6 and find modest improvements in the phase 6 models regarding their ability to produce realistic climatologies.",Robert C. Garrett; Trevor Harris; Zhuo Wang; Bo Li,~Robert_C._Garrett1; ~Trevor_Harris1; ~Zhuo_Wang6; ~Bo_Li8,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/d2936d5d2e539246fd12de9624014d27f805dbec.pdf,2024-05-14T03:23:27.766000,2024-09-25T18:11:15.204000,2024-11-06T06:18:30.941000,https://openreview.net/forum?id=mmSFfib6pI,"Department of Computer Science, University of Illinois at Urbana Champaign; Carnegie Mellon University; University of Connecticut; Texas A&M University"
2292,Woiqqi5bYV,Woiqqi5bYV,8274,Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification,"Vision models excel in image classification but struggle to generalize to unseen data, such as classifying images from unseen domains or discovering novel categories. In this paper, we explore the relationship between logical reasoning and deep learning generalization in visual classification. A logical regularization termed L-Reg is derived which bridges a logical analysis framework to image classification. Our work reveals that L-Reg reduces the complexity of the model in terms of the feature distribution and classifier weights. Specifically, we unveil the interpretability brought by L-Reg, as it enables the model to extract the salient features, such as faces to persons, for classification. Theoretical analysis and experiments demonstrate that L-Reg enhances generalization across various scenarios, including multi-domain generalization and generalized category discovery. In complex real-world scenarios where images span unknown classes and unseen domains, L-Reg consistently improves generalization, highlighting its practical efficacy.",Zhaorui Tan; Xi Yang; Qiufeng Wang; Anh Nguyen; Kaizhu Huang,~Zhaorui_Tan1; ~Xi_Yang7; ~Qiufeng_Wang2; ~Anh_Nguyen2; ~Kaizhu_Huang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/9ff43094e04fb6ebb0263c4559a145c7362b3b6f.pdf,2024-05-14T03:20:06.887000,2024-09-25T18:11:14.837000,2024-12-19T04:29:05.952000,https://openreview.net/forum?id=Woiqqi5bYV,Xi'an Jiaotong-Liverpool University; University of Liverpool; Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University; University of Liverpool; Xi'an Jiaotong-Liverpool University; Duke Kunshan University
2294,3j2nasmKkP,3j2nasmKkP,8271,Cluster-wise Graph Transformer with Dual-granularity Kernelized Attention,"In the realm of graph learning, there is a category of methods that conceptualize graphs as hierarchical structures, utilizing node clustering to capture broader structural information. While generally effective, these methods often rely on a fixed graph coarsening routine, leading to overly homogeneous cluster representations and loss of node-level information. In this paper, we envision the graph as a network of interconnected node sets without compressing each cluster into a single embedding. To enable effective information transfer among these node sets, we propose the Node-to-Cluster Attention (N2C-Attn) mechanism. N2C-Attn incorporates techniques from Multiple Kernel Learning into the kernelized attention framework, effectively capturing information at both node and cluster levels. We then devise an efficient form for N2C-Attn using the cluster-wise message-passing framework, achieving linear time complexity. We further analyze how N2C-Attn combines bi-level feature maps of queries and keys, demonstrating its capability to merge dual-granularity information. The resulting architecture, Cluster-wise Graph Transformer (Cluster-GT), which uses node clusters as tokens and employs our proposed N2C-Attn module, shows superior performance on various graph-level tasks. Code is available at https://github.com/LUMIA-Group/Cluster-wise-Graph-Transformer.",Siyuan Huang; Yunchong Song; Jiayue Zhou; Zhouhan Lin,~Siyuan_Huang8; ~Yunchong_Song1; ~Jiayue_Zhou1; ~Zhouhan_Lin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/c53ce013e91509cfa4169631f250b745996a7321.pdf,2024-05-14T03:19:20.804000,2024-09-25T18:11:14.643000,2024-12-24T13:47:07.774000,https://openreview.net/forum?id=3j2nasmKkP,Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University
2301,SpPAB1tmlC,SpPAB1tmlC,8250,Unveiling Encoder-Free Vision-Language Models,"Existing vision-language models (VLMs) mostly rely on vision encoders to extract visual features followed by large language models (LLMs) for visual-language tasks. However, the vision encoders set a strong inductive bias in abstracting visual representation, e.g., resolution, aspect ratio, and semantic priors, which could impede the flexibility and efficiency of the VLMs. Training pure VLMs that accept the seamless vision and language inputs, i.e., without vision encoders, remains challenging and rarely explored. Empirical observations reveal that direct training without encoders results in slow convergence and large performance gaps. In this work, we bridge the gap between encoder-based and encoder-free models, and present a simple yet effective training recipe towards pure VLMs. Specifically, we unveil the key aspects of training encoder-free VLMs efficiently via thorough experiments: (1) Bridging vision-language representation inside one unified decoder; (2) Enhancing visual recognition capability via extra supervision. With these strategies, we launch EVE, an encoder-free vision-language model that can be trained and forwarded efficiently. Notably, solely utilizing 35M publicly accessible data, EVE can impressively rival the encoder-based VLMs of similar capacities across multiple vision-language benchmarks. It significantly outperforms the counterpart Fuyu-8B with mysterious training procedures and undisclosed training data. We believe that EVE provides a transparent and efficient route for developing pure decoder-only architecture across modalities.",Haiwen Diao; Yufeng Cui; Xiaotong Li; Yueze Wang; Huchuan Lu; Xinlong Wang,~Haiwen_Diao2; ~Yufeng_Cui1; ~Xiaotong_Li2; ~Yueze_Wang1; ~Huchuan_Lu1; ~Xinlong_Wang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/2d69ff6922074e2ebb922b4502ee72a43c9d090c.pdf,2024-05-14T03:11:11.178000,2024-09-25T18:11:13.657000,2024-11-06T06:18:30.555000,https://openreview.net/forum?id=SpPAB1tmlC,Dalian University of Technology; Beijing Academy of Artificial Intelligence; Peking University; Beijing Academy of Artificial Intelligence; Dalian University of Technology; Beijing Academy of Artificial Intelligence
2312,5pnhGedG98,5pnhGedG98,8179,Scalable and Effective Arithmetic Tree Generation for Adder and Multiplier Designs,"Across a wide range of hardware scenarios, the computational efficiency and physical size of the arithmetic units significantly influence the speed and footprint of the overall hardware system. Nevertheless, the effectiveness of prior arithmetic design techniques proves inadequate, as they do not sufficiently optimize speed and area, resulting in increased latency and larger module size. To boost computing performance, this work focuses on the two most common and fundamental arithmetic modules, adders and multipliers. We cast the design tasks as single-player tree generation games, leveraging reinforcement learning techniques to optimize their arithmetic tree structures. This tree generation formulation allows us to efficiently navigate the vast search space and discover superior arithmetic designs that improve computational efficiency and hardware size within just a few hours. Our proposed method, **ArithTreeRL**, achieves significant improvements for both adders and multipliers. For adders, our approach discovers designs of 128-bit adders that achieve Pareto optimality in theoretical metrics. Compared with PrefixRL, it reduces delay and size by up to 26% and 30%, respectively. For multipliers, compared to RL-MUL, our method enhances speed and reduces size by as much as 49% and 45%. Additionally, ArithTreeRL's flexibility and scalability enable seamless integration into 7nm technology. We believe our work will offer valuable insights into hardware design, further accelerating speed and reducing size through the refined search space and our tree generation methodologies.",Yao Lai; Jinxin Liu; David Z. Pan; Ping Luo,~Yao_Lai2; ~Jinxin_Liu1; ~David_Z._Pan1; ~Ping_Luo2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/44ca33901ea50657dc124ad97b707f66e6c89c9e.pdf,2024-05-14T02:51:04.040000,2024-09-25T18:11:11.453000,2024-11-06T06:18:30.103000,https://openreview.net/forum?id=5pnhGedG98,The University of Texas at Austin; University of Hong Kong; Westlake University; Westlake Robotics; The University of Texas at Austin; University of Hong Kong
2322,N8YbGX98vc,N8YbGX98vc,8134,TFG: Unified Training-Free Guidance for Diffusion Models,"Given an unconditional diffusion model and a predictor for a target property of interest (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. Existing methods, though effective in various individual applications, often lack theoretical grounding and rigorous testing on extensive benchmarks. As a result, they could even fail on simple tasks, and applying them to a new problem becomes unavoidably difficult. This paper introduces a novel algorithmic framework encompassing existing methods as special cases, unifying the study of training-free guidance into the analysis of an algorithm-agnostic design space. Via theoretical and empirical investigation, we propose an efficient and effective hyper-parameter searching strategy that can be readily applied to any downstream task. We systematically benchmark across 7 diffusion models on 16 tasks with 40 targets, and improve performance by 8.5% on average. Our framework and benchmark offer a solid foundation for conditional generation in a training-free manner.",Haotian Ye; Haowei Lin; Jiaqi Han; Minkai Xu; Sheng Liu; Yitao Liang; Jianzhu Ma; James Zou; Stefano Ermon,~Haotian_Ye1; ~Haowei_Lin1; ~Jiaqi_Han2; ~Minkai_Xu1; ~Sheng_Liu2; ~Yitao_Liang1; ~Jianzhu_Ma2; ~James_Zou1; ~Stefano_Ermon1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/13821f949417135671f0e547e84a4a28af80b02d.pdf,2024-05-14T02:33:27.115000,2024-09-25T18:11:09.841000,2024-11-06T06:18:29.733000,https://openreview.net/forum?id=N8YbGX98vc,"Stanford University; Peking University; Stanford University; Stanford University; Stanford University; Peking University; Tsinghua University, Beijing; Stanford University; Stanford University"
2335,DV15UbHCY1,DV15UbHCY1,8082,Are Language Models Actually Useful for Time Series Forecasting?,"Large language models (LLMs) are being applied to time series forecasting. But are language models actually useful for time series? In a series of ablation studies on three recent and popular LLM-based time series forecasting methods, we find that removing the LLM component or replacing it with a basic attention layer does not degrade forecasting performance---in most cases, the results even improve! We also find that despite their significant computational cost, pretrained LLMs do no better than models trained from scratch, do not represent the sequential dependencies in time series, and do not assist in few-shot settings. Additionally, we explore time series encoders and find that patching and attention structures perform similarly to LLM-based forecasters. All resources needed to reproduce our work are available: https://github.com/BennyTMT/LLMsForTimeSeries.",Mingtian Tan; Mike A Merrill; Vinayak Gupta; Tim Althoff; Thomas Hartvigsen,~Mingtian_Tan1; ~Mike_A_Merrill1; ~Vinayak_Gupta1; ~Tim_Althoff2; ~Thomas_Hartvigsen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,evaluation,/pdf/997f213b76c3b259e0f4cc88195a65f800b920e3.pdf,2024-05-14T02:06:03.440000,2024-09-25T18:11:07.727000,2024-11-06T06:18:29.177000,https://openreview.net/forum?id=DV15UbHCY1,University of Virginia; University of Washington; Lawrence Livermore National Laboratory; University of Washington; University of Virginia
2346,thUf6ZBlPp,thUf6ZBlPp,8022,EigenVI: score-based variational inference with orthogonal function expansions,"We develop EigenVI, an eigenvalue-based approach for black-box variational inference (BBVI). EigenVI constructs its variational approximations from orthogonal function expansions. For distributions over $\mathbb{R}^D$, the lowest order term in these expansions provides a Gaussian variational approximation, while higher-order terms provide a systematic way to model non-Gaussianity. These approximations are flexible enough to model complex distributions (multimodal, asymmetric), but they are simple enough that one can calculate their low-order moments and draw samples from them. EigenVI can also model other types of random variables (e.g., nonnegative, bounded) by constructing variational approximations from different families of orthogonal functions. Within these families, EigenVI computes the variational approximation that best matches the score function of the target distribution by minimizing a stochastic estimate of the Fisher divergence. Notably, this optimization reduces to solving a minimum eigenvalue problem, so that EigenVI effectively sidesteps the iterative gradient-based optimizations that are required for many other BBVI algorithms. (Gradient-based methods can be sensitive to learning rates, termination criteria, and other tunable hyperparameters.) We use EigenVI to approximate a variety of target distributions, including a benchmark suite of Bayesian models from posteriordb. On these distributions, we find that EigenVI is more accurate than existing methods for Gaussian BBVI.",Diana Cai; Chirag Modi; Charles Margossian; Robert M. Gower; David Blei; Lawrence K. Saul,~Diana_Cai1; ~Chirag_Modi1; ~Charles_Margossian1; ~Robert_M._Gower1; ~David_Blei2; ~Lawrence_K._Saul3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/3a5a8652ca4682261561100d0bf891d9086e2f30.pdf,2024-05-14T01:37:40.307000,2024-09-25T18:11:05.928000,2024-11-06T06:18:28.708000,https://openreview.net/forum?id=thUf6ZBlPp,"Flatiron Institute; Flatiron Institute; Flatiron Institute; University of California, San Diego; Flatiron Institute"
2356,135eKqDoRR,135eKqDoRR,7993,Bayesian-guided Label Mapping for Visual Reprogramming,"*Visual reprogramming* (VR) leverages the intrinsic capabilities of pretrained vision models by adapting their input or output interfaces to solve downstream tasks whose labels (i.e., downstream labels) might be totally different from the labels associated with the pretrained models (i.e., pretrained labels). 
When adapting the output interface, label mapping methods transform the pretrained labels to downstream labels by establishing a gradient-free one-to-one correspondence between the two sets of labels.
However, in this paper, we reveal that one-to-one mappings may overlook the complex relationship between pretrained and downstream labels. Motivated by this observation, we propose a ***B**ayesian-guided **L**abel **M**apping* (BLM) method. 
BLM constructs an iteratively-updated probabilistic label mapping matrix, with each element quantifying a pairwise relationship between pretrained and downstream labels.
The assignment of values to the constructed matrix is guided by Bayesian conditional probability, considering the joint distribution of the downstream labels and the labels predicted by the pretrained model on downstream samples. Experiments conducted on both pretrained vision models (e.g., ResNeXt) and vision-language models (e.g., CLIP) demonstrate the superior performance of BLM over existing label mapping methods. The success of BLM also offers a probabilistic lens through which to understand and analyze the effectiveness of VR.
Our code is available at https://github.com/tmlr-group/BayesianLM.",Chengyi Cai; Zesheng Ye; Lei Feng; Jianzhong Qi; Feng Liu,~Chengyi_Cai2; ~Zesheng_Ye1; ~Lei_Feng1; ~Jianzhong_Qi1; ~Feng_Liu2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/5bd51ea14b1857a137832007130aaf712c5b6a63.pdf,2024-05-14T01:23:28.120000,2024-09-25T18:11:04.989000,2025-01-07T04:18:17.714000,https://openreview.net/forum?id=135eKqDoRR,University of Melbourne; University of Melbourne; UNSW Sydney; Singapore University of Technology and Design; University of Melbourne; University of Melbourne
2417,F9NDzHQtOl,F9NDzHQtOl,7728,Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity,"Diffusion models have become a leading method for generative modeling of both image and scientific data.
As these models are costly to train and \emph{evaluate}, reducing the inference cost for diffusion models remains a major goal.
Inspired by the recent empirical success in accelerating diffusion models via the parallel sampling technique~\cite{shih2024parallel}, we propose to divide the sampling process into $\mathcal{O}(1)$ blocks with parallelizable Picard iterations within each block. Rigorous theoretical analysis reveals that our algorithm achieves $\widetilde{\mathcal{O}}(\mathrm{poly} \log d)$ overall time complexity, marking \emph{the first implementation with provable sub-linear complexity w.r.t. the data dimension $d$}. Our analysis is based on a generalized version of Girsanov's theorem and is compatible with both the SDE and probability flow ODE implementations. Our results shed light on the potential of fast and efficient sampling of high-dimensional data on fast-evolving modern large-memory GPU clusters.",Haoxuan Chen; Yinuo Ren; Lexing Ying; Grant M. Rotskoff,~Haoxuan_Chen1; ~Yinuo_Ren1; ~Lexing_Ying1; ~Grant_M._Rotskoff1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/9f1d3d6e770d079a98411143457f004c59280ae6.pdf,2024-05-13T21:25:49.678000,2024-09-25T18:10:56.661000,2024-12-23T06:13:58.344000,https://openreview.net/forum?id=F9NDzHQtOl,"NEC Laboratories, America; Stanford University; Stanford University"
2429,xymhWyiZOp,xymhWyiZOp,7675,On the Use of Anchoring for Training Vision Models,"Anchoring is a recent, architecture-agnostic principle for training deep neural networks that has been shown to significantly improve uncertainty estimation, calibration, and extrapolation capabilities. In this paper, we systematically explore anchoring as a general protocol for training vision models, providing fundamental insights into its training and inference processes and their implications for generalization and safety. Despite its promise, we identify a critical problem in anchored training that can lead to an increased risk of learning undesirable shortcuts, thereby limiting its generalization capabilities. To address this, we introduce a new anchored training protocol that employs a simple regularizer to mitigate this issue and significantly enhances generalization. We empirically evaluate our proposed approach across datasets and architectures of varying scales and complexities, demonstrating substantial performance gains in generalization and safety metrics compared to the standard training protocol. The open-source code is available at https://software.llnl.gov/anchoring.",Vivek Narayanaswamy; Kowshik Thopalli; Rushil Anirudh; Yamen Mubarka; Wesam A. Sakla; Jayaraman J. Thiagarajan,~Vivek_Narayanaswamy1; ~Kowshik_Thopalli1; ~Rushil_Anirudh1; ~Yamen_Mubarka1; ~Wesam_A._Sakla1; ~Jayaraman_J._Thiagarajan3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/31b62781b7295d311f43718b5f5a178ec72948c1.pdf,2024-05-13T20:42:06.236000,2024-09-25T18:10:55.115000,2024-11-06T06:18:25.197000,https://openreview.net/forum?id=xymhWyiZOp,Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Amazon; Lawrence Livermore National Laboratory; Lawrence Livermore National Laboratory; Apple
2434,bOYVESX7PK,bOYVESX7PK,7650,Identifying Equivalent Training Dynamics,"Study of the nonlinear evolution deep neural network (DNN) parameters undergo during training has uncovered regimes of distinct dynamical behavior. While a detailed understanding of these phenomena has the potential to advance improvements in training efficiency and robustness, the lack of methods for identifying when DNN models have equivalent dynamics limits the insight that can be gained from prior work. Topological conjugacy, a notion from dynamical systems theory, provides a precise definition of dynamical equivalence, offering a possible route to address this need. However, topological conjugacies have historically been challenging to compute. By leveraging advances in Koopman operator theory, we develop a framework for identifying conjugate and non-conjugate training dynamics. To validate our approach, we demonstrate that comparing Koopman eigenvalues can correctly identify a known equivalence between online mirror descent and online gradient descent. We then utilize our approach to: (a) identify non-conjugate training dynamics between shallow and wide fully connected neural networks; (b) characterize the early phase of training dynamics in convolutional neural networks; (c) uncover non-conjugate training dynamics in Transformers that do and do not undergo grokking. Our results, across a range of DNN architectures, illustrate the flexibility of our framework and highlight its potential for shedding new light on training dynamics.",William T Redman; Juan M. Bello-Rivas; Maria Fonoberova; Ryan Mohr; Yannis Kevrekidis; Igor Mezic,~William_T_Redman1; ~Juan_M._Bello-Rivas1; ~Maria_Fonoberova2; ~Ryan_Mohr1; ~Yannis_Kevrekidis1; ~Igor_Mezic1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/c8cddc675f77431637a5f5c7510c217cbfeb2954.pdf,2024-05-13T20:23:16.419000,2024-09-25T18:10:54.433000,2024-11-06T06:18:25.007000,https://openreview.net/forum?id=bOYVESX7PK,AIMdyn Inc.; Johns Hopkins University; Microsoft
2452,5k9XeHIK3L,5k9XeHIK3L,7571,Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts,"Prototyping complex computer-aided design (CAD) models in modern softwares can be very time-consuming. This is due to the lack of intelligent systems that can quickly generate simpler intermediate parts. We propose Text2CAD, the first AI framework for generating text-to-parametric CAD models using designer-friendly instructions for all skill levels. Furthermore, we introduce a data annotation pipeline for generating text prompts based on natural language instructions for the DeepCAD dataset using Mistral and LLaVA-NeXT. The dataset contains $\sim170$K models and $\sim660$K text annotations, from abstract CAD descriptions (e.g., _generate two concentric cylinders_) to detailed specifications (e.g., _draw two circles with center_ $(x,y)$ and _radius_ $r_{1}$, $r_{2}$, \textit{and extrude along the normal by} $d$...). Within the Text2CAD framework, we propose an end-to-end transformer-based auto-regressive network to generate parametric CAD models from input texts. We evaluate the performance of our model through a mixture of metrics, including visual quality, parametric precision, and geometrical accuracy. Our proposed framework shows great potential in AI-aided design applications. Project page is available at https://sadilkhan.github.io/text2cad-project/.",Mohammad Sadil Khan; Sankalp Sinha; Sheikh Talha Uddin; Didier Stricker; Sk Aziz Ali; Muhammad Zeshan Afzal,~Mohammad_Sadil_Khan1; ~Sankalp_Sinha1; ~Sheikh_Talha_Uddin1; ~Didier_Stricker1; ~Sk_Aziz_Ali2; ~Muhammad_Zeshan_Afzal1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/9f3142a99be0b0075f8fb4b87e46c8d0b8ed25e0.pdf,2024-05-13T19:27:20.498000,2024-09-25T18:10:51.753000,2024-11-06T06:18:24.172000,https://openreview.net/forum?id=5k9XeHIK3L,"Rheinland-Pfälzische Technische Universität; RPTU; German Research Center for AI; German Research Center for AI; Technical University Kaiserslautern; Birla Institute of Technology and Science, Pilani; German Research Center for AI; German Research Center for AI"
2457,cmBjkpRuvw,cmBjkpRuvw,7552,Axioms for AI Alignment from Human Feedback,"In the context of reinforcement learning from human feedback (RLHF), the reward function is generally derived from maximum likelihood estimation of a random utility model based on pairwise comparisons made by humans. The problem of learning a reward function is one of preference aggregation that, we argue, largely falls within the scope of social choice theory. From this perspective, we can evaluate different aggregation methods via established axioms, examining whether these methods meet or fail well-known standards. We demonstrate that both the Bradley-Terry-Luce Model and its broad generalizations fail to meet basic axioms. In response, we develop novel rules for learning reward functions with strong axiomatic guarantees. A key innovation from the standpoint of social choice is that our problem has a *linear* structure, which greatly restricts the space of feasible rules and leads to a new paradigm that we call *linear social choice*.",Luise Ge; Daniel Halpern; Evi Micha; Ariel D. Procaccia; Itai Shapira; Yevgeniy Vorobeychik; Junlin Wu,~Luise_Ge1; ~Daniel_Halpern1; ~Evi_Micha1; ~Ariel_D._Procaccia1; ~Itai_Shapira1; ~Yevgeniy_Vorobeychik1; ~Junlin_Wu2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/384780d6ea5008602cf547c18b0c256105a92008.pdf,2024-05-13T19:13:26.684000,2024-09-25T18:10:51.039000,2024-11-06T06:18:23.988000,https://openreview.net/forum?id=cmBjkpRuvw,"Washington University, Saint Louis; Harvard University; University of Southern California; Harvard University; Washington University, Saint Louis; Washington University, Saint Louis"
2465,Mwj57TcHWX,Mwj57TcHWX,7510,DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning,"This paper introduces DiffTORI, which utilizes $\textbf{Diff}$erentiable $\textbf{T}$rajectory $\textbf{O}$ptimization as the policy representation to generate actions for deep $\textbf{R}$einforcement and $\textbf{I}$mitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization.  As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTORI addresses the “objective mismatch” issue of prior model-based RL algorithms, as the dynamics model in DiffTORI is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTORI  for imitation learning on standard robotic manipulation task suites with high-dimensional sensory observations and compare our method to feedforward policy classes as well as Energy-Based Models (EBM) and Diffusion. Across 15 model based RL tasks and 35 imitation learning tasks with high-dimensional image and point cloud inputs, DiffTORI outperforms prior state-of-the-art methods in both domains.",Weikang Wan; Ziyu Wang; Yufei Wang; Zackory Erickson; David Held,~Weikang_Wan1; ~Ziyu_Wang15; ~Yufei_Wang4; ~Zackory_Erickson1; ~David_Held1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/797ea8f1f520e879eef0d48f51e53fa63d677421.pdf,2024-05-13T18:42:20.554000,2024-09-25T18:10:49.352000,2024-11-06T06:18:23.666000,https://openreview.net/forum?id=Mwj57TcHWX,"Peking University; NVIDIA; University of California, San Diego; Carnegie Mellon University; The University of Texas at Austin; Tsinghua University, Beijing; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University"
2471,2aGcshccuV,2aGcshccuV,7472,When Is Inductive Inference Possible?,"Can a physicist make only a finite number of errors in the eternal quest to uncover the law of nature?
This millennium-old philosophical problem, known as inductive inference, lies at the heart of epistemology.
Despite its significance to understanding human reasoning, a rigorous justification of inductive inference has remained elusive.
At a high level, inductive inference asks whether one can make at most finite errors amidst an infinite sequence of observations, when deducing the correct hypothesis from a given hypothesis class.
Historically, the only theoretical guarantee has been that if the hypothesis class is countable, inductive inference is possible, as exemplified by Solomonoff induction for learning Turing machines.
In this paper, we provide a tight characterization of inductive inference by establishing a novel link to online learning theory.
As our main result, we prove that inductive inference is possible if and only if the hypothesis class is a countable union of online learnable classes, potentially with an uncountable size, no matter the observations are adaptively chosen or iid sampled.
Moreover, the same condition is also sufficient and necessary in the agnostic setting, where any hypothesis class meeting this criterion enjoys an $\tilde{O}(\sqrt{T})$ regret bound for any time step $T$, while others require an arbitrarily slow rate of regret.
Our main technical tool is a novel non-uniform online learning framework, which may be of independent interest.
Our main technical tool is a novel non-uniform online learning framework, which may be of independent interest.",Zhou Lu,~Zhou_Lu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/e97a1eea8ae497e71e2ab1952dc037489d72efa3.pdf,2024-05-13T18:06:00.506000,2024-09-25T18:10:48.200000,2024-11-06T06:18:23.440000,https://openreview.net/forum?id=2aGcshccuV,
2490,Ddak3nSqQM,Ddak3nSqQM,7398,"Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting","When humans need to learn a new skill, we can acquire knowledge through written books, including textbooks, tutorials, etc. However, current research for decision-making, like reinforcement learning (RL), has primarily required numerous real interactions with the target environment to learn a skill, while failing to utilize the existing knowledge already summarized in the text. The success of Large Language Models (LLMs) sheds light on utilizing such knowledge behind the books. In this paper, we discuss a new policy learning problem called Policy Learning from tutorial Books (PLfB) upon the shoulders of LLMs’ systems, which aims to leverage rich resources such as tutorial books to derive a policy network. Inspired by how humans learn from books, we solve the problem via a three-stage framework: Understanding, Rehearsing, and Introspecting (URI). In particular, it first rehearses decision-making trajectories based on the derived knowledge after understanding the books, then introspects in the imaginary dataset to distill a policy network. 
 We build two benchmarks for PLfB~based on Tic-Tac-Toe and Football games. In experiment, URI's policy achieves at least 44% net win rate against GPT-based agents without any real data; In Football game, which is a complex scenario, URI's policy beat the built-in AIs with a 37% while using GPT-based agent can only achieve a 6\% winning rate. The project page: https://plfb-football.github.io.",Xiong-Hui Chen; Ziyan Wang; Yali Du; Shengyi Jiang; Meng Fang; Yang Yu; Jun Wang,~Xiong-Hui_Chen1; ~Ziyan_Wang3; ~Yali_Du1; ~Shengyi_Jiang2; ~Meng_Fang1; ~Yang_Yu5; ~Jun_Wang2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/f4d95b3399a1323142228b0362d42345119de142.pdf,2024-05-13T17:23:34.105000,2024-09-25T18:10:45.546000,2025-01-04T09:03:32.779000,https://openreview.net/forum?id=Ddak3nSqQM,Nanjing University; King's College London; Carnegie Mellon University; King's College London; Delft University of Technology; University of Liverpool; Nanjing University; University College London
2515,u6XxyuD3Ro,u6XxyuD3Ro,7317,Online Convex Optimisation: The Optimal Switching Regret for all Segmentations Simultaneously,"We consider the classic problem of online convex optimisation. Whereas the notion of static regret is relevant for stationary problems, the notion of switching regret is more appropriate for non-stationary problems. A switching regret is defined relative to any segmentation of the trial sequence, and is equal to the sum of the static regrets of each segment. In this paper we show that, perhaps surprisingly, we can achieve the asymptotically optimal switching regret on every possible segmentation simultaneously. Our algorithm for doing so is very efficient: having a space and per-trial time complexity that is logarithmic in the time-horizon. Our algorithm also obtains novel bounds on its dynamic regret: being adaptive to variations in the rate of change of the comparator sequence.",Stephen Pasteris; Chris Hicks; Vasilios Mavroudis; Mark Herbster,~Stephen_Pasteris1; ~Chris_Hicks1; ~Vasilios_Mavroudis1; ~Mark_Herbster1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,online_learning,/pdf/1d79cf793394d552ca09f0c84043a66df15140b0.pdf,2024-05-13T16:29:46.746000,2024-09-25T18:10:42.877000,2025-01-14T12:19:39.195000,https://openreview.net/forum?id=u6XxyuD3Ro,Alan Turing Institute; Alan Turing Institute; University College London
2519,mkzpN2T87C,mkzpN2T87C,7300,Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search,"In this paper, we present the first explicit and non-asymptotic global convergence rates of the BFGS method when implemented with an inexact line search scheme satisfying the Armijo-Wolfe conditions. We show that BFGS achieves a global linear convergence rate of $(1 - \frac{1}{\kappa})^t$ for $\mu$-strongly convex functions with $L$-Lipschitz gradients, where $\kappa = \frac{L}{\mu}$ represents the condition number. Additionally, if the objective function's Hessian is Lipschitz, BFGS with the Armijo-Wolfe line search achieves a linear convergence rate that depends solely on the line search parameters, independent of the condition number. We also establish a global superlinear convergence rate of $\mathcal{O}((\frac{1}{t})^t)$. These global bounds are all valid for any starting point $x_0$ and any symmetric positive definite initial Hessian approximation matrix $B_0$, though the choice of $B_0$ impacts the number of iterations needed to achieve these rates. By synthesizing these results, we outline the first global complexity characterization of BFGS with the Armijo-Wolfe line search. Additionally, we clearly define a mechanism for selecting the step size to satisfy the Armijo-Wolfe conditions and characterize its overall complexity.",Qiujiang Jin; Ruichen Jiang; Aryan Mokhtari,~Qiujiang_Jin1; ~Ruichen_Jiang1; ~Aryan_Mokhtari3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/381eca59c41cc65a2d39cfb89c6a5c1a62451b77.pdf,2024-05-13T16:23:13.063000,2024-09-25T18:10:42.336000,2024-11-06T06:18:21.532000,https://openreview.net/forum?id=mkzpN2T87C,The University of Texas at Austin; The University of Texas at Austin
2543,HN05DQxyLl,HN05DQxyLl,7205,Approximating mutual information of high-dimensional variables using learned representations,"Mutual information (MI) is a general measure of statistical dependence with widespread application across the sciences. However, estimating MI between multi-dimensional variables is challenging because the number of samples necessary to converge to an accurate estimate scales unfavorably with dimensionality. In practice, existing techniques can reliably estimate MI in up to tens of dimensions, but fail in higher dimensions, where sufficient sample sizes are infeasible. Here, we explore the idea that underlying low-dimensional structure in high-dimensional data can be exploited to faithfully approximate MI in high-dimensional settings with realistic sample sizes. We develop a method that we call latent MI (LMI) approximation, which applies a nonparametric MI estimator to low-dimensional representations learned by a simple, theoretically-motivated model architecture. Using several benchmarks, we show that unlike existing techniques, LMI can approximate MI well for variables with $> 10^3$ dimensions if their dependence structure is captured by low-dimensional representations. Finally, we showcase LMI on two open problems in biology. First, we approximate MI between protein language model (pLM) representations of interacting proteins, and find that pLMs encode non-trivial information about protein-protein interactions. Second, we quantify cell fate information contained in single-cell RNA-seq (scRNA-seq) measurements of hematopoietic stem cells, and find a sharp transition during neutrophil differentiation when fate information captured by scRNA-seq increases dramatically. An implementation of LMI is available at *latentmi.readthedocs.io.*",Gokul Gowri; Xiaokang Lun; Allon M Klein; Peng Yin,~Gokul_Gowri1; ~Xiaokang_Lun1; ~Allon_M_Klein1; ~Peng_Yin2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/b061bd1567a269ab237736569959410a04c5789b.pdf,2024-05-13T15:42:30.538000,2024-09-25T18:10:39.048000,2024-11-06T06:18:20.370000,https://openreview.net/forum?id=HN05DQxyLl,Harvard University; Harvard University
2547,Pf7kdIjHRf,Pf7kdIjHRf,7169,Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers,"One of the roadblocks for training generalist robotic models today is heterogeneity. Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting. This work studies the problem of learning policy representations through heterogeneous pre-training on robot data across different embodiments and tasks at scale. We propose Heterogeneous Pre-trained Transformers (HPT), which pre-train a large, shareable trunk of a policy neural network to learn a task and embodiment agnostic shared representation. This general architecture aligns the specific proprioception and vision inputs from distinct embodiments to a short sequence of tokens and then processes such tokens to map to control robots for different tasks. Leveraging the recent large-scale multi-embodiment real-world robotic datasets as well as simulation, deployed robots, and human video datasets, we investigate pre-training policies across heterogeneity. We conduct experiments to investigate the scaling behaviors of training objectives, to the extent of 52 datasets. HPTs outperform several baselines and enhance the fine-tuned policy performance by over 20% on unseen tasks in multiple simulator benchmarks and real-world settings. See the project website (liruiw.github.io/hpt) for code and videos.",Lirui Wang; Xinlei Chen; Jialiang Zhao; Kaiming He,~Lirui_Wang1; ~Xinlei_Chen1; ~Jialiang_Zhao1; ~Kaiming_He2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,robotics,/pdf/c13c57a0e7c8c79cd64396bfd32a10ba0b9c7238.pdf,2024-05-13T15:29:45.863000,2024-09-25T18:10:37.806000,2024-11-06T06:18:20.177000,https://openreview.net/forum?id=Pf7kdIjHRf,Massachusetts Institute of Technology; OpenAI; Meta; Massachusetts Institute of Technology; Meta; Massachusetts Institute of Technology
2554,h1iMVi2iEM,h1iMVi2iEM,7147,A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs,"As a popular paradigm for juggling data privacy and collaborative training, federated learning (FL) is flourishing to distributively process the large scale of heterogeneous datasets on edged clients. Due to bandwidth limitations and security considerations, it ingeniously splits the original problem into multiple subproblems to be solved in parallel, which empowers primal dual solutions to great application values in FL. In this paper, we review the recent development of classical federated primal dual methods and point out a serious common defect of such methods in non-convex scenarios, which we say is a ``dual drift'' caused by dual hysteresis of those longstanding inactive clients under partial participation training. To further address this problem, we propose a novel Aligned Federated Primal Dual (A-FedPD) method, which constructs virtual dual updates to align global consensus and local dual variables for those protracted unparticipated local clients. Meanwhile, we provide a comprehensive analysis of the optimization and generalization efficiency for the A-FedPD method on smooth non-convex objectives, which confirms its high efficiency and practicality. Extensive experiments are conducted on several classical FL setups to validate the effectiveness of our proposed method.",Yan Sun; Li Shen; Dacheng Tao,~Yan_Sun3; ~Li_Shen1; ~Dacheng_Tao1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/511a5d72ccce8fb7ef575e0074a4d74f9c27afee.pdf,2024-05-13T15:20:20.243000,2024-09-25T18:10:37.069000,2024-11-06T06:18:19.863000,https://openreview.net/forum?id=h1iMVi2iEM,University of Sydney; JD AI Research; Sun Yat-sen University; Nanyang Technological University
2558,DAtNDZHbqj,DAtNDZHbqj,7136,Variational Delayed Policy Optimization,"In environments with delayed observation, state augmentation by including actions within the delay window is adopted to retrieve Markovian property to enable reinforcement learning (RL). Whereas, state-of-the-art (SOTA) RL techniques with Temporal-Difference (TD) learning frameworks commonly suffer from learning inefficiency, due to the significant expansion of the augmented state space with the delay. To improve the learning efficiency without sacrificing performance, this work novelly introduces Variational Delayed Policy Optimization (VDPO), reforming delayed RL as a variational inference problem. This problem is further modelled as a two-step iterative optimization problem, where the first step is TD learning in the delay-free environment with a small state space, and the second step is behaviour cloning which can be addressed much more efficiently than TD learning. We not only provide a theoretical analysis of VDPO in terms of sample complexity and performance, but also empirically demonstrate that VDPO can achieve consistent performance with SOTA methods, with a significant enhancement of sample efficiency (approximately 50\% less amount of samples) in the MuJoCo benchmark.",Qingyuan Wu; Simon Sinong Zhan; Yixuan Wang; Yuhui Wang; Chung-Wei Lin; Chen Lv; Qi Zhu; Chao Huang,~Qingyuan_Wu1; ~Simon_Sinong_Zhan1; ~Yixuan_Wang1; ~Yuhui_Wang1; ~Chung-Wei_Lin1; ~Chen_Lv1; ~Qi_Zhu2; ~Chao_Huang5,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/d97a3ffd9d96cadb9fcf33a58bd18c416933fd62.pdf,2024-05-13T15:16:10.709000,2024-09-25T18:10:36.618000,2024-11-06T06:18:19.663000,https://openreview.net/forum?id=DAtNDZHbqj,University of Liverpool; University of Southampton; Northwestern University; King Abdullah University of Science and Technology; Nanyang Technological University; Northwestern University; University of Liverpool; University of Southampton
2582,3LKuC8rbyV,3LKuC8rbyV,7029,Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning,"Machine unlearning has raised significant interest with the adoption of laws ensuring the ``right to be forgotten''. Researchers have provided a probabilistic notion of approximate unlearning under a similar definition of Differential Privacy (DP), where privacy is defined as statistical indistinguishability to retraining from scratch. We propose Langevin unlearning, an unlearning framework based on noisy gradient descent with privacy guarantees for approximate unlearning problems. Langevin unlearning unifies the DP learning process and the privacy-certified unlearning process with many algorithmic benefits. These include approximate certified unlearning for non-convex problems, complexity saving compared to retraining, sequential and batch unlearning for multiple unlearning requests.",Eli Chien; Haoyu Peter Wang; Ziang Chen; Pan Li,~Eli_Chien1; ~Haoyu_Peter_Wang1; ~Ziang_Chen1; ~Pan_Li2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,privacy,/pdf/aa13791d4d47615e643c1857acf62c40610ff40a.pdf,2024-05-13T14:36:44.347000,2024-09-25T18:10:33.083000,2024-11-06T06:18:18.659000,https://openreview.net/forum?id=3LKuC8rbyV,Georgia Institute of Technology; Georgia Institute of Technology
2584,T0glCBw28a,T0glCBw28a,7027,The ALCHEmist: Automated Labeling 500x CHEaper than LLM Data Annotators,"Large pretrained models can be used as annotators, helping replace or augment crowdworkers and enabling distilling generalist models into smaller specialist models. Unfortunately, this comes at a cost: employing top-of-the-line models often requires paying thousands of dollars for API calls, while the resulting datasets are static and challenging to audit. To address these challenges, we propose a simple alternative: rather than directly querying labels from pretrained models, we task models to generate programs that can produce labels. These programs can be stored and applied locally, re-used and extended, and cost orders of magnitude less. Our system, $\textbf{Alchemist}$, obtains comparable to or better performance than large language model-based annotation in a range of tasks for a fraction of the cost: on average, improvements amount to a $\textbf{12.9}$% enhancement while the total labeling costs across all datasets are reduced by a factor of approximately $\textbf{500}\times$.",Tzu-Heng Huang; Catherine Cao; Vaishnavi Bhargava; Frederic Sala,~Tzu-Heng_Huang1; ~Catherine_Cao1; ~Vaishnavi_Bhargava1; ~Frederic_Sala1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/53a3bb2ee078f274280d72c6694f12d99ca0d2ba.pdf,2024-05-13T14:35:55.188000,2024-09-25T18:10:32.908000,2024-11-06T06:18:18.629000,https://openreview.net/forum?id=T0glCBw28a,Apple; University of Wisconsin - Madison; University of Wisconsin - Madison
2590,PGOuBHYdbr,PGOuBHYdbr,7001,Thompson Sampling For Combinatorial Bandits: Polynomial Regret and Mismatched Sampling Paradox,We consider Thompson Sampling (TS) for linear combinatorial semi-bandits and subgaussian rewards. We propose the first known TS whose finite-time regret does not scale exponentially with the dimension of the problem. We further show the mismatched sampling paradox: A learner who knows the rewards distributions and samples from the correct posterior distribution can perform exponentially worse than a learner who does not know the rewards and simply samples from a well-chosen Gaussian posterior. The code used to generate the experiments is available at https://github.com/RaymZhang/CTS-Mismatched-Paradox,Raymond Zhang; Richard Combes,~Raymond_Zhang1; ~Richard_Combes1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,bandits,/pdf/8644b06f7b2ccc9b027f161438d8a5e12d2b0cb4.pdf,2024-05-13T14:27:08.198000,2024-09-25T18:10:31.655000,2025-01-15T17:09:02.217000,https://openreview.net/forum?id=PGOuBHYdbr,
2597,OuKW8cUiuY,OuKW8cUiuY,6958,Diffusion Priors for Variational Likelihood Estimation and Image Denoising,"Real-world noise removal is crucial in low-level computer vision. Due to the remarkable generation capabilities of diffusion models, recent attention has shifted towards leveraging diffusion priors for image restoration tasks. However, existing diffusion priors-based methods either consider simple noise types or rely on approximate posterior estimation, limiting their effectiveness in addressing structured and signal-dependent noise commonly found in real-world images. In this paper, we build upon diffusion priors and propose adaptive likelihood estimation and MAP inference during the reverse diffusion process to tackle real-world noise. We introduce an independent, non-identically distributed likelihood combined with the noise precision (inverse variance) prior and dynamically infer the precision posterior using variational Bayes during the generation process. Meanwhile, we rectify the estimated noise variance through local Gaussian convolution. The final denoised image is obtained by propagating intermediate MAP solutions that balance the updated likelihood and diffusion prior. Additionally, we explore the local diffusion prior inherent in low-resolution diffusion models, enabling direct handling of high-resolution noisy images. Extensive experiments and analyses on diverse real-world datasets demonstrate the effectiveness of our method. Code is available at https://github.com/HUST-Tan/DiffusionVI.",Jun Cheng; Shan Tan,~Jun_Cheng7; ~Shan_Tan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/06036f3c58df1c9149580acbacd0e9cb3872f737.pdf,2024-05-13T14:04:16.087000,2024-09-25T18:10:30.172000,2024-11-06T06:18:18.042000,https://openreview.net/forum?id=OuKW8cUiuY,Huazhong University of Science and Technology; Huazhong University of Science and Technology
2604,gITGmIEinf,gITGmIEinf,6935,Approximating the Top Eigenvector in Random Order Streams,"When rows of an $n \times d$ matrix $A$ are given in a stream, we study algorithms for approximating the top eigenvector of $A^T A$ (equivalently, the top right singular vector of $A$). We consider worst case inputs $A$ but assume that the rows are presented to the streaming algorithm in a uniformly random order. We show that when the gap parameter $R = \sigma_1(A)^2/\sigma_2(A)^2 = \Omega(1)$, then there is a randomized algorithm that uses $O(h \cdot d \cdot \text{polylog}(d))$ bits of space and outputs a unit vector $v$ that has a correlation $1 - O(1/\sqrt{R})$ with the top eigenvector $v_1$. Here $h$ denotes the number of ``heavy rows'' in the matrix, defined as the rows with Euclidean norm at least $\|{A}\|_F/\sqrt{d \cdot \text{polylog}(d)}$. We also provide a lower bound showing that any algorithm using $O(hd/R)$ bits of space can obtain at most $1 - \Omega(1/R^2)$ correlation with the top eigenvector. Thus, parameterizing the space complexity in terms of the number of heavy rows is necessary for high accuracy solutions.

Our results improve upon the $R = \Omega(\log n \cdot \log d)$ requirement  in a recent work of Price. We note that Price's algorithm works for arbitrary order streams whereas our algorithm requires a stronger assumption that the rows are presented in a uniformly random order. We additionally show that the gap requirements in Price's analysis can be brought down to $R = \Omega(\log^2 d)$ for arbitrary order streams and $R = \Omega(\log d)$ for random order streams. The requirement of $R = \Omega(\log d)$ for random order streams is nearly tight for Price's analysis as we obtain a simple instance with $R = \Omega(\log d/\log\log d)$ for which Price's algorithm, with any fixed learning rate, cannot output a vector approximating the top eigenvector $v_1$.",Praneeth Kacham; David Woodruff,~Praneeth_Kacham1; ~David_Woodruff1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/7c7ec19817846e15ae1777f56dbfdeecb133f68e.pdf,2024-05-13T13:50:10.704000,2024-09-25T18:10:29.544000,2024-11-06T06:18:17.743000,https://openreview.net/forum?id=gITGmIEinf,Google; Carnegie Mellon University
2611,enlxHLwwFf,enlxHLwwFf,6898,Functional Bilevel Optimization for Machine Learning,"In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks.",Ieva Petrulionytė; Julien Mairal; Michael Arbel,~Ieva_Petrulionytė1; ~Julien_Mairal1; ~Michael_Arbel1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/5133c5b9c29b8972f15d6e48d6249a792f75ff6c.pdf,2024-05-13T13:37:11.968000,2024-09-25T18:10:28.344000,2024-11-06T06:18:17.642000,https://openreview.net/forum?id=enlxHLwwFf,"Inria, Paris; Inria, Paris"
2622,SSCtCq2MH2,SSCtCq2MH2,6848,GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation,"This paper studies the problem of estimating physical properties (system identification) through visual observations. To facilitate geometry-aware guidance in physical property estimation, we introduce a novel hybrid framework that leverages 3D Gaussian representation to not only capture explicit shapes but also enable the simulated continuum to render object masks as 2D shape surrogates during training. We propose a new dynamic 3D Gaussian framework based on motion factorization to recover the object as 3D Gaussian point sets across different time states. Furthermore, we develop a coarse-to-fine filling strategy to generate the density fields of the object from the Gaussian reconstruction, allowing for the extraction of object continuums along with their surfaces and the integration of Gaussian attributes into these continuum. In addition to the extracted object surfaces, the Gaussian-informed continuum also enables the rendering of object masks during simulations, serving as 2D-shape guidance for physical property estimation. Extensive experimental evaluations demonstrate that our pipeline achieves state-of-the-art performance across multiple benchmarks and metrics. Additionally, we illustrate the effectiveness of the proposed method through real-world demonstrations, showcasing its practical utility. Our project page is at  https://jukgei.github.io/project/gic.",Junhao Cai; Yuji Yang; Weihao Yuan; Yisheng HE; Zilong Dong; Liefeng Bo; Hui Cheng; Qifeng Chen,~Junhao_Cai1; ~Yuji_Yang1; ~Weihao_Yuan1; ~Yisheng_HE1; ~Zilong_Dong2; ~Liefeng_Bo1; ~Hui_Cheng5; ~Qifeng_Chen1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_vision,/pdf/35d3fb34ac9b1b65eb96b7a01480e9b13895a855.pdf,2024-05-13T13:14:43.617000,2024-09-25T18:10:27.248000,2024-11-06T06:18:16.951000,https://openreview.net/forum?id=SSCtCq2MH2,Hong Kong University of Science and Technology(Guangzhou); Sun Yat-sen University; Alibaba Group; Alibaba Group; Alibaba Group; Alibaba Group; Sun Yat-sen University; Hong Kong University of Science and Technology(Guangzhou)
2650,aNQWRHyh15,aNQWRHyh15,6735,In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies,"We present a new random walk for uniformly sampling high-dimensional convex bodies. It achieves state-of-the-art runtime complexity with stronger guarantees on the output than previously known, namely in Rényi divergence (which implies TV, $\mathcal{W}_2$, KL, $\chi^2$). The proof departs from known approaches for polytime algorithms for the problem - we utilize a stochastic diffusion perspective to show contraction to the target distribution with the rate of convergence determined by functional isoperimetric constants of the stationary density.",Yunbum Kook; Santosh Vempala; Matthew Shunshi Zhang,~Yunbum_Kook1; ~Santosh_Vempala1; ~Matthew_Shunshi_Zhang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/df8f4f026ee93c5ce31f8c590424320f4f3313d6.pdf,2024-05-13T12:30:50.184000,2024-09-25T18:10:23.891000,2024-11-06T06:18:15.655000,https://openreview.net/forum?id=aNQWRHyh15,Georgia Institute of Technology; University of Toronto
2656,X2UMdvcmMo,X2UMdvcmMo,6702,FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images,"Facial parts swapping aims to selectively transfer regions of interest from the source image onto the target image while maintaining the rest of the target image unchanged.
Most studies on face swapping designed specifically for full-face swapping, are either unable or significantly limited when it comes to swapping individual facial parts, which hinders fine-grained and customized character designs.
However, designing such an approach specifically for facial parts swapping is challenged by a reasonable multiple reference feature fusion, which needs to be both efficient and effective.
To overcome this challenge, FuseAnyPart is proposed to facilitate the seamless ""fuse-any-part"" customization of the face.
In FuseAnyPart, facial parts from different people are assembled into a complete face in latent space within the Mask-based Fusion Module.
Subsequently, the consolidated feature is dispatched to the Addition-based Injection Module for
fusion within the UNet of the diffusion model to create novel characters.
Extensive experiments qualitatively and quantitatively validate the superiority and robustness of FuseAnyPart.
Source codes are available at https://github.com/Thomas-wyh/FuseAnyPart.",Zheng Yu; Yaohua Wang; Siying Cui; Aixi Zhang; Wei-Long Zheng; Senzhang Wang,~Zheng_Yu4; ~Yaohua_Wang2; ~Siying_Cui1; ~Aixi_Zhang2; ~Wei-Long_Zheng1; ~Senzhang_Wang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/dbba55c268b5c8d21a7734deddad6b07ffd0c949.pdf,2024-05-13T12:14:04.442000,2024-09-25T18:10:22.892000,2024-11-06T06:18:15.440000,https://openreview.net/forum?id=X2UMdvcmMo,"Shanghai Jiao Tong University; Alibaba Group; Tsinghua University, Beijing; Peking University; Alibaba Group; Shanghai Jiao Tong University; Central South University"
2669,nIeufGuQ9x,nIeufGuQ9x,6624,DiffSF: Diffusion Models for Scene Flow Estimation,"Scene flow estimation is an essential ingredient for a variety of real-world applications, especially for autonomous agents, such as self-driving cars and robots. While recent scene flow estimation approaches achieve reasonable accuracy, their applicability to real-world systems additionally benefits from a reliability measure. Aiming at improving accuracy while additionally providing an estimate for uncertainty, we propose DiffSF that combines transformer-based scene flow estimation with denoising diffusion models. In the diffusion process, the ground truth scene flow vector field is gradually perturbed by adding Gaussian noise. In the reverse process, starting from randomly sampled Gaussian noise, the scene flow vector field prediction is recovered by conditioning on a source and a target point cloud. We show that the diffusion process greatly increases the robustness of predictions compared to prior approaches resulting in state-of-the-art performance on standard scene flow estimation benchmarks. Moreover, by sampling multiple times with different initial states, the denoising process predicts multiple hypotheses, which enables measuring the output uncertainty, allowing our approach to detect a majority of the inaccurate predictions. The code is available at https://github.com/ZhangYushan3/DiffSF.",Yushan Zhang; Bastian Wandt; Maria Magnusson; Michael Felsberg,~Yushan_Zhang1; ~Bastian_Wandt2; ~Maria_Magnusson1; ~Michael_Felsberg2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/469a83f616f15f8f0d5c0e23e222481187df6199.pdf,2024-05-13T11:37:54.211000,2024-09-25T18:10:21.101000,2024-11-06T06:18:14.907000,https://openreview.net/forum?id=nIeufGuQ9x,Linköping University; NVIDIA; Linköping University; Linköping University
2674,4DA5vaPHFb,4DA5vaPHFb,6596,Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport,"We present a new approach for Neural Optimal Transport (NOT) training procedure, capable of accurately and efficiently estimating optimal transportation plan via specific regularization on dual Kantorovich potentials. The main bottleneck of existing NOT solvers is associated with the procedure of finding a near-exact approximation of the conjugate operator (i.e., the c-transform), which is done either by optimizing over non-convex max-min objectives or by the computationally intensive fine-tuning of the initial approximated prediction. We resolve both issues by proposing a new theoretically justified loss in the form of expectile regularization which enforces binding conditions on the learning process of the dual potentials. Such a regularization provides the upper bound estimation over the distribution of possible conjugate potentials and makes the learning stable, completely eliminating the need for additional extensive fine-tuning. Proposed method, called Expectile-Regularized Neural Optimal Transport (ENOT), outperforms previous state-of-the-art approaches in the established Wasserstein-2 benchmark tasks by a large margin (up to a 3-fold improvement in quality and up to a 10-fold improvement in runtime). Moreover, we showcase performance of ENOT for various cost functions in different tasks, such as image generation, demonstrating generalizability and robustness of the proposed algorithm.",Nazar Buzun; Maksim Bobrin; Dmitry V. Dylov,~Nazar_Buzun1; ~Maksim_Bobrin1; ~Dmitry_V._Dylov1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/205d45fb32e98954f27c1fa59331354cffba2412.pdf,2024-05-13T11:26:36.058000,2024-09-25T18:10:20.101000,2024-11-06T06:18:14.730000,https://openreview.net/forum?id=4DA5vaPHFb,The Skolkovo Institute of Science and Technology; The Skolkovo Institute of Science and Technology; AIRI; The Skolkovo Institute of Science and Technology
2684,7O6KtaAr8n,7O6KtaAr8n,6544,Learning Social Welfare Functions,"Is it possible to understand or imitate a policy maker's rationale by looking at past decisions they made? We formalize this question as the problem of learning social welfare functions belonging to the well-studied family of power mean functions. We focus on two learning tasks; in the first, the input is vectors of utilities of an action (decision or policy) for individuals in a group and their associated social welfare as judged by a policy maker, whereas in the second, the input is pairwise comparisons between the welfares associated with a given pair of utility vectors. We show that power mean functions are learnable with polynomial sample complexity in both cases, even if the social welfare information is noisy. Finally, we design practical algorithms for these tasks and evaluate their performance.",Kanad Shrikar Pardeshi; Itai Shapira; Ariel D. Procaccia; Aarti Singh,~Kanad_Shrikar_Pardeshi1; ~Itai_Shapira1; ~Ariel_D._Procaccia1; ~Aarti_Singh1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/54eb0830d5ca05f88f13138e8eb57bb7580bef36.pdf,2024-05-13T10:59:28.942000,2024-09-25T18:10:18.135000,2024-11-06T06:18:14.334000,https://openreview.net/forum?id=7O6KtaAr8n,Carnegie Mellon University; Harvard University
2691,YvA8UF0I37,YvA8UF0I37,6508,PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression,"There has been significant interest in ""extreme"" compression of large language models (LLMs), i.e. to 1-2 bits per parameter, which allows such models to be executed efficiently on resource-constrained devices.  
Existing work focused on improved one-shot quantization techniques and weight representations; yet, purely post-training  approaches are reaching diminishing returns in terms of the accuracy-vs-bit-width trade-off. State-of-the-art quantization methods such as QuIP# and AQLM include fine-tuning (part of) the compressed parameters over a limited amount of calibration data; however, such fine-tuning techniques over compressed weights often make exclusive use of straight-through estimators (STE), whose performance is not well-understood in this setting. 
In this work, we question the use of STE for extreme LLM compression, showing that it can be sub-optimal, and perform a systematic study of quantization-aware fine-tuning strategies for LLMs.
We propose PV-Tuning - a representation-agnostic framework that generalizes and improves upon existing fine-tuning strategies, and provides convergence guarantees in restricted cases.
On the practical side, when used for 1-2 bit vector quantization, PV-Tuning outperforms prior techniques for highly-performant models such as Llama and Mistral. 
Using PV-Tuning, we achieve the first Pareto-optimal quantization for Llama-2 family models at  2 bits per parameter.",Vladimir Malinovskii; Denis Mazur; Ivan Ilin; Denis Kuznedelev; Konstantin Pavlovich Burlachenko; Kai Yi; Dan Alistarh; Peter Richtárik,~Vladimir_Malinovskii1; ~Denis_Mazur1; ~Ivan_Ilin1; ~Denis_Kuznedelev1; ~Konstantin_Pavlovich_Burlachenko1; ~Kai_Yi1; ~Dan_Alistarh7; ~Peter_Richtárik1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/a41bd553618c035e26d1f1f6a8ebd19108274f50.pdf,2024-05-13T10:32:54.425000,2024-09-25T18:10:16.807000,2024-11-06T06:18:14.066000,https://openreview.net/forum?id=YvA8UF0I37,Yandex; National Research University Higher School of Economics; Moscow Institute of Physics and Technology; King Abdullah University of Science and Technology; Yandex; King Abdullah University of Science and Technology; Institute of Science and Technology Austria; King Abdullah University of Science and Technology
2711,LEzx6QRkRH,LEzx6QRkRH,6379,RL-GPT: Integrating Reinforcement Learning and Code-as-policy,"Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.",Shaoteng Liu; Haoqi Yuan; Minda Hu; Yanwei Li; Yukang Chen; Shu Liu; Zongqing Lu; Jiaya Jia,~Shaoteng_Liu1; ~Haoqi_Yuan1; ~Minda_Hu1; ~Yanwei_Li1; ~Yukang_Chen1; ~Shu_Liu4; ~Zongqing_Lu2; ~Jiaya_Jia1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/8489e6d14edc65b16f5f04f6773edb790ac430a4.pdf,2024-05-13T09:13:52.744000,2024-09-25T18:10:13.005000,2024-11-06T06:18:13.213000,https://openreview.net/forum?id=LEzx6QRkRH,Adobe Systems; Chinese University of Hong Kong; Peking University; Chinese University of Hong Kong; ByteDance Inc.; Chinese University of Hong Kong; NVIDIA; Smartmore Technology; Peking University; Hong Kong University of Science and Technology(Guangzhou)
2721,5iUxMVJVEV,5iUxMVJVEV,6350,Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis,"Time series analysis finds wide applications in fields such as weather forecasting, anomaly detection, and behavior recognition. Previous methods attempted to model temporal variations directly using 1D time series. However, this has been quite challenging due to the discrete nature of data points in time series and the complexity of periodic variation. In terms of periodicity, taking weather and traffic data as an example, there are multi-periodic variations such as yearly, monthly, weekly, and daily, etc. In order to break through the limitations of the previous methods, we decouple the implied complex periodic variations into inclusion and overlap relationships among different level periodic components based on the observation of the multi-periodicity therein and its inclusion relationships. This explicitly represents the naturally occurring pyramid-like properties in time series, where the top level is the original time series and lower levels consist of periodic components with gradually shorter periods, which we call the periodic pyramid. To further extract complex temporal variations, we introduce self-attention mechanism into the periodic pyramid, capturing complex periodic relationships by computing attention between periodic components based on their inclusion, overlap, and adjacency relationships. Our proposed Peri-midFormer demonstrates outstanding performance in five mainstream time series analysis tasks, including short- and long-term forecasting, imputation, classification, and anomaly detection.",Qiang Wu; Gechang Yao; Zhixi Feng; Shuyuan Yang,~Qiang_Wu8; ~Gechang_Yao1; ~Zhixi_Feng1; ~Shuyuan_Yang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/3ac59359084dfedf179eab80c5846777a457947e.pdf,2024-05-13T08:58:19.506000,2024-09-25T18:10:12.044000,2025-01-08T08:11:18.439000,https://openreview.net/forum?id=5iUxMVJVEV,Xidian University; Xidian University; Xidian University; Xidian University
2729,lcALCNF2qe,lcALCNF2qe,6328,Towards Universal Mesh Movement Networks,"Solving complex Partial Differential Equations (PDEs) accurately and efficiently is an essential and challenging problem in all scientific and engineering disciplines. Mesh movement methods provide the capability to improve the accuracy of the numerical solution without increasing the overall mesh degree of freedom count. Conventional sophisticated mesh movement methods are extremely expensive and struggle to handle scenarios with complex boundary geometries. However, existing learning-based methods require re-training from scratch given a different PDE type or boundary geometry, which limits their applicability, and also often suffer from robustness issues in the form of inverted elements. In this paper, we introduce the Universal Mesh Movement Network (UM2N), which -- once trained -- can be applied in a non-intrusive, zero-shot manner to move meshes with different size distributions and structures, for solvers applicable to different PDE types and boundary geometries. UM2N consists of a Graph Transformer (GT) encoder for extracting features and a Graph Attention Network (GAT) based decoder for moving the mesh. We evaluate our method on advection and Navier-Stokes based examples, as well as a real-world tsunami simulation case. Our method out-performs existing learning-based mesh movement methods in terms of the benchmarks described above. In comparison to the conventional sophisticated Monge-Ampère PDE-solver based method, our approach not only significantly accelerates mesh movement, but also proves effective in scenarios where the conventional method fails. Our project page can be found at https://erizmr.github.io/UM2N/.",Mingrui Zhang; Chunyang Wang; Stephan C. Kramer; Joseph Gregory Wallwork; Siyi Li; Jiancheng Liu; Xiang Chen; Matthew D Piggott,~Mingrui_Zhang4; ~Chunyang_Wang1; ~Stephan_C._Kramer1; ~Joseph_Gregory_Wallwork1; ~Siyi_Li6; ~Jiancheng_Liu2; ~Xiang_Chen8; ~Matthew_D_Piggott1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/f76c7735ce5ebac8981b5ac2377795bf7fb37598.pdf,2024-05-13T08:52:25.449000,2024-09-25T18:10:11.324000,2025-01-13T02:14:28.762000,https://openreview.net/forum?id=lcALCNF2qe,Tencent; Imperial College London; Imperial College London; Imperial College London; Met Office; University of Cambridge; Imperial College London; Michigan State University; Huawei Technologies Research & Development (UK) Ltd
2735,9FYat8HPpv,9FYat8HPpv,6311,SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams,"Reconstructing a sequence of sharp images from the blurry input is crucial for enhancing our insights into the captured scene and poses a significant challenge due to the limited temporal features embedded in the image. Spike cameras, sampling at rates up to 40,000 Hz, have proven effective in capturing motion features and beneficial for solving this ill-posed problem. Nonetheless, existing methods fall into the supervised learning paradigm, which suffers from notable performance degradation when applied to real-world scenarios that diverge from the synthetic training data domain. To address these challenges, we propose the first self-supervised framework for the task of spike-guided motion deblurring. Our approach begins with the formulation of a spike-guided deblurring model that explores the theoretical relationships among spike streams, blurry images, and their corresponding sharp sequences. We subsequently develop a self-supervised cascaded framework to alleviate the issues of spike noise and spatial-resolution mismatching encountered in the deblurring model. With knowledge distillation and re-blurring loss, we further design a lightweight deblur network to generate high-quality sequences with brightness and texture consistency with the original input. Quantitative and qualitative experiments conducted on our real-world and synthetic datasets with spikes validate the superior generalization of the proposed framework. Our code, data and trained models are available at \url{https://github.com/chenkang455/S-SDM}.",Kang Chen; Shiyan Chen; Jiyuan Zhang; Baoyue Zhang; Yajing Zheng; Tiejun Huang; Zhaofei Yu,~Kang_Chen9; ~Shiyan_Chen1; ~Jiyuan_Zhang3; ~Baoyue_Zhang1; ~Yajing_Zheng1; ~Tiejun_Huang1; ~Zhaofei_Yu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/9df7f66462e4533aebee3c88a3dbbf45c92e9ff1.pdf,2024-05-13T08:43:59.911000,2024-09-25T18:10:10.616000,2024-12-20T08:42:57.299000,https://openreview.net/forum?id=9FYat8HPpv,Peking University; Peking University; Peking University; Peking University; Peking University; University College London; Peking University; Peking University
2745,4fSSqpk1sM,4fSSqpk1sM,6277,Resolving Discrepancies in Compute-Optimal Scaling of Language Models,"Kaplan et al. and Hoffmann et al. developed influential scaling laws for the optimal model size as a function of the compute budget, but these laws yield substantially different predictions. We explain the discrepancy by reproducing the Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and identifying three factors causing the difference: last layer computational cost, warmup duration, and scale-dependent optimizer tuning. With these factors corrected, we obtain excellent agreement with the Hoffmann et al. (i.e., ""Chinchilla"") scaling law. Counter to a hypothesis of Hoffmann et al., we find that careful learning rate decay is not essential for the validity of their scaling law. As a secondary result, we derive scaling laws for the optimal learning rate and batch size, finding that tuning the AdamW $\beta_2$ parameter is essential at lower batch sizes.",Tomer Porian; Mitchell Wortsman; Jenia Jitsev; Ludwig Schmidt; Yair Carmon,~Tomer_Porian1; ~Mitchell_Wortsman1; ~Jenia_Jitsev1; ~Ludwig_Schmidt1; ~Yair_Carmon1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/e638502ae6c06477a675bb6e68eeaa986174b2ec.pdf,2024-05-13T08:29:50.531000,2024-09-25T18:10:09.703000,2024-11-06T06:18:11.690000,https://openreview.net/forum?id=4fSSqpk1sM,Forschungszentrum Jülich; Forschungszentrum Jülich; LAION; Stanford University; Anthropic; University of Washington; Tel Aviv University
2749,QpKWFLtZKi,QpKWFLtZKi,6262,Rethinking Exploration in Reinforcement Learning with Effective Metric-Based Exploration Bonus,"Enhancing exploration in reinforcement learning (RL) through the incorporation of intrinsic rewards, specifically by leveraging *state discrepancy* measures within various metric spaces as exploration bonuses, has emerged as a prevalent strategy to encourage agents to visit novel states. The critical factor lies in how to quantify the difference between adjacent states as *novelty* for promoting effective exploration.
Nonetheless, existing methods that evaluate state discrepancy in the latent space under $L_1$ or $L_2$ norm often depend on count-based episodic terms as scaling factors for exploration bonuses, significantly limiting their scalability. Additionally, methods that utilize the bisimulation metric for evaluating state discrepancies face a theory-practice gap due to improper approximations in metric learning, particularly struggling with *hard exploration* tasks. To overcome these challenges, we introduce the **E**ffective **M**etric-based **E**xploration-bonus (EME). EME critically examines and addresses the inherent limitations and approximation inaccuracies of current metric-based state discrepancy methods for exploration, proposing a robust metric for state discrepancy evaluation backed by comprehensive theoretical analysis. Furthermore, we propose the diversity-enhanced scaling factor integrated into the exploration bonus to be dynamically adjusted by the variance of prediction from an ensemble of reward models, thereby enhancing exploration effectiveness in particularly challenging scenarios. 
Extensive experiments are conducted on hard exploration tasks within Atari games, Minigrid, Robosuite, and Habitat, which illustrate our method's scalability to various scenarios. The project website can be found at https://sites.google.com/view/effective-metric-exploration.",Yiming Wang; Kaiyan Zhao; Furui Liu; Leong Hou U,~Yiming_Wang15; ~Kaiyan_Zhao3; ~Furui_Liu1; ~Leong_Hou_U2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/423a34e03d164123b65bbc51e55d860ca217e428.pdf,2024-05-13T08:23:46.507000,2024-09-25T18:10:09.430000,2025-01-08T12:56:32.035000,https://openreview.net/forum?id=QpKWFLtZKi,University of Macau; University of Macau; Wuhan University; Zhejiang University; University of Macau
2759,LzLeAscHnj,LzLeAscHnj,6184,Bridging The Gap between Low-rank and Orthogonal Adaptation via Householder Reflection Adaptation,"While following different technical routes, both low-rank and orthogonal adaptation techniques can efficiently adapt large-scale pre-training models in specific tasks or domains based on a small piece of trainable parameters. In this study, we bridge the gap between these two techniques, proposing a simple but effective adaptation method based on Householder reflections. Given a pre-trained model, our method fine-tunes its layers by multiplying each frozen weight matrix with an orthogonal matrix constructed by a chain of learnable Householder reflections (HRs). This HR-based orthogonal fine-tuning is equivalent to an adaptive low-rank adaptation. Moreover, we show that the orthogonality of the reflection planes corresponding to the HRs impacts the model capacity and regularity. The analysis motivates us to regularize the orthogonality of the HRs, leading to different implementations of the proposed Householder reflection adaptation (HRA) method. Compared with state-of-the-art methods, HRA achieves superior performance with fewer learnable parameters when adapting large language models and conditional image generators. The code of the experiments is available at https://github.com/DaShenZi721/HRA, and the method has been merged into the [PEFT](https://github.com/huggingface/peft) package.",Shen Yuan; Haotian Liu; Hongteng Xu,~Shen_Yuan1; ~Haotian_Liu9; ~Hongteng_Xu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/7f5e41de0065d41d0d2eaffaa85c8e7a955b837a.pdf,2024-05-13T07:47:58.283000,2024-09-25T18:10:07.382000,2024-12-19T08:53:19.525000,https://openreview.net/forum?id=LzLeAscHnj,Renmin University of China; Beijing Institute of Technology; Renmin University of China; Renmin University of China
2775,I2gVmVRgNk,I2gVmVRgNk,6086,Towards Understanding Evolving Patterns in Sequential Data,"In many machine learning tasks, data is inherently sequential. Most existing algorithms learn from sequential data in an auto-regressive manner, which predicts the next unseen data point based on the observed sequence, implicitly assuming the presence of an \emph{evolving pattern} embedded in the data that can be leveraged. However, identifying and assessing evolving patterns in learning tasks often relies on subjective judgments rooted in the prior knowledge of human experts, lacking a standardized quantitative measure. Furthermore, such measures enable us to determine the suitability of employing sequential models effectively and make informed decisions on the temporal order of time series data, and feature/data selection processes. To address this issue, we introduce the Evolving Rate (EvoRate), which quantitatively approximates the intensity of evolving patterns in the data with Mutual Information. Furthermore, in some temporal data with neural mutual information estimations, we only have snapshots at different timestamps, lacking correspondence, which hinders EvoRate estimation. To tackle this challenge, we propose EvoRate$_\mathcal{W}$, aiming to establish correspondence with optimal transport for estimating the first-order EvoRate. Experiments on synthetic and real-world datasets including images and tabular data validate the efficacy of our EvoRate.",QIUHAO Zeng; Long-Kai Huang; Qi CHEN; Charles Ling; Boyu Wang,~QIUHAO_Zeng1; ~Long-Kai_Huang1; ~Qi_CHEN6; ~Charles_Ling1; ~Boyu_Wang3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/1bad237b38f022e552a2d25e8441f9509ba655a2.pdf,2024-05-13T06:50:06.671000,2024-09-25T18:10:04.604000,2024-12-29T04:52:18.334000,https://openreview.net/forum?id=I2gVmVRgNk,Western University; Tencent; York University; Université Laval; Western University; Western University
2777,kQMyiDWbOG,kQMyiDWbOG,6081,Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators,"Spiking neural networks (SNNs) represent a promising approach to developing artificial neural networks that are both energy-efficient and biologically plausible.
However, applying SNNs to sequential tasks, such as text classification and time-series forecasting, has been hindered by the challenge of creating an effective and hardware-friendly spike-form positional encoding (PE) strategy.
Drawing inspiration from the central pattern generators (CPGs) in the human brain,  which produce rhythmic patterned outputs without requiring rhythmic inputs, we propose a novel PE technique for SNNs, termed CPG-PE.
We demonstrate that the commonly used sinusoidal PE is mathematically a specific solution to the membrane potential dynamics of a particular CPG.
Moreover, extensive experiments across various domains, including time-series forecasting, natural language processing, and image classification, show that SNNs with CPG-PE outperform their conventional counterparts.
Additionally, we perform analysis experiments to elucidate the mechanism through which SNNs encode positional information and to explore the function of CPGs in the human brain.
This investigation may offer valuable insights into the fundamental principles of neural computation.",Changze Lv; Dongqi Han; Yansen Wang; Xiaoqing Zheng; Xuanjing Huang; Dongsheng Li,~Changze_Lv1; ~Dongqi_Han1; ~Yansen_Wang2; ~Xiaoqing_Zheng2; ~Xuanjing_Huang1; ~Dongsheng_Li2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/493bc45a8f861549109d3a613e0bba96314e96a9.pdf,2024-05-13T06:48:36.779000,2024-09-25T18:10:04.480000,2024-11-06T06:18:10.461000,https://openreview.net/forum?id=kQMyiDWbOG,Fudan University; Microsoft; Microsoft; Fudan University; Fudan University; Microsoft
2798,gtU2eLSAmO,gtU2eLSAmO,5961,Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking,"We introduce *Brain-JEPA*, a brain dynamics foundation model with the Joint-Embedding Predictive Architecture (JEPA). This pioneering model achieves state-of-the-art performance in demographic prediction, disease diagnosis/prognosis, and trait prediction through fine-tuning. Furthermore, it excels in off-the-shelf evaluations (e.g., linear probing) and demonstrates superior generalizability across different ethnic groups, surpassing the previous large model for brain activity significantly. Brain-JEPA incorporates two innovative techniques: **Brain Gradient Positioning** and **Spatiotemporal Masking**. Brain Gradient Positioning introduces a functional coordinate system for brain functional parcellation, enhancing the positional encoding of different Regions of Interest (ROIs). Spatiotemporal Masking, tailored to the unique characteristics of fMRI data, addresses the challenge of heterogeneous time-series patches. These methodologies enhance model performance and advance our understanding of the neural circuits underlying cognition. Overall, Brain-JEPA is paving the way to address pivotal questions of building brain functional coordinate system and masking brain activity at the AI-neuroscience interface, and setting a potentially new paradigm in brain activity analysis through downstream adaptation.",Zijian Dong; Li Ruilin; Yilei Wu; Thuan Tinh Nguyen; Joanna Su Xian Chong; Fang Ji; Nathanael Ren Jie Tong; Christopher Li Hsian Chen; Juan Helen Zhou,~Zijian_Dong2; ~Li_Ruilin1; ~Yilei_Wu1; ~Thuan_Tinh_Nguyen1; ~Joanna_Su_Xian_Chong1; ~Fang_Ji1; ~Nathanael_Ren_Jie_Tong1; ~Christopher_Li_Hsian_Chen1; ~Juan_Helen_Zhou1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/241263e77aa12ff21dfce5e68c3c6dfcc8c9f3ab.pdf,2024-05-13T05:43:35.741000,2024-09-25T18:10:00.550000,2024-11-06T06:18:09.625000,https://openreview.net/forum?id=gtU2eLSAmO,National University of Singapore; Nanyang Technological University; National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore
2819,eWUM5hRYgH,eWUM5hRYgH,5847,Statistical Efficiency of Distributional Temporal Difference Learning,"Distributional reinforcement learning (DRL) has achieved empirical success in various domains.
One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$.
The distributional temporal difference learning has been accordingly proposed, which
is an extension of the temporal difference learning (TD) in the classic RL area.
In the tabular case,  Rowland et al. [2018] and Rowland et al. [2023] proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference learning (CTD) and quantile temporal difference learning (QTD), respectively.
In this paper, we go a step further and analyze the finite-sample performance of distributional TD.
To facilitate theoretical analysis, we propose a non-parametric distributional TD learning (NTD).
For a $\gamma$-discounted infinite-horizon tabular Markov decision process,
we show that for NTD we need $\widetilde O\left(\frac{1}{\varepsilon^{2p}(1-\gamma)^{2p+1}}\right)$ iterations to achieve an $\varepsilon$-optimal estimator with high probability, when the estimation error is measured by the $p$-Wasserstein distance.
This sample complexity bound is minimax optimal (up to logarithmic factors) in the case of the $1$-Wasserstein distance.
To achieve this, we establish a novel Freedman's inequality in Hilbert spaces, which would be of independent interest.
In addition, we revisit CTD, showing that the same non-asymptotic convergence bounds hold for CTD in the case of the $p$-Wasserstein distance.",Yang Peng; Liangyu Zhang; Zhihua Zhang,~Yang_Peng1; ~Liangyu_Zhang2; ~Zhihua_Zhang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/3002a75ebfe6a386efc8dee88d8a2382d1d837e1.pdf,2024-05-13T03:49:45.713000,2024-09-25T18:09:56.628000,2024-12-27T05:15:47.802000,https://openreview.net/forum?id=eWUM5hRYgH,Peking University; Peking University; Shanghai University of Finance and Economics
2844,AVd7DpiooC,AVd7DpiooC,5735,QKFormer: Hierarchical Spiking Transformer using Q-K Attention,"Spiking Transformers, which integrate Spiking Neural Networks (SNNs) with Transformer architectures, have attracted significant attention due to their potential for low energy consumption and high performance. However, there remains a substantial gap in performance between SNNs and Artificial Neural Networks (ANNs). To narrow this gap, we have developed QKFormer, a direct training spiking transformer with the following features: i) _Linear complexity and high energy efficiency_, the novel spike-form Q-K attention module efficiently models the token or channel attention through binary vectors and enables the construction of larger models. ii) _Multi-scale spiking representation_, achieved by a hierarchical structure with the different numbers of tokens across blocks. iii) _Spiking Patch Embedding with Deformed Shortcut (SPEDS)_, enhances spiking information transmission and integration, thus improving overall performance. It is shown that QKFormer achieves significantly superior performance over existing state-of-the-art SNN models on various mainstream datasets. Notably, with comparable size to Spikformer (66.34 M, 74.81\%), QKFormer (64.96 M) achieves a groundbreaking top-1 accuracy of **85.65\%** on ImageNet-1k, substantially outperforming Spikformer by **10.84\%**. To our best knowledge, this is the first time that directly training SNNs have exceeded 85\% accuracy on ImageNet-1K.",Chenlin Zhou; Han Zhang; Zhaokun Zhou; Liutao Yu; Liwei Huang; Xiaopeng Fan; Li Yuan; Zhengyu Ma; Huihui Zhou; Yonghong Tian,~Chenlin_Zhou1; ~Han_Zhang23; ~Zhaokun_Zhou1; ~Liutao_Yu1; ~Liwei_Huang1; ~Xiaopeng_Fan1; ~Li_Yuan2; ~Zhengyu_Ma1; ~Huihui_Zhou1; ~Yonghong_Tian1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/5b7b47f6c562699e4f609a598c9cd0113968c00d.pdf,2024-05-13T02:33:09.898000,2024-09-25T18:09:53.191000,2024-11-06T06:18:07.649000,https://openreview.net/forum?id=AVd7DpiooC,Peng Cheng Laboratory; Harbin Institute of Technology; Peking University; Peking University; Harbin Institute of Technology; Peking University; Peng Cheng Laboratory; Peng Cheng Laboratory; Peking University
2845,R8SolCx62K,R8SolCx62K,5733,Exploitation of a Latent Mechanism in Graph Contrastive Learning: Representation Scattering,"Graph Contrastive Learning (GCL) has emerged as a powerful approach for generating graph representations without the need for manual annotation. Most advanced GCL methods fall into three main frameworks: node discrimination, group discrimination, and bootstrapping schemes, all of which achieve comparable performance. However, the underlying mechanisms and factors that contribute to their effectiveness are not yet fully understood. In this paper, we revisit these frameworks and reveal a common mechanism—representation scattering—that significantly enhances their performance. Our discovery highlights an essential feature of GCL and unifies these seemingly disparate methods under the concept of representation scattering. To leverage this insight, we introduce Scattering Graph Representation Learning (SGRL), a novel framework that incorporates a new representation scattering mechanism designed to enhance representation diversity through a center-away strategy. Additionally, consider the interconnected nature of graphs, we develop a topology-based constraint  mechanism that integrates graph structural properties with representation scattering to prevent excessive scattering. We extensively evaluate SGRL across various downstream tasks on benchmark datasets, demonstrating its efficacy and superiority over existing GCL methods. Our findings underscore the significance of representation scattering in GCL and provide a structured framework for harnessing this mechanism to advance graph representation learning. The code of SGRL is at https://github.com/hedongxiao-tju/SGRL.",Dongxiao He; Lianze Shan; Jitao Zhao; Hengrui Zhang; Zhen Wang; Weixiong Zhang,~Dongxiao_He1; ~Lianze_Shan1; ~Jitao_Zhao2; ~Hengrui_Zhang1; ~Zhen_Wang11; ~Weixiong_Zhang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/e21a9b3822e99ccaefbd6f6562cd41ff019e09ba.pdf,2024-05-13T02:32:59.927000,2024-09-25T18:09:53.130000,2024-11-06T06:18:07.591000,https://openreview.net/forum?id=R8SolCx62K,Tianjin University of Technology; Tianjin University of Technology; Tianjin University of Technology; University of Illinois at Chicago; Northwestern Polytechnical University
2849,105ZuvpdyW,105ZuvpdyW,5700,SegVol: Universal and Interactive Volumetric Medical Image Segmentation,"Precise image segmentation provides clinical study with instructive information. Despite the remarkable progress achieved in medical image segmentation, there is still an absence of a 3D foundation segmentation model that can segment a wide range of anatomical categories with easy user interaction. In this paper, we propose a 3D foundation segmentation model, named SegVol, supporting universal and interactive volumetric medical image segmentation. By scaling up training data to 90K unlabeled Computed Tomography (CT) volumes and 6K labeled CT volumes, this foundation model supports the segmentation of over 200 anatomical categories using semantic and spatial prompts. To facilitate efficient and precise inference on volumetric images, we design a zoom-out-zoom-in mechanism. Extensive experiments on 22 anatomical segmentation tasks verify that SegVol outperforms the competitors in 19 tasks, with improvements up to 37.24\% compared to the runner-up methods. We demonstrate the effectiveness and importance of specific designs by ablation study. We expect this foundation model can promote the development of volumetric medical image analysis. The model and code are publicly available at https://github.com/BAAI-DCAI/SegVol.",Yuxin Du; Fan BAI; Tiejun Huang; Bo Zhao,~Yuxin_Du2; ~Fan_BAI4; ~Tiejun_Huang1; ~Bo_Zhao4,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_healthcare,/pdf/be1c6fd41b6a35d009d999195ed528afb6b69f1b.pdf,2024-05-13T02:07:23.337000,2024-09-25T18:09:52.028000,2024-12-23T14:00:59.413000,https://openreview.net/forum?id=105ZuvpdyW,Beijing Academy of Artificial Intelligence; Hong Kong University of Science and Technology(Guangzhou); Chinese University of Hong Kong; Huawei Technologies Research & Development (UK) Ltd; Peking University; Beijing Academy of Artificial Intelligence; Shanghai Jiao Tong University
2858,9Jmt1eER9P,9Jmt1eER9P,5661,Optimization Algorithm Design via Electric Circuits,"We present a novel methodology for convex optimization algorithm design using ideas from electric RLC circuits. Given an optimization problem, the first stage of the methodology is to design an appropriate electric circuit whose continuous-time dynamics converge to the solution of the optimization problem at hand. Then, the second stage is an automated, computer-assisted discretization of the continuous-time dynamics, yielding a provably convergent discrete-time algorithm. Our methodology recovers many classical (distributed) optimization algorithms and enables users to quickly design and explore a wide range of new algorithms with convergence guarantees.",Stephen P. Boyd; Tetiana Parshakova; Ernest K. Ryu; Jaewook J. Suh,~Stephen_P._Boyd1; ~Tetiana_Parshakova1; ~Ernest_K._Ryu1; ~Jaewook_J._Suh1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/2cf7de88420d5be599397f01a65dad5f501cd69f.pdf,2024-05-13T01:16:47.683000,2024-09-25T18:09:51.112000,2025-01-14T18:31:31.190000,https://openreview.net/forum?id=9Jmt1eER9P,"Amazon; Seoul National University; University of California, Los Angeles; Seoul National University; Rice University"
2865,zuwpeRkJNH,zuwpeRkJNH,5623,Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation,"Surgical video-language pretraining (VLP) faces unique challenges due to the knowledge domain gap and the scarcity of multi-modal data. This study aims to bridge the gap by addressing issues regarding textual information loss in surgical lecture videos and the spatial-temporal challenges of surgical VLP. To tackle these issues, we propose a hierarchical knowledge augmentation approach and a novel Procedure-Encoded Surgical Knowledge-Augmented Video-Language Pretraining (PeskaVLP) framework. The proposed knowledge augmentation approach uses large language models (LLM) to refine and enrich surgical concepts, thus providing comprehensive language supervision and reducing the risk of overfitting. The PeskaVLP framework combines language supervision with visual self-supervision, constructing hard negative samples and employing a Dynamic Time Warping (DTW) based loss function to effectively comprehend the cross-modal procedural alignment. Extensive experiments on multiple public surgical scene understanding and cross-modal retrieval datasets show that our proposed method significantly improves zero-shot transferring performance and offers a generalist visual repre- sentation for further advancements in surgical scene understanding. The source code will be available at https://github.com/CAMMA-public/PeskaVLP.",Kun yuan; Vinkle Srivastav; Nassir Navab; Nicolas Padoy,~Kun_yuan6; ~Vinkle_Srivastav1; ~Nassir_Navab1; ~Nicolas_Padoy1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_healthcare,/pdf/b754552d7cad51cf70357809a56df08d88257ab9.pdf,2024-05-12T23:52:14.793000,2024-09-25T18:09:50.116000,2024-11-06T06:18:06.652000,https://openreview.net/forum?id=zuwpeRkJNH,Technical University of Munich; Université de Strasbourg; Université de Strasbourg; Technical University of Munich; Université de Strasbourg
2879,dIktpSgK4F,dIktpSgK4F,5559,Dissecting Query-Key Interaction in Vision Transformers,"Self-attention in vision transformers is often thought to perform perceptual grouping where tokens attend to other tokens with similar embeddings, which could correspond to semantically similar features of an object. However, attending to dissimilar tokens can be beneficial by providing contextual information. We propose to analyze the query-key interaction by the singular value decomposition of the interaction matrix (i.e. ${\textbf{W}_q}^\top\textbf{W}_k$). We find that in many ViTs, especially those with classification training objectives, early layers attend more to similar tokens, while late layers show increased attention to dissimilar tokens, providing evidence corresponding to perceptual grouping and contextualization, respectively. Many of these interactions between features represented by singular vectors are interpretable and semantic, such as attention between relevant objects, between parts of an object, or between the foreground and background. This offers a novel perspective on interpreting the attention mechanism, which contributes to understanding how transformer models utilize context and salient features when processing images.",Xu Pan; Aaron Philip; Ziqian Xie; Odelia Schwartz,~Xu_Pan2; ~Aaron_Philip1; ~Ziqian_Xie1; ~Odelia_Schwartz1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/ad3ea73573f947cc727074af4a9f8fdbf5e4455a.pdf,2024-05-12T21:30:13.032000,2024-09-25T18:09:47.855000,2025-01-14T01:43:33.002000,https://openreview.net/forum?id=dIktpSgK4F,University of Miami; Harvard University
2883,lfxIASyLxB,lfxIASyLxB,5547,In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness,"A striking property of transformers is their ability to perform in-context learning (ICL), a machine learning framework in which the learner is presented with a novel context during inference implicitly through some data, and tasked with making a prediction in that context. As such, that learner must adapt to the context without additional training. We explore the role of *softmax* attention in an ICL setting where each context encodes a regression task. We show that an attention unit learns a window that it uses to implement a nearest-neighbors predictor adapted to the landscape of the pretraining tasks. Specifically, we show that this window widens with decreasing Lipschitzness and increasing label noise in the pretraining tasks. We also show that on low-rank, linear problems, the attention unit learns to project onto the appropriate subspace before inference. Further, we show that this adaptivity relies crucially on the softmax activation and thus cannot be replicated by the linear activation often studied in prior theoretical analyses.",Liam Collins; Advait U Parulekar; Aryan Mokhtari; sujay sanghavi; Sanjay Shakkottai,~Liam_Collins1; ~Advait_U_Parulekar1; ~Aryan_Mokhtari3; ~sujay_sanghavi1; ~Sanjay_Shakkottai1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/4d0a9ce81958e13f8f0b42e37c7730d17dd79463.pdf,2024-05-12T21:08:18.929000,2024-09-25T18:09:47.414000,2024-11-06T06:18:05.917000,https://openreview.net/forum?id=lfxIASyLxB,The University of Texas at Austin; Snap Inc.; The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin
2886,S4YRCLbUK1,S4YRCLbUK1,5537,Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt Coherence Metrics with T2IScoreScore (TS2),"With advances in the quality of text-to-image (T2I) models has come interest in benchmarking their prompt faithfulness---the semantic coherence of generated images to the prompts they were conditioned on. A variety of T2I faithfulness metrics have been proposed, leveraging advances in cross-modal embeddings and vision-language models (VLMs). However, these metrics are not rigorously compared and benchmarked, instead presented with correlation to human Likert scores over a set of easy-to-discriminate images against seemingly weak baselines. 

We introduce T2IScoreScore, a curated set of semantic error graphs containing a prompt and a set of increasingly erroneous images. These allow us to rigorously judge whether a given prompt faithfulness metric can correctly order images with respect to their objective error count and significantly discriminate  between different error nodes, using meta-metric scores derived from established statistical tests. Surprisingly, we find that the state-of-the-art VLM-based metrics (e.g., TIFA, DSG, LLMScore, VIEScore) we tested fail to significantly outperform simple (and supposedly worse) feature-based metrics like CLIPScore, particularly on a hard subset of naturally-occurring T2I model errors. TS2 will enable the development of better T2I prompt faithfulness metrics through more rigorous comparison of their conformity to expected orderings and separations under objective criteria.",Michael Saxon; Fatima Jahara; Mahsa Khoshnoodi; Yujie Lu; Aditya Sharma; William Yang Wang,~Michael_Saxon1; ~Fatima_Jahara1; ~Mahsa_Khoshnoodi1; ~Yujie_Lu1; ~Aditya_Sharma3; ~William_Yang_Wang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,evaluation,/pdf/a66fbcdc022a25f214f22e630fac504dc4b80efd.pdf,2024-05-12T20:51:04.512000,2024-09-25T18:09:47.140000,2024-11-06T06:18:05.806000,https://openreview.net/forum?id=S4YRCLbUK1,"University of California, Santa Barbara; Advanced Micro Devices; Fatima Fellowship; Workera.ai; Rutgers University; Fatima Fellowship; University of California, Santa Barbara; University of California, Santa Barbara; Google; University of California, Santa Barbara"
2887,7sdkLVuYCU,7sdkLVuYCU,5532,QTIP: Quantization with Trellises and Incoherence Processing,"Post-training quantization (PTQ) reduces the memory footprint of LLMs by quantizing weights to low-precision datatypes.
Since LLM inference is usually memory-bound, PTQ methods can improve inference throughput.
Recent state-of-the-art PTQ approaches use vector quantization (VQ) to quantize multiple weights at once, which improves information utilization through better shaping.
However, VQ requires a codebook with size exponential in the dimension.
This limits current VQ-based PTQ works to low VQ dimensions ($\le 8$) that in turn limit quantization quality.
Here, we introduce QTIP, which instead uses trellis coded quantization (TCQ) to achieve ultra-high-dimensional quantization. 
TCQ uses a stateful decoder that separates the codebook size from the bitrate and effective dimension. 
QTIP introduces a spectrum of lookup-only to computed lookup-free trellis codes designed for a hardware-efficient ""bitshift"" trellis structure; these codes achieve state-of-the-art results in both quantization quality and inference speed.",Albert Tseng; Qingyao Sun; David Hou; Christopher De Sa,~Albert_Tseng1; ~Qingyao_Sun1; ~David_Hou2; ~Christopher_De_Sa2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/38b6702730caf063684e5a0cd860918f99833335.pdf,2024-05-12T20:40:47.117000,2024-09-25T18:09:47.013000,2024-11-06T06:18:05.719000,https://openreview.net/forum?id=7sdkLVuYCU,Cornell University; Together AI; Cornell University
2894,YlmYm7sHDE,YlmYm7sHDE,5520,Minimum Entropy Coupling with Bottleneck,"This paper investigates a novel lossy compression framework operating under logarithmic loss, designed to handle situations where the reconstruction distribution diverges from the source distribution. This framework is especially relevant for applications that require joint compression and retrieval, and in scenarios involving distributional shifts due to processing. We show that the proposed formulation extends the classical minimum entropy coupling framework by integrating a bottleneck, allowing for controlled variability in the degree of stochasticity in the coupling.
We explore the decomposition of the Minimum Entropy Coupling with Bottleneck (MEC-B) into two distinct optimization problems: Entropy-Bounded Information Maximization (EBIM) for the encoder, and Minimum Entropy Coupling (MEC) for the decoder. Through extensive analysis, we provide a greedy algorithm for EBIM with guaranteed performance, and characterize the optimal solution near functional mappings, yielding significant theoretical insights into the structural complexity of this problem.
Furthermore, we illustrated the practical application of MEC-B through experiments in Markov Coding Games (MCGs) under rate limits. These games simulate a communication scenario within a Markov Decision Process, where an agent must transmit a compressed message from a sender to a receiver through its actions. Our experiments highlighted the trade-offs between MDP rewards and receiver accuracy across various compression rates, showcasing the efficacy of our method compared to conventional compression baseline.",MohammadReza Ebrahimi; Jun Chen; Ashish J Khisti,~MohammadReza_Ebrahimi1; ~Jun_Chen8; ~Ashish_J_Khisti1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/27cb641bf8ba5e9d57f036039eae25c7e0507769.pdf,2024-05-12T20:25:00.189000,2024-09-25T18:09:46.521000,2024-11-06T06:18:05.443000,https://openreview.net/forum?id=YlmYm7sHDE,Qualcomm AI Research; University of Toronto; McMaster University; University of Toronto
2907,3s8V8QP9XV,3s8V8QP9XV,5477,Nearly Optimal Approximation of Matrix Functions by the Lanczos Method,"Approximating the action of a matrix function $f(\vec{A})$ on a vector $\vec{b}$ is an increasingly important primitive in machine learning, data science, and statistics, with applications such as sampling high dimensional Gaussians, Gaussian process regression and Bayesian inference, principle component analysis, and approximating Hessian spectral densities.
Over the past decade, a number of algorithms enjoying strong theoretical guarantees have been proposed for this task.
Many of the most successful belong to a family of algorithms called Krylov subspace methods.
Remarkably, a classic Krylov subspace method, called the Lanczos method for matrix functions (Lanczos-FA), frequently outperforms newer methods in practice. Our main result is a theoretical justification for this finding: we show that, for a natural class of rational functions, Lanczos-FA matches the error of the best possible Krylov subspace method up to a multiplicative approximation factor. 
The approximation factor depends on the degree of $f(x)$'s denominator and the condition number of $\vec{A}$, but not on the number of iterations $k$. Our result provides a strong justification for the excellent performance of Lanczos-FA, especially on functions that are well approximated by rationals, such as the matrix square root.",Noah Amsel; Tyler Chen; Anne Greenbaum; Cameron N Musco; Christopher Musco,~Noah_Amsel1; ~Tyler_Chen1; ~Anne_Greenbaum1; ~Cameron_N_Musco1; ~Christopher_Musco1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/097297b1fc6191ebb6ebb74267736cfa244efa2f.pdf,2024-05-12T18:12:48.128000,2024-09-25T18:09:44.854000,2024-11-06T06:18:04.888000,https://openreview.net/forum?id=3s8V8QP9XV,New York University; University of Massachusetts Amherst; New York University
2917,EK1tyHcb3W,EK1tyHcb3W,5429,Sample Complexity of Posted Pricing for a Single Item,"Selling a single item to $n$ self-interested bidders is a fundamental problem in economics, where the two  objectives  typically considered are welfare maximization and revenue maximization.   Since the optimal auctions are often impractical and do not work for sequential bidders, posted pricing auctions, where fixed prices are set for the item for different bidders, have emerged as a practical and effective alternative. This paper investigates how many samples are needed from bidders' value distributions to find near-optimal posted prices, considering both independent and correlated bidder distributions, and welfare versus revenue maximization.  We obtain matching upper and lower bounds (up to logarithmic terms) on the sample complexity for all these settings.",Billy Jin; Thomas Kesselheim; Will Ma; Sahil Singla,~Billy_Jin1; ~Thomas_Kesselheim1; ~Will_Ma1; ~Sahil_Singla3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/c6e10d932dfb767f83da8360d11716d8e26de1f5.pdf,2024-05-12T16:30:02.260000,2024-09-25T18:09:43.429000,2024-11-06T06:18:04.496000,https://openreview.net/forum?id=EK1tyHcb3W,Cornell University; University of Chicago; University of Bonn; Georgia Institute of Technology
2926,25Ioxw576r,25Ioxw576r,5374,You Only Cache Once: Decoder-Decoder Architectures for Language Models,"We introduce a decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once. It consists of two components, i.e., a cross-decoder stacked upon a self-decoder. The self-decoder efficiently encodes global key-value (KV) caches that are reused by the cross-decoder via cross-attention. The overall model behaves like a decoder-only Transformer, although YOCO only caches once. The design substantially reduces GPU memory demands, yet retains global attention capability. Additionally, the computation flow enables prefilling to early exit without changing the final output, thereby significantly speeding up the prefill stage. Experimental results demonstrate that YOCO achieves favorable performance compared to Transformer in various settings of scaling up model size and number of training tokens. We also extend YOCO to 1M context length with near-perfect needle retrieval accuracy. The profiling results show that YOCO improves inference memory, prefill latency, and throughput by orders of magnitude across context lengths and model sizes.",Yutao Sun; Li Dong; Yi Zhu; Shaohan Huang; Wenhui Wang; Shuming Ma; Quanlu Zhang; Jianyong Wang; Furu Wei,~Yutao_Sun1; ~Li_Dong1; ~Yi_Zhu8; ~Shaohan_Huang1; ~Wenhui_Wang1; ~Shuming_Ma1; ~Quanlu_Zhang1; ~Jianyong_Wang2; ~Furu_Wei1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/c001fdfd3a2894f8c62da3eef3be8317b3800c61.pdf,2024-05-12T15:06:41.149000,2024-09-25T18:09:41.806000,2024-11-06T06:18:04.153000,https://openreview.net/forum?id=25Ioxw576r,"Tsinghua University, Beijing; Microsoft; Microsoft; Microsoft; Microsoft; Microsoft; Tsinghua University, Beijing; Microsoft"
2941,cFqAANINgW,cFqAANINgW,5273,Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation,"Despite recent progress made by large language models in code generation, they still struggle with programs that meet complex requirements. Recent work utilizes plan-and-solve decomposition to decrease the complexity and leverage self-tests to refine the generated program. Yet, planning deep-inside requirements in advance can be challenging, and the tests need to be accurate to accomplish self-improvement. To this end, we propose FunCoder, a code generation framework incorporating the divide-and-conquer strategy with functional consensus. Specifically, FunCoder recursively branches off sub-functions as smaller goals during code generation, represented by a tree hierarchy. These sub-functions are then composited to attain more complex objectives. Additionally, we designate functions via a consensus formed by identifying similarities in program behavior, mitigating error propagation. FunCoder outperforms state-of-the-art methods by +9.8% on average in HumanEval, MBPP, xCodeEval and MATH with GPT-3.5 and GPT-4. Moreover, our method demonstrates superiority on smaller models: With FunCoder, StableCode-3b surpasses GPT-3.5 by +18.6% and achieves 97.7% of GPT-4's performance on HumanEval. Further analysis reveals that our proposed dynamic function decomposition is capable of handling complex requirements, and the functional consensus prevails over self-testing in correctness evaluation.",Jingchang Chen; Hongxuan Tang; Zheng Chu; Qianglong Chen; Zekun Wang; Ming Liu; Bing Qin,~Jingchang_Chen1; ~Hongxuan_Tang2; ~Zheng_Chu1; ~Qianglong_Chen1; ~Zekun_Wang1; ~Ming_Liu6; ~Bing_Qin2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/3e5f8faab4f950de11084efdc7ef0ade167c4af9.pdf,2024-05-12T13:18:18.959000,2024-09-25T18:09:38.619000,2025-01-15T11:35:12.135000,https://openreview.net/forum?id=cFqAANINgW,Harbin Institute of Technology; Microsoft; Harbin Institute of Technology; Huawei Technologies Research & Development (UK) Ltd; Harbin Institute of Technology; Harbin Institute of Technology; Harbin Institute of Technology
2942,mp8u2Pcmqz,mp8u2Pcmqz,5272,DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs,"Quantization of large language models (LLMs) faces significant challenges, particularly due to the presence of outlier activations that impede efficient low-bit representation. Traditional approaches predominantly address Normal Outliers, which are activations across all tokens with relatively large magnitudes. However, these methods struggle with smoothing Massive Outliers that display significantly larger values, which leads to significant performance degradation in low-bit quantization. In this paper, we introduce DuQuant, a novel approach that utilizes rotation and permutation transformations to more effectively mitigate both massive and normal outliers. First, DuQuant starts by constructing the rotation matrix, using specific outlier dimensions as prior knowledge, to redistribute outliers to adjacent channels by block-wise rotation. Second, We further employ a zigzag permutation to balance the distribution of outliers across blocks, thereby reducing block-wise variance. A subsequent rotation further smooths the activation landscape, enhancing model performance. DuQuant simplifies the quantization process and excels in managing outliers, outperforming the state-of-the-art baselines across various sizes and types of LLMs on multiple tasks, even with 4-bit weight-activation quantization. Our code is available at https://github.com/Hsu1023/DuQuant.",Haokun Lin; Haobo Xu; Yichen Wu; Jingzhi Cui; Yingtao Zhang; Linzhan Mou; Linqi Song; Zhenan Sun; Ying Wei,~Haokun_Lin4; ~Haobo_Xu2; ~Yichen_Wu2; ~Jingzhi_Cui1; ~Yingtao_Zhang3; ~Linzhan_Mou1; ~Linqi_Song1; ~Zhenan_Sun1; ~Ying_Wei1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/f75c5ce9e83cea209b9b5807072a3537bac72822.pdf,2024-05-12T13:17:43.927000,2024-09-25T18:09:38.573000,2025-01-14T16:23:28.817000,https://openreview.net/forum?id=mp8u2Pcmqz,"University of Chinese Academy of Sciences; City University of Hong Kong; Tsinghua University, Beijing; Harvard University; City University of Hong Kong; Tsinghua University, Beijing; Tsinghua University, Beijing; Zhejiang University; City University of Hong Kong; University of Chinese Academy of Sciences; Zhejiang University; Nanyang Technological University"
2954,8aA3DHLK5h,8aA3DHLK5h,5213,Extensive-Form Game Solving via Blackwell Approachability on Treeplexes,"We introduce the first algorithmic framework for Blackwell approachability on the sequence-form polytope, the class of convex polytopes capturing the strategies of players in extensive-form games (EFGs).
This leads to a new class of regret-minimization algorithms that are stepsize-invariant, in the same sense as the Regret Matching and Regret Matching$^+$ algorithms for the simplex.
Our modular framework can be combined with any existing regret minimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs with perfect recall, through the self-play framework. Leveraging predictive online mirror descent, we introduce *Predictive Treeplex Blackwell$^+$* (PTB$^+$), and show a $O(1/\sqrt{T})$ convergence rate to Nash equilibrium in self-play. We then show how to stabilize PTB$^+$ with a stepsize, resulting in an algorithm with a state-of-the-art $O(1/T)$ convergence rate. 
We provide an extensive set of experiments to compare our framework with several algorithmic benchmarks, including CFR$^+$ and its predictive variant, and we highlight interesting connections between practical performance and the stepsize-dependence or stepsize-invariance properties of classical algorithms.",Darshan Chakrabarti; Julien Grand-Clément; Christian Kroer,~Darshan_Chakrabarti1; ~Julien_Grand-Clément1; ~Christian_Kroer1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/df42beac9e6141101c00c68dafab3a0648264998.pdf,2024-05-12T11:58:49.330000,2024-09-25T18:09:37.112000,2024-11-06T06:18:02.914000,https://openreview.net/forum?id=8aA3DHLK5h,Columbia University; Columbia University
2956,0NMzBwqaAJ,0NMzBwqaAJ,5208,Not All Tokens Are What You Need for Pretraining,"Previous language model pre-training methods have uniformly applied a next-token prediction loss to all training tokens. Challenging this norm, we posit that ''Not all tokens in a corpus are equally important for language model training''. Our initial analysis examines token-level training dynamics of language model, revealing distinct loss patterns for different tokens. Leveraging these insights, we introduce a new language model called Rho-1. Unlike traditional LMs that learn to predict every next token in a corpus, Rho-1 employs Selective Language Modeling (SLM), which selectively trains on useful tokens that aligned with the desired distribution. This approach involves scoring training tokens using a reference model, and then training the language model with a focused loss on tokens with higher scores. When continual continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute improvement in few-shot accuracy of up to 30% in 9 math tasks. After fine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and 51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the pretraining tokens. Furthermore, when continual pretraining on 80B general tokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks, increasing both data efficiency and performance of the language model pre-training.",Zhenghao Lin; Zhibin Gou; Yeyun Gong; Xiao Liu; yelong shen; Ruochen Xu; Chen Lin; Yujiu Yang; Jian Jiao; Nan Duan; Weizhu Chen,~Zhenghao_Lin1; ~Zhibin_Gou1; ~Yeyun_Gong2; ~Xiao_Liu14; ~yelong_shen1; ~Ruochen_Xu2; ~Chen_Lin5; ~Yujiu_Yang2; ~Jian_Jiao2; ~Nan_Duan1; ~Weizhu_Chen1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/322b6309b2e8e9565af8f7bd497dae2d47861bc5.pdf,2024-05-12T11:51:38.411000,2024-09-25T18:09:36.903000,2025-01-08T09:30:53.148000,https://openreview.net/forum?id=0NMzBwqaAJ,"Xiamen University; Microsoft; Microsoft; Microsoft; Microsoft; 01.AI; Microsoft; Xiamen University; Tsinghua University, Beijing; Microsoft; Stepfun; Microsoft; Microsoft"
2960,rhCgizNupi,rhCgizNupi,5179,Reranking Laws for Language Generation: A Communication-Theoretic Perspective,"To ensure large language models (LLMs) are used safely, one must reduce their propensity to hallucinate or to generate unacceptable answers. A simple and often used strategy is to first let the LLM generate multiple hypotheses and then employ a reranker to choose the best one. In this paper, we draw a parallel between this strategy and the use of redundancy to decrease the error rate in noisy communication channels. We conceptualize the generator as a sender transmitting multiple descriptions of a message through parallel noisy channels. The receiver decodes the message by ranking the (potentially corrupted) descriptions and selecting the one found to be most reliable. We provide conditions under which this protocol is asymptotically error-free (i.e., yields an acceptable answer almost surely) even in scenarios where the reranker is imperfect (governed by Mallows or Zipf-Mandelbrot models) and the channel distributions are statistically dependent. We use our framework to obtain reranking laws which we validate empirically on two real-world tasks using LLMs: text-to-code generation with DeepSeek-Coder 7B and machine translation of medical data with TowerInstruct 13B.",António Farinhas; Haau-Sing Li; Andre Martins,~António_Farinhas1; ~Haau-Sing_Li1; ~Andre_Martins1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/1d824c959b9a0a08e7614ea8420a49d8b2d56b9c.pdf,2024-05-12T10:41:29.696000,2024-09-25T18:09:36.061000,2024-11-06T06:18:02.678000,https://openreview.net/forum?id=rhCgizNupi,"Instituto de Telecomunicações, Portugal; ELLIS Institute, Tübingen; Technical University of Darmstadt; Unbabel; Instituto Superior Técnico"
2967,6ZBHIEtdP4,6ZBHIEtdP4,5120,PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models,"To parameter-efficiently fine-tune (PEFT) large language models (LLMs), the low-rank adaptation (LoRA) method approximates the model changes $\Delta W \in \mathbb{R}^{m \times n}$ through the product of two matrices $A \in \mathbb{R}^{m \times r}$ and $B \in \mathbb{R}^{r \times n}$, where $r \ll \min(m, n)$, $A$ is initialized with Gaussian noise, and $B$ with zeros. LoRA **freezes the original model $W$** and **updates the ""Noise \& Zero"" adapter**, which may lead to slow convergence. To overcome this limitation, we introduce **P**r**i**ncipal **S**ingular values and **S**ingular vectors **A**daptation (PiSSA). PiSSA shares the same architecture as LoRA, but initializes the adaptor matrices $A$ and $B$ with the principal components of the original matrix $W$, and put the remaining components into a residual matrix $W^{res} \in \mathbb{R}^{m \times n}$ which is frozen during fine-tuning.
Compared to LoRA, PiSSA **updates the principal components** while **freezing the ""residual"" parts**, allowing faster convergence and enhanced performance. Comparative experiments of PiSSA and LoRA across 11 different models, ranging from 184M to 70B, encompassing 5 NLG and 8 NLU tasks, reveal that PiSSA consistently outperforms LoRA under identical experimental setups. On the GSM8K benchmark, Gemma-7B fine-tuned with PiSSA achieves an accuracy of 77.7\%, surpassing LoRA's 74.53\% by 3.25\%. Due to the same architecture, PiSSA is also compatible with quantization to further reduce the memory requirement of fine-tuning. Compared to QLoRA, QPiSSA (PiSSA with 4-bit quantization) exhibits smaller quantization errors in the initial stages. Fine-tuning LLaMA-3-70B on GSM8K, QPiSSA attains an accuracy of 86.05\%, exceeding the performances of QLoRA at 81.73\%. Leveraging a fast SVD technique, PiSSA can be initialized in only a few seconds, presenting a negligible cost for transitioning from LoRA to PiSSA.",Fanxu Meng; Zhaohui Wang; Muhan Zhang,~Fanxu_Meng1; ~Zhaohui_Wang2; ~Muhan_Zhang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/a9ffb96fadbc12583951c22e68a1611536eaf521.pdf,2024-05-12T09:04:34.055000,2024-09-25T18:09:34.413000,2024-11-06T06:18:02.410000,https://openreview.net/forum?id=6ZBHIEtdP4,Peking University; Tencent; University of Chinese Academy of Sciences; Peking University
2969,NGuGVT7ar2,NGuGVT7ar2,5110,Enhancing LLM Reasoning via Vision-Augmented Prompting,"Verbal and visual-spatial information processing are two critical subsystems that activate different brain regions and often collaborate together for cognitive reasoning. Despite the rapid advancement of LLM-based reasoning, the mainstream frameworks, such as Chain-of-Thought (CoT) and its variants, primarily focus on the verbal dimension, resulting in limitations in tackling reasoning problems with visual and spatial clues. To bridge the gap, we propose a novel dual-modality reasoning framework called Vision-Augmented Prompting (VAP). Upon receiving a textual problem description, VAP automatically synthesizes an image from the visual and spatial clues by utilizing external drawing tools. Subsequently, VAP formulates a chain of thought in both modalities and iteratively refines the synthesized image. Finally, a conclusive reasoning scheme based on self-alignment is proposed for final result generation. Extensive experiments are conducted across four versatile tasks, including solving geometry problems, Sudoku, time series prediction, and travelling salesman problem. The results validated the superiority of VAP over existing LLMs-based reasoning frameworks.",Ziyang Xiao; Dongxiang Zhang; Xiongwei Han; Xiaojin Fu; Wing Yin YU; Tao Zhong; Sai Wu; Yuan Jessica Wang; Jianwei Yin; Gang Chen,~Ziyang_Xiao2; ~Dongxiang_Zhang2; ~Xiongwei_Han1; ~Xiaojin_Fu1; ~Wing_Yin_YU1; ~Tao_Zhong2; ~Sai_Wu2; ~Yuan_Jessica_Wang1; ~Jianwei_Yin1; ~Gang_Chen6,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/e5b33b51f40c74900516f4e0bd0f6074a89de4a2.pdf,2024-05-12T08:53:47.093000,2024-09-25T18:09:33.997000,2024-12-19T03:35:37.410000,https://openreview.net/forum?id=NGuGVT7ar2,Zhejiang University; Huawei Technologies Research & Development (UK) Ltd; Huawei Technologies Research & Development (UK) Ltd; Huawei Technologies Research & Development (UK) Ltd; Zhejiang University; Zhejiang University; Zhejiang Sci-Tech University
2978,M8dy0ZuSb1,M8dy0ZuSb1,5074,Improving robustness to corruptions with multiplicative weight perturbations,"Deep neural networks (DNNs) excel on clean images but struggle with corrupted ones. Incorporating specific corruptions into the data augmentation pipeline can improve robustness to those corruptions but may harm performance on clean images and other types of distortion. In this paper, we introduce an alternative approach that improves the robustness of DNNs to a wide range of corruptions without compromising accuracy on clean images. We first demonstrate that input perturbations can be mimicked by multiplicative perturbations in the weight space. Leveraging this, we propose Data Augmentation via Multiplicative Perturbation (DAMP), a training method that optimizes DNNs under random multiplicative weight perturbations. We also examine the recently proposed Adaptive Sharpness-Aware Minimization (ASAM) and show that it optimizes DNNs under adversarial multiplicative weight perturbations. Experiments on image classification datasets (CIFAR-10/100, TinyImageNet and ImageNet) and neural network architectures (ResNet50, ViT-S/16, ViT-B/16) show that DAMP enhances model generalization performance in the presence of corruptions across different settings. Notably, DAMP is able to train a ViT-S/16 on ImageNet from scratch, reaching the top-1 error of 23.7% which is comparable to ResNet50 without extensive data augmentations.",Trung Trinh; Markus Heinonen; Luigi Acerbi; Samuel Kaski,~Trung_Trinh1; ~Markus_Heinonen1; ~Luigi_Acerbi1; ~Samuel_Kaski1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/cd357863b16fdaa3cf6a01d9517ccb415b187402.pdf,2024-05-12T08:09:52.458000,2024-09-25T18:09:32.842000,2024-12-24T10:16:36.303000,https://openreview.net/forum?id=M8dy0ZuSb1,Aalto University; Aalto University; University of Helsinki; Helsinki Institute for Information Technology; Aalto University; University of Manchester
3002,FGTDe6EA0B,FGTDe6EA0B,4978,Language Generation in the Limit,"Although current large language models are complex, the most basic specifications of the underlying language generation problem itself are simple to state: given a finite set of training samples from an unknown language, produce valid new strings from the language that don't already appear in the training data. Here we ask what we can conclude about language generation using only this specification, without further assumptions. In particular, suppose that an adversary enumerates the strings of an unknown target language L that is known only to come from one of a possibly infinite list of candidates. A computational agent is trying to learn to generate from this language; we say that the agent generates from $L$ in the limit if after some finite point in the enumeration of $L$, the agent is able to produce new elements that come exclusively from $L$ and that have not yet been presented by the adversary. Our main result is that there is an agent that is able to generate in the limit for every countable list of candidate languages. This contrasts dramatically with negative results due to Gold and Angluin in a well-studied model of language learning where the goal is to identify an unknown language from samples; the difference between these results suggests that identifying a language is a fundamentally different problem than generating from it.",Jon Kleinberg; Sendhil Mullainathan,~Jon_Kleinberg3; ~Sendhil_Mullainathan2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/9b6d3b0766755bf0260924f8028eb512c04846ec.pdf,2024-05-12T05:28:23.687000,2024-09-25T18:09:26.533000,2024-11-06T06:18:00.783000,https://openreview.net/forum?id=FGTDe6EA0B,University of Chicago
3004,mZwilh3hd2,mZwilh3hd2,4969,Polynomial-Time Computation of Exact $\Phi$-Equilibria in Polyhedral Games,"It is a well-known fact that correlated equilibria can be computed in polynomial time in a large class of concisely represented games using the celebrated Ellipsoid Against Hope algorithm \citep{Papadimitriou2008:Computing, Jiang2015:Polynomial}. However, the landscape of efficiently computable equilibria in sequential (extensive-form) games remains unknown. The Ellipsoid Against Hope does not apply directly to these games, because they do not have the required ``polynomial type'' property. Despite this barrier, \citet{Huang2008:Computing} altered the algorithm to compute exact extensive-form correlated equilibria.

In this paper, we generalize the Ellipsoid Against Hope and develop a simple algorithmic framework for efficiently computing saddle-points in bilinear zero-sum games, even when one of the dimensions is exponentially large. Moreover, the framework only requires a ``good-enough-response'' oracle, which is a weakened notion of a best-response oracle.

Using this machinery, we develop a general algorithmic framework for computing exact linear $\Phi$-equilibria in any polyhedral game (under mild assumptions), including correlated equilibria in normal-form games, and extensive-form correlated equilibria in extensive-form games. This enables us to give the first polynomial-time algorithm for computing exact linear-deviation correlated equilibria in extensive-form games, thus resolving an open question by \citet{Farina2023:Polynomial}. Furthermore, even for the cases for which a polynomial time algorithm for exact equilibria was already known, our framework provides a conceptually simpler solution.",Gabriele Farina; Charilaos Pipis,~Gabriele_Farina1; ~Charilaos_Pipis1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/6a58ad8a87873801cdd3838c48d1d9959c0a228b.pdf,2024-05-12T05:14:13.821000,2024-09-25T18:09:26.327000,2024-11-06T06:18:00.723000,https://openreview.net/forum?id=mZwilh3hd2,Massachusetts Institute of Technology
3008,ANO1i9JPtb,ANO1i9JPtb,4955,Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models,"We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs). Specifically, we propose meta-buffer to store a series of informative high-level thoughts, namely thought-template, distilled from the problem-solving processes across various tasks. Then for each problem, we retrieve a relevant thought-template and adaptively instantiate it with specific reasoning structures to conduct efficient reasoning. To guarantee the scalability and stability, we further propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved. We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and achieve significant performance improvements over previous SOTA methods: 11\% on Game of 24, 20\% on Geometric Shapes and 51\% on Checkmate-in-One. Further analysis demonstrate the superior generalization ability and model robustness of our BoT, while requiring only 12\% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average. Code is available at: https://github.com/YangLing0818/buffer-of-thought-llm",Ling Yang; Zhaochen Yu; Tianjun Zhang; Shiyi Cao; Minkai Xu; Wentao Zhang; Joseph E. Gonzalez; Bin CUI,~Ling_Yang1; ~Zhaochen_Yu2; ~Tianjun_Zhang1; ~Shiyi_Cao1; ~Minkai_Xu1; ~Wentao_Zhang1; ~Joseph_E._Gonzalez1; ~Bin_CUI2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/1e9bd50c1379b65b4fe08ae09759cd95b6408b8c.pdf,2024-05-12T04:53:19.628000,2024-09-25T18:09:25.859000,2024-11-06T06:18:00.567000,https://openreview.net/forum?id=ANO1i9JPtb,"Peking University; Princeton University; Peking University; University of California, Berkeley; University of California, Berkeley; Stanford University; Peking University; University of California, Berkeley; Peking University"
3024,F8aSOovlEP,F8aSOovlEP,4887,MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning,"Video causal reasoning aims to achieve a high-level understanding of video content from a causal perspective. However, current video reasoning tasks are limited in scope, primarily executed in a question-answering paradigm and focusing on short videos containing only a single event and simple causal relationships, lacking comprehensive and structured causality analysis for videos with multiple events. To fill this gap, we introduce a new task and dataset, Multi-Event Causal Discovery (MECD). It aims to uncover the causal relationships between events distributed chronologically across long videos. Given visual segments and textual descriptions of events, MECD requires identifying the causal associations between these events to derive a comprehensive, structured event-level video causal diagram explaining why and how the final result event occurred. To address MECD, we devise a novel framework inspired by the Granger Causality method, using an efficient mask-based event prediction model to perform an Event Granger Test, which estimates causality by comparing the predicted result event when premise events are masked versus unmasked. Furthermore, we integrate causal inference techniques such as front-door adjustment and counterfactual inference to address challenges in MECD like causality confounding and illusory causality. Experiments validate the effectiveness of our framework in providing causal relationships in multi-event videos, outperforming GPT-4o and VideoLLaVA by 5.7% and 4.1%, respectively.",Tieyuan Chen; Huabin Liu; Tianyao He; Yihang Chen; Chaofan Gan; Xiao Ma; Cheng Zhong; Yang Zhang; Yingxue Wang; Hui Lin; Weiyao Lin,~Tieyuan_Chen1; ~Huabin_Liu1; ~Tianyao_He1; ~Yihang_Chen2; ~Chaofan_Gan1; ~Xiao_Ma11; ~Cheng_Zhong5; ~Yang_Zhang23; ~Yingxue_Wang2; ~Hui_Lin7; ~Weiyao_Lin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/d7e11b7d203a8b48880739fdf28f8bf16f08e095.pdf,2024-05-12T02:23:20.859000,2024-09-25T18:09:23.916000,2024-12-27T02:17:21.073000,https://openreview.net/forum?id=F8aSOovlEP,"Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Monash University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; lenovo group; lenovo group; Lenovo Research, AI Lab; China electronics technology design and research institute; Shanghai Jiao Tong University"
3025,Kl13lipxTW,Kl13lipxTW,4885,BackTime: Backdoor Attacks on Multivariate Time Series Forecasting,"Multivariate Time Series (MTS) forecasting is a fundamental task with numerous real-world applications, such as transportation, climate, and epidemiology. While a myriad of powerful deep learning models have been developed for this task, few works have explored the robustness of MTS forecasting models to malicious attacks, which is crucial for their trustworthy employment in high-stake scenarios. To address this gap, we dive deep into the backdoor attacks on MTS forecasting models and propose an effective attack method named BackTime. By subtly injecting a few \textit{stealthy triggers} into the MTS data, BackTime can alter the predictions of the forecasting model according to the attacker's intent. Specifically, BackTime first identifies vulnerable timestamps in the data for poisoning, and then adaptively synthesizes stealthy and effective triggers by solving a bi-level optimization problem with a GNN-based trigger generator. Extensive experiments across multiple datasets and state-of-the-art MTS forecasting models demonstrate the effectiveness, versatility, and stealthiness of BackTime attacks.",Xiao Lin; Zhining Liu; Dongqi Fu; Ruizhong Qiu; Hanghang Tong,~Xiao_Lin8; ~Zhining_Liu1; ~Dongqi_Fu1; ~Ruizhong_Qiu1; ~Hanghang_Tong3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/1fa47bbd3756afb005487f49b0c6a1d97cef5555.pdf,2024-05-12T02:11:35.553000,2024-09-25T18:09:23.859000,2024-12-31T02:03:11.116000,https://openreview.net/forum?id=Kl13lipxTW,"Department of Computer Science, University of Illinois at Urbana Champaign; Department of Computer Science, University of Illinois at Urbana Champaign; Meta; Department of Computer Science, University of Illinois at Urbana Champaign; Department of Computer Science, University of Illinois at Urbana Champaign; Department of Computer Science, University of Illinois at Urbana Champaign"
3033,ge8GZn8Gtu,ge8GZn8Gtu,4838,Achieving Optimal Clustering in Gaussian Mixture Models with Anisotropic Covariance Structures,"We study clustering under anisotropic Gaussian Mixture Models (GMMs), where covariance matrices from different clusters are unknown and are not necessarily the identity matrix. We analyze two anisotropic scenarios: homogeneous, with identical covariance matrices, and heterogeneous, with distinct matrices per cluster. For these models, we derive minimax lower bounds that illustrate the critical influence of covariance structures on clustering accuracy. To solve the clustering problem, we consider a variant of Lloyd's algorithm, adapted to estimate and utilize covariance information iteratively. We prove that the adjusted algorithm not only achieves the minimax optimality but also converges within a logarithmic number of iterations, thus bridging the gap between theoretical guarantees and practical efficiency.",Xin Chen; Anderson Ye Zhang,~Xin_Chen29; ~Anderson_Ye_Zhang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,learning_theory,/pdf/43a0e0281aa6e1dcadbd067c201ceb2c07c5bf4c.pdf,2024-05-11T22:42:30.778000,2024-09-25T18:09:22.534000,2024-11-06T06:17:59.521000,https://openreview.net/forum?id=ge8GZn8Gtu,
3035,vBlzen37i0,vBlzen37i0,4819,Optimal deep learning of holomorphic operators between Banach spaces,"Operator learning problems arise in many key areas of scientific computing where Partial Differential Equations (PDEs) are used to model physical systems. In such scenarios, the operators map between Banach or Hilbert spaces. In this work, we tackle the problem of learning operators between Banach spaces, in contrast to the vast majority of past works considering only Hilbert spaces. We focus on learning holomorphic operators -- an important class of problems with many applications. We combine arbitrary approximate encoders and decoders with standard feedforward Deep Neural Network (DNN) architectures -- specifically, those with constant width exceeding the depth -- under standard $\ell^2$-loss minimization. We first identify a family of  DNNs such that the resulting Deep Learning (DL) procedure achieves optimal generalization bounds for such operators. For standard fully-connected architectures, we then show that there are uncountably many minimizers of the training problem that yield equivalent optimal performance. The DNN architectures we consider are `problem agnostic', with width and depth only depending on the amount of training data $m$ and not on regularity assumptions of the target operator. Next, we show that DL is optimal for this problem: no recovery procedure can surpass these generalization bounds up to log terms. Finally, we present numerical results demonstrating the practical performance on challenging problems including the parametric diffusion, Navier-Stokes-Brinkman and Boussinesq PDEs.",Ben Adcock; Nick Dexter; Sebastian Moraga,~Ben_Adcock1; ~Nick_Dexter1; ~Sebastian_Moraga1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/9cb30e6da1adb9a507589be6884af286e65e2967.pdf,2024-05-11T21:46:25.577000,2024-09-25T18:09:21.911000,2024-11-06T06:17:59.461000,https://openreview.net/forum?id=vBlzen37i0,Simon Fraser University
3038,aVSxwicpAk,aVSxwicpAk,4802,4+3 Phases of Compute-Optimal Neural Scaling Laws,"We consider the solvable neural scaling model with three parameters: data complexity, target complexity, and model-parameter-count. We use this neural scaling model to derive new predictions about the compute-limited, infinite-data scaling law regime.  To train the neural scaling model, we run one-pass stochastic gradient descent on a mean-squared loss.  We derive a representation of the loss curves which holds over all iteration counts and improves in accuracy as the model parameter count grows.  We then analyze the compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in the data-complexity/target-complexity phase-plane.  The phase boundaries are determined by the relative importance of model capacity, optimizer noise, and embedding of the features. We furthermore derive, with mathematical proof and extensive numerical evidence, the scaling-law exponents in all of these phases, in particular computing the optimal model-parameter-count as a function of floating point operation budget. We include a colab notebook https://tinyurl.com/2saj6bkj, nanoChinchilla, that reproduces some key results of the paper.",Elliot Paquette; Courtney Paquette; Lechao Xiao; Jeffrey Pennington,~Elliot_Paquette1; ~Courtney_Paquette1; ~Lechao_Xiao2; ~Jeffrey_Pennington1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/d98e6d5ce327f74218765f194d5ec40a6210472d.pdf,2024-05-11T21:16:07.880000,2024-09-25T18:09:21.317000,2025-01-15T10:41:20.557000,https://openreview.net/forum?id=aVSxwicpAk,McGill University; Google
3050,UCSt4gk6iX,UCSt4gk6iX,4755,3D Gaussian Splatting as Markov Chain Monte Carlo,"While 3D Gaussian Splatting has recently become popular for neural rendering, current methods rely on carefully engineered cloning and splitting strategies for placing Gaussians, which does not always generalize and may lead to poor-quality renderings. For many real-world scenes this leads to their heavy dependence on good initializations. In this work, we rethink the set of 3D Gaussians as a random sample drawn from an underlying probability distribution describing the physical representation of the scene—in other words, Markov Chain Monte Carlo (MCMC) samples. Under this view, we show that the 3D Gaussian updates can be converted as Stochastic Gradient Langevin Dynamics (SGLD) update by simply introducing noise. We then rewrite the densification and pruning strategies in 3D Gaussian Splatting as simply a deterministic state transition of MCMC samples, removing these heuristics from the framework. To do so, we revise the ‘cloning’ of Gaussians into a relocalization scheme that approximately preserves sample probability. To encourage efficient use of Gaussians, we introduce an L1-regularizer on the Gaussians. On various standard evaluation scenes, we show that our method provides improved rendering quality, easy control over the number of Gaussians, and robustness to initialization. The project website is available at https://3dgs-mcmc.github.io/.",Shakiba Kheradmand; Daniel Rebain; Gopal Sharma; Weiwei Sun; Yang-Che Tseng; Hossam Isack; Abhishek Kar; Andrea Tagliasacchi; Kwang Moo Yi,~Shakiba_Kheradmand1; ~Daniel_Rebain1; ~Gopal_Sharma1; ~Weiwei_Sun4; ~Yang-Che_Tseng1; ~Hossam_Isack1; ~Abhishek_Kar1; ~Andrea_Tagliasacchi2; ~Kwang_Moo_Yi1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/178046bf1115afd62e70f5e880b7b1c05069e093.pdf,2024-05-11T18:27:09.730000,2024-09-25T18:09:20.200000,2025-01-16T07:09:46.493000,https://openreview.net/forum?id=UCSt4gk6iX,University of British Columbia; University of British Columbia; University of British Columbia; Amazon; University of British Columbia; University of British Columbia; Google; Meta; Google; Simon Fraser University; University of Toronto; Google; University of British Columbia
3054,iYzyTmd3Jd,iYzyTmd3Jd,4732,CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics,"Enabling humanoid robots to clean rooms has long been a pursued dream within humanoid research communities. However, many tasks require multi-humanoid collaboration, such as carrying large and heavy furniture together. Given the scarcity of motion capture data on multi-humanoid collaboration and the efficiency challenges associated with multi-agent learning, these tasks cannot be straightforwardly addressed using training paradigms designed for single-agent scenarios. In this paper, we introduce **Coo**perative **H**uman-**O**bject **I**nteraction (**CooHOI**), a framework designed to tackle the challenge of multi-humanoid object transportation problem through a two-phase learning paradigm: individual skill learning and subsequent policy transfer. First, a single humanoid character learns to interact with objects through imitation learning from human motion priors. Then, the humanoid learns to collaborate with others by considering the shared dynamics of the manipulated object using centralized training and decentralized execution (CTDE) multi-agent RL algorithms. When one agent interacts with the object, resulting in specific object dynamics changes, the other agents learn to respond appropriately, thereby achieving implicit communication and coordination between teammates. Unlike previous approaches that relied on tracking-based methods for multi-humanoid HOI, CooHOI is inherently efficient, does not depend on motion capture data of multi-humanoid interactions, and can be seamlessly extended to include more participants and a wide range of object types.",Jiawei Gao; Ziqin Wang; Zeqi Xiao; Jingbo Wang; Tai Wang; Jinkun Cao; Xiaolin Hu; Si Liu; Jifeng Dai; Jiangmiao Pang,~Jiawei_Gao1; ~Ziqin_Wang2; ~Zeqi_Xiao2; ~Jingbo_Wang3; ~Tai_Wang2; ~Jinkun_Cao1; ~Xiaolin_Hu1; ~Si_Liu5; ~Jifeng_Dai1; ~Jiangmiao_Pang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/dd44c497d9be71bd929e7c858aa8fbc75b131dac.pdf,2024-05-11T16:33:42.867000,2024-09-25T18:09:19.268000,2024-11-06T06:17:58.726000,https://openreview.net/forum?id=iYzyTmd3Jd,"Carnegie Mellon University; Tsinghua University, Beijing; Beihang University; Nanyang Technological University; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; Carnegie Mellon University; Tsinghua University, Beijing; Beihang University; Tsinghua University, Beijing; Shanghai Artificial Intelligence Laboratory"
3067,QFUsZvw9mx,QFUsZvw9mx,4671,Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning,"As a marriage between offline RL and meta-RL, the advent of offline meta-reinforcement learning (OMRL) has shown great promise in enabling RL agents to multi-task and quickly adapt while acquiring knowledge safely. Among which, context-based OMRL (COMRL) as a popular paradigm, aims to learn a universal policy conditioned on effective task representations. In this work, by examining several key milestones in the field of COMRL, we propose to integrate these seemingly independent methodologies into a unified framework. Most importantly, we show that the pre-existing COMRL algorithms are essentially optimizing the same mutual information objective between the task variable $M$ and its latent representation $Z$ by implementing various approximate bounds. Such theoretical insight offers ample design freedom for novel algorithms. As demonstrations, we propose a supervised and a self-supervised implementation of $I(Z; M)$, and empirically show that the corresponding optimization algorithms exhibit remarkable generalization across a broad spectrum of RL benchmarks, context shift scenarios, data qualities and deep learning architectures. This work lays the information theoretic foundation for COMRL methods, leading to a better understanding of task representation learning in the context of reinforcement learning. Given its
generality, we envision our framework as a promising offline pre-training paradigm of foundation models for decision making.",Lanqing Li; Hai Zhang; Xinyu Zhang; Shatong Zhu; Yang YU; Junqiao Zhao; Pheng-Ann Heng,~Lanqing_Li1; ~Hai_Zhang2; ~Xinyu_Zhang31; ~Shatong_Zhu1; ~Yang_YU10; ~Junqiao_Zhao1; ~Pheng-Ann_Heng1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/431275f735b91b74efbeacc336decc57c51809c2.pdf,2024-05-11T14:39:43.449000,2024-09-25T18:09:17.392000,2025-01-16T12:25:29.279000,https://openreview.net/forum?id=QFUsZvw9mx,Chinese University of Hong Kong; Zhejiang Lab; Tongji University; Stony Brook University; Tongji University; Chinese University of Hong Kong; Chinese University of Hong Kong
3097,bcVLFQCOjc,bcVLFQCOjc,4550,DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ,"Creating high-quality scientific figures can be time-consuming and challenging, even though sketching ideas on paper is relatively easy. Furthermore, recreating existing figures that are not stored in formats preserving semantic information is equally complex. To tackle this problem, we introduce DeTikZify, a novel multimodal language model that automatically synthesizes scientific figures as semantics-preserving TikZ graphics programs based on sketches and existing figures. To achieve this, we create three new datasets: DaTikZv2, the largest TikZ dataset to date, containing over 360k human-created TikZ graphics; SketchFig, a dataset that pairs hand-drawn sketches with their corresponding scientific figures; and MetaFig, a collection of diverse scientific figures and associated metadata. We train DeTikZify on MetaFig and DaTikZv2, along with synthetically generated sketches learned from SketchFig. We also introduce an MCTS-based inference algorithm that enables DeTikZify to iteratively refine its outputs without the need for additional training. Through both automatic and human evaluation, we demonstrate that DeTikZify outperforms commercial Claude 3 and GPT-4V in synthesizing TikZ programs, with the MCTS algorithm effectively boosting its performance. We make our code, models, and datasets publicly available.",Jonas Belouadi; Simone Paolo Ponzetto; Steffen Eger,~Jonas_Belouadi1; ~Simone_Paolo_Ponzetto1; ~Steffen_Eger1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/66017807b14cb742e6c3280f2111afbdde4e0f46.pdf,2024-05-11T11:19:21.569000,2024-09-25T18:09:13.859000,2024-11-06T06:17:57.068000,https://openreview.net/forum?id=bcVLFQCOjc,University of Mannheim; National Institute of Information and Communications Technology (NICT); University of Mannheim; University of Mannheim; University of Technology Nuremberg
3117,W8rFsaKr4m,W8rFsaKr4m,4467,MambaTree: Tree Topology is All You Need in State Space Model,"The state space models, employing recursively propagated features, demonstrate strong representation capabilities comparable to Transformer models and superior efficiency.
However, constrained by the inherent geometric constraints of sequences, it still falls short in modeling long-range dependencies.
To address this issue, we propose the MambaTree network, which first dynamically generates a tree topology based on spatial relationships and input features.
Then, feature propagation is performed based on this graph, thereby breaking the original sequence constraints to achieve stronger representation capabilities.
Additionally, we introduce a linear complexity dynamic programming algorithm to enhance long-range interactions without increasing computational cost.
MambaTree is a versatile multimodal framework that can be applied to both visual and textual tasks.
Extensive experiments demonstrate that our method significantly outperforms existing structured state space models on image classification, object detection and segmentation.
Besides, by fine-tuning large language models, our approach achieves consistent improvements in multiple textual tasks at minor training cost.",Yicheng Xiao; Lin Song; Shaoli Huang; Jiangshan Wang; Siyu Song; Yixiao Ge; Xiu Li; Ying Shan,~Yicheng_Xiao1; ~Lin_Song2; ~Shaoli_Huang2; ~Jiangshan_Wang2; ~Siyu_Song1; ~Yixiao_Ge2; ~Xiu_Li1; ~Ying_Shan2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/ecf846fd239301d12bd43f4cb289ebe072572a80.pdf,2024-05-11T08:42:20.041000,2024-09-25T18:09:11.373000,2024-11-06T06:17:56.150000,https://openreview.net/forum?id=W8rFsaKr4m,"Tsinghua University, Beijing; Tencent; Tencent; Tsinghua University, Beijing; Central China Normal University; Tencent; Tsinghua University, Beijing; Tencent"
3127,nZB1FpXUU6,nZB1FpXUU6,4408,Implicit Curriculum in Procgen Made Explicit,"Procedurally generated environments such as Procgen Benchmark provide a testbed for evaluating the agent's ability to robustly learn a relevant skill, by situating the agent in ever-changing levels. The diverse levels associated with varying contexts are naturally connected to curriculum learning. Existing works mainly focus on arranging the levels to explicitly form a curriculum. In this work, we take a close look at the learning process itself under the multi-level training in Procgen. Interestingly, the learning process exhibits a gradual shift from easy contexts to hard contexts, suggesting an implicit curriculum in multi-level training. Our analysis is made possible through C-Procgen, a benchmark we build upon Procgen that enables explicit control of the contexts. We believe our findings will foster a deeper understanding of learning in diverse contexts, and our benchmark will benefit future research in curriculum reinforcement learning.",Zhenxiong Tan; Kaixin Wang; Xinchao Wang,~Zhenxiong_Tan1; ~Kaixin_Wang1; ~Xinchao_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/5f720379b9da89e568586d306f92a07c4beea5fd.pdf,2024-05-11T07:09:23.409000,2024-09-25T18:09:09.894000,2024-11-06T06:17:55.756000,https://openreview.net/forum?id=nZB1FpXUU6,"National University of Singapore; Computer Science Department, Technion - Israel Institute of Technology; Microsoft; National University of Singapore"
3136,Ur00BNk1v2,Ur00BNk1v2,4363,GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing,"Despite the success achieved by existing image generation and editing methods, current models still struggle with complex problems including intricate text prompts, and the absence of  verification and self-correction mechanisms makes the generated images unreliable. Meanwhile, a single model tends to specialize in particular tasks and possess the corresponding capabilities, making it inadequate for fulfilling all user requirements. We propose GenArtist, a unified image generation and editing system, coordinated by a multimodal large language model (MLLM) agent. We integrate a comprehensive range of existing models into the tool library and utilize the agent for tool selection and execution. For a complex problem, the MLLM agent decomposes it into simpler sub-problems and constructs a tree structure to systematically plan the procedure of generation, editing, and self-correction with step-by-step verification. By automatically generating missing position-related inputs and incorporating position information, the appropriate tool can be effectively employed to address each sub-problem. Experiments demonstrate that GenArtist can perform various generation and editing tasks, achieving state-of-the-art performance and surpassing existing models such as SDXL and DALL-E 3, as can be seen in Fig. 1. We will open-source the code for future research and applications.",Zhenyu Wang; Aoxue Li; Zhenguo Li; Xihui Liu,~Zhenyu_Wang3; ~Aoxue_Li2; ~Zhenguo_Li1; ~Xihui_Liu1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/f258668c755324b43c7684198fb87a097e4dd1b5.pdf,2024-05-11T06:17:12.251000,2024-09-25T18:09:08.434000,2024-11-06T06:17:55.373000,https://openreview.net/forum?id=Ur00BNk1v2,"Tsinghua University, Beijing; Huawei Technologies Research & Development (UK) Ltd; Huawei Noah's Ark Lab; Hong Kong University of Science and Technology(Guangzhou); University of Hong Kong"
3140,2xTkeyJFJb,2xTkeyJFJb,4348,Generative Retrieval Meets Multi-Graded Relevance,"Generative retrieval represents a novel approach to information retrieval, utilizing an encoder-decoder architecture to directly produce relevant document identifiers (docids) for queries. While this method offers benefits, current implementations are limited to scenarios with binary relevance data, overlooking the potential for documents to have multi-graded relevance. Extending generative retrieval to accommodate multi-graded relevance poses challenges, including the need to reconcile likelihood probabilities for docid pairs and the possibility of multiple relevant documents sharing the same identifier. To address these challenges, we introduce a new framework called GRaded Generative Retrieval (GR$^2$). Our approach focuses on two key components: ensuring relevant and distinct identifiers, and implementing multi-graded constrained contrastive training. Firstly, we aim to create identifiers that are both semantically relevant and sufficiently distinct to represent individual documents effectively. This is achieved by jointly optimizing the relevance and distinctness of docids through a combination of docid generation and autoencoder models. Secondly, we incorporate information about the relationship between relevance grades to guide the training process. Specifically, we leverage a constrained contrastive training strategy to bring the representations of queries and the identifiers of their relevant documents closer together, based on their respective relevance grades.Extensive experiments on datasets with both multi-graded and binary relevance demonstrate the effectiveness of our method.",Yubao Tang; Ruqing Zhang; Jiafeng Guo; Maarten de Rijke; Wei Chen; Xueqi Cheng,~Yubao_Tang1; ~Ruqing_Zhang3; ~Jiafeng_Guo1; ~Maarten_de_Rijke1; ~Wei_Chen1; ~Xueqi_Cheng1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/79db9c31fa2ec6dbb9dcaba9b60415f8b52386f9.pdf,2024-05-11T05:47:00.457000,2024-09-25T18:09:08.203000,2024-11-06T06:17:55.103000,https://openreview.net/forum?id=2xTkeyJFJb,University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Amsterdam; Chinese Academy of Sciences; University of Chinese Academy of Sciences
3142,qkoZgJhxsA,qkoZgJhxsA,4310,SocraticLM: Exploring Socratic Personalized Teaching with Large Language Models,"Large language models (LLMs) are considered a crucial technology for advancing intelligent education since they exhibit the potential for an in-depth understanding of teaching scenarios and providing students with personalized guidance. Nonetheless, current LLM-based application in personalized teaching predominantly follows a ""Question-Answering"" paradigm, where students are passively provided with answers and explanations. In this paper, we propose SocraticLM, which achieves a Socratic ""Thought-Provoking"" teaching paradigm that fulfills the role of a real classroom teacher in actively engaging students in the thought process required for genuine problem-solving mastery. To build SocraticLM, we first propose a novel ""Dean-Teacher-Student"" multi-agent pipeline to construct a new dataset, SocraTeach, which contains $35$K meticulously crafted Socratic-style multi-round (equivalent to $208$K single-round) teaching dialogues grounded in fundamental mathematical problems. Our dataset simulates authentic teaching scenarios, interacting with six representative types of simulated students with different cognitive states, and strengthening four crucial teaching abilities. SocraticLM is then fine-tuned on SocraTeach with three strategies balancing its teaching and reasoning abilities. Moreover, we contribute a comprehensive evaluation system encompassing five pedagogical dimensions for assessing the teaching quality of LLMs. Extensive experiments verify that SocraticLM achieves significant improvements in the teaching performance, outperforming GPT4 by more than 12\%. Our dataset and code is available at https://github.com/Ljyustc/SocraticLM.",Jiayu Liu; Zhenya Huang; Tong Xiao; Jing Sha; Jinze Wu; Qi Liu; Shijin Wang; Enhong Chen,~Jiayu_Liu2; ~Zhenya_Huang2; ~Tong_Xiao7; ~Jing_Sha1; ~Jinze_Wu1; ~Qi_Liu3; ~Shijin_Wang1; ~Enhong_Chen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/0ffd4457ec8b4fc554d8b483ae93e3e188155407.pdf,2024-05-11T04:02:13.252000,2024-09-25T18:09:07.278000,2024-11-06T06:17:55.026000,https://openreview.net/forum?id=qkoZgJhxsA,University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; IFLYTEK CO.LTD.; University of Science and Technology of China; State Key Laboratory of Cognitive Intelligence; University of Science and Technology of China
3143,yBrxziByeG,yBrxziByeG,4309,Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model,"Existing multi-modal image fusion methods fail to address the compound degradations presented in source images, resulting in fusion images plagued by noise, color bias, improper exposure, etc. Additionally, these methods often overlook the specificity of foreground objects, weakening the salience of the objects of interest within the fused images. To address these challenges, this study proposes a novel interactive multi-modal image fusion framework based on the text-modulated diffusion model, called Text-DiFuse. First, this framework integrates feature-level information integration into the diffusion process, allowing adaptive degradation removal and multi-modal information fusion. This is the first attempt to deeply and explicitly embed information fusion within the diffusion process, effectively addressing compound degradation in image fusion. Second, by embedding the combination of the text and zero-shot location model into the diffusion fusion process, a text-controlled fusion re-modulation strategy is developed. This enables user-customized text control to improve fusion performance and highlight foreground objects in the fused images. Extensive experiments on diverse public datasets show that our Text-DiFuse achieves state-of-the-art fusion performance across various scenarios with complex degradation. Moreover, the semantic segmentation experiment validates the significant enhancement in semantic performance achieved by our text-controlled fusion re-modulation strategy. The code is publicly available at https://github.com/Leiii-Cao/Text-DiFuse.",Hao Zhang; Lei Cao; Jiayi Ma,~Hao_Zhang26; ~Lei_Cao10; ~Jiayi_Ma2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/1870be1308452cfd34778a0947c89002562387ed.pdf,2024-05-11T04:01:50.881000,2024-09-25T18:09:07.214000,2024-11-06T06:17:54.990000,https://openreview.net/forum?id=yBrxziByeG,Wuhan University; Wuhan University; Wuhan University
3146,lYdjzx3DYu,lYdjzx3DYu,4299,EMR-Merging: Tuning-Free High-Performance Model Merging,"The success of pretrain-finetune paradigm brings about the release of numerous model weights. In this case, merging models finetuned on different tasks to enable a single model with multi-task capabilities is gaining increasing attention for its practicability. Existing model merging methods usually suffer from (1) significant performance degradation or (2) requiring tuning by additional data or training. In this paper, we rethink and analyze the existing model merging paradigm. We discover that using a single model's weights can hardly simulate all the models' performance. To tackle this issue, we propose Elect, Mask & Rescale-Merging (EMR-Merging). We first (a) elect a unified model from all the model weights and then (b) generate extremely lightweight task-specific modulators, including masks and rescalers, to align the direction and magnitude between the unified model and each specific model, respectively. EMR-Merging is tuning-free, thus requiring no data availability or any additional training while showing impressive performance. We find that EMR-Merging shows outstanding performance compared to existing merging methods under different classical and newly-established settings, including merging different numbers of vision models (up to 30), NLP models, PEFT models, and multi-modal models.",Chenyu Huang; Peng Ye; Tao Chen; Tong He; Xiangyu Yue; Wanli Ouyang,~Chenyu_Huang2; ~Peng_Ye4; ~Tao_Chen6; ~Tong_He2; ~Xiangyu_Yue1; ~Wanli_Ouyang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/a38766f5219099b521172d338543f2873c94fc89.pdf,2024-05-11T03:39:31.487000,2024-09-25T18:09:06.907000,2024-11-06T06:17:54.769000,https://openreview.net/forum?id=lYdjzx3DYu,Fudan University; Southeast University; Fudan University; Chinese University of Hong Kong; Fudan University; Shanghai Artificial Intelligence Laboratory; Chinese University of Hong Kong; Shanghai Artificial Intelligence Laboratory
3168,iSfCWhvEGA,iSfCWhvEGA,4226,Learn To be Efficient: Build Structured Sparsity in Large Language Models,"Large Language Models (LLMs) have achieved remarkable success with their billion-level parameters, yet they incur high inference overheads. The emergence of activation sparsity in LLMs provides a natural approach to reduce this cost by involving only parts of the parameters for inference. However, existing methods only focus on utilizing this naturally formed activation sparsity in a post-training setting, overlooking the potential for further amplifying this inherent sparsity. In this paper, we hypothesize that LLMs can learn to be efficient by achieving more structured activation sparsity. To achieve this, we introduce a novel training algorithm, Learn-To-be-Efficient (LTE), designed to train efficiency-aware LLMs to learn to activate fewer neurons and achieve a better trade-off between sparsity and performance. Furthermore, unlike SOTA MoEfication methods, which mainly focus on ReLU-based models, LTE can also be applied to LLMs like LLaMA using non-ReLU activations. Extensive evaluation on language understanding, language generation, and instruction tuning tasks show that LTE consistently outperforms SOTA baselines. Along with our hardware-aware custom kernel implementation, LTE reduces LLaMA2-7B inference latency by 25% at 50% sparsity.",Haizhong Zheng; Xiaoyan Bai; Xueshen Liu; Zhuoqing Mao; Beidi Chen; Fan Lai; Atul Prakash,~Haizhong_Zheng1; ~Xiaoyan_Bai1; ~Xueshen_Liu1; ~Zhuoqing_Mao1; ~Beidi_Chen1; ~Fan_Lai1; ~Atul_Prakash1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/cbc38b75fb9f4610e187bea81a58d84cd2bde26a.pdf,2024-05-11T00:59:05.449000,2024-09-25T18:09:04.326000,2024-11-06T06:17:53.876000,https://openreview.net/forum?id=iSfCWhvEGA,University of Michigan - Ann Arbor; University of Michigan - Ann Arbor; University of Chicago; University of Michigan - Ann Arbor; University of Michigan - Ann Arbor; Google; Meta; Carnegie Mellon University
3169,wiEHZSV15I,wiEHZSV15I,4225,Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting,"Long-term time series forecasting (LTSF) represents a critical frontier in time series analysis, characterized by extensive input sequences, as opposed to the shorter spans typical of traditional approaches. While longer sequences inherently offer richer information for enhanced predictive precision, prevailing studies often respond by escalating model complexity. These intricate models can inflate into millions of parameters, resulting in prohibitive parameter scales. Our study demonstrates, through both theoretical and empirical evidence, that decomposition is key to containing excessive model inflation while achieving uniformly superior and robust results across various datasets. Remarkably, by tailoring decomposition to the intrinsic dynamics of time series data, our proposed model outperforms existing benchmarks, using over 99\% fewer parameters than the majority of competing methods. Through this work, we aim to unleash the power of a restricted set of parameters by capitalizing on domain characteristics—a timely reminder that in the realm of LTSF, bigger is not invariably better. The code is available at \url{https://anonymous.4open.science/r/SSCNN-321D/}.",Jinliang Deng; Feiyang Ye; Du Yin; Xuan Song; Ivor Tsang; Hui Xiong,~Jinliang_Deng1; ~Feiyang_Ye4; ~Du_Yin1; ~Xuan_Song2; ~Ivor_Tsang1; ~Hui_Xiong1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/948d95efe5e6afae5d29dfdcaa09d2ce2b04a7bc.pdf,2024-05-11T00:48:13.921000,2024-09-25T18:09:04.321000,2025-01-06T14:08:06.004000,https://openreview.net/forum?id=wiEHZSV15I,University of Technology Sydney; Hong Kong University of Science and Technology(Guangzhou); University of Technology Sydney; UNSW Sydney; Southern University of Science and Technology (SUSTech); The University of Tokyo; Jilin University; A*STAR; Hong Kong University of Science and Technology(Guangzhou)
3170,P4s6FUpCbG,P4s6FUpCbG,4219,3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors,"Novel-view synthesis aims to generate novel views of a scene from multiple input
images or videos, and recent advancements like 3D Gaussian splatting (3DGS)
have achieved notable success in producing photorealistic renderings with efficient
pipelines. However, generating high-quality novel views under challenging settings,
such as sparse input views, remains difficult due to insufficient information in
under-sampled areas, often resulting in noticeable artifacts. This paper presents
3DGS-Enhancer, a novel pipeline for enhancing the representation quality of
3DGS representations. We leverage 2D video diffusion priors to address the
challenging 3D view consistency problem, reformulating it as achieving temporal
consistency within a video generation process. 3DGS-Enhancer restores view-
consistent latent features of rendered novel views and integrates them with the
input views through a spatial-temporal decoder. The enhanced views are then
used to fine-tune the initial 3DGS model, significantly improving its rendering
performance. Extensive experiments on large-scale datasets of unbounded scenes
demonstrate that 3DGS-Enhancer yields superior reconstruction performance and
high-fidelity rendering results compared to state-of-the-art methods. The project
webpage is https://xiliu8006.github.io/3DGS-Enhancer-project.",Xi Liu; Chaoyi Zhou; Siyu Huang,~Xi_Liu3; ~Chaoyi_Zhou2; ~Siyu_Huang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/a720faff2c30ef1cb570c05034912fe3f646d738.pdf,2024-05-10T23:40:26.868000,2024-09-25T18:09:03.957000,2024-11-06T06:17:53.790000,https://openreview.net/forum?id=P4s6FUpCbG,Clemson University; Clemson University; Clemson University
3171,nfK0ZXFFSn,nfK0ZXFFSn,4205,HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection,"The surge in applications of large language models (LLMs) has prompted concerns about the generation of misleading or fabricated information, known as hallucinations. Therefore, detecting hallucinations has become critical to maintaining trust in LLM-generated content. A primary challenge in learning a truthfulness classifier is the lack of a large amount of labeled truthful and hallucinated data. To address the challenge, we introduce HaloScope, a novel learning framework that leverages the unlabeled LLM generations in the wild for hallucination detection. Such unlabeled data arises freely upon deploying LLMs in the open world, and consists of both truthful and hallucinated information. To harness the unlabeled data, we present an automated scoring function for distinguishing between truthful and untruthful generations within unlabeled mixture data, thereby enabling the training of a binary classifier on top. Importantly, our framework does not require extra data collection and human annotations, offering strong flexibility and practicality for real-world applications. Extensive experiments show that HaloScope can achieve superior hallucination detection performance, outperforming the competitive rivals by a significant margin.",Xuefeng Du; Chaowei Xiao; Yixuan Li,~Xuefeng_Du1; ~Chaowei_Xiao2; ~Yixuan_Li1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/2aa5c5a4f6fe82c75a1685bb7ec91893ade0f68b.pdf,2024-05-10T22:22:20.050000,2024-09-25T18:09:03.771000,2024-11-06T06:17:53.746000,https://openreview.net/forum?id=nfK0ZXFFSn,University of Wisconsin - Madison; University of Wisconsin - Madison; NVIDIA; Cornell University; University of Wisconsin - Madison; Meta; Stanford University; Google
3177,OCQbC0eDJJ,OCQbC0eDJJ,4181,Honor Among Bandits: No-Regret Learning for Online Fair Division,"We consider the problem of online fair division of indivisible goods to players when there are a finite number of types of goods and player values are drawn from distributions with unknown means. Our goal is to maximize social welfare subject to allocating the goods fairly in expectation. When a player's value for an item is unknown at the time of allocation, we show that this problem reduces to a variant of (stochastic) multi-armed bandits, where there exists an arm for each player's value for each type of good. At each time step, we choose a distribution over arms which determines how the next item is allocated. We consider two sets of fairness constraints for this problem: envy-freeness in expectation and proportionality in expectation. Our main result is the design of an explore-then-commit algorithm that achieves $\tilde{O}(T^{2/3})$ regret while maintaining either fairness constraint. This result relies on unique properties fundamental to fair-division constraints that allow faster rates of learning, despite the restricted action space.",Ariel D. Procaccia; Benjamin Schiffer; Shirley Zhang,~Ariel_D._Procaccia1; ~Benjamin_Schiffer1; ~Shirley_Zhang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,algorithmic_game_theory,/pdf/e51703a9cc881f1bac82757c29e0110b097fd401.pdf,2024-05-10T21:06:02.244000,2024-09-25T18:09:03.245000,2024-11-06T06:17:53.513000,https://openreview.net/forum?id=OCQbC0eDJJ,Harvard University; Harvard University; Harvard University
3188,TxffvJMnBy,TxffvJMnBy,4153,Optimal Algorithms for Online Convex Optimization with Adversarial Constraints,"A well-studied generalization of the standard online convex optimization (OCO) framework is constrained online convex optimization (COCO). In COCO, on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round. The objective is to design an online learning policy that simultaneously achieves a small regret while ensuring a small cumulative constraint violation (CCV) against an adaptive adversary interacting over a horizon of length $T$. A long-standing open question in COCO is whether an online policy can simultaneously achieve $O(\sqrt{T})$ regret and $\tilde{O}(\sqrt{T})$ CCV without any restrictive assumptions. For the first time, we answer this in the affirmative and show that a simple first-order policy can simultaneously achieve these bounds. Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to $O(\log T)$ while keeping the CCV bound the same as above. We establish these results by effectively combining adaptive OCO policies as a blackbox with Lyapunov optimization - a classic tool from control theory. Surprisingly, the analysis is short and elegant.",Abhishek Sinha; Rahul Vaze,~Abhishek_Sinha3; ~Rahul_Vaze1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,online_learning,/pdf/269618651cc4c3886e154ec85079164a62691bdc.pdf,2024-05-10T19:10:09.133000,2024-09-25T18:09:02.162000,2024-11-06T06:17:53.026000,https://openreview.net/forum?id=TxffvJMnBy,Tata Institute of Fundamental Research
3222,zNiJZUAlxg,zNiJZUAlxg,4022,ResAD: A Simple Framework for Class Generalizable Anomaly Detection,"This paper explores the problem of class-generalizable anomaly detection, where the objective is to train one unified AD model that can generalize to detect anomalies in diverse classes from different domains without any retraining or fine-tuning on the target data. Because normal feature representations vary significantly across classes, this will cause the widely studied one-for-one AD models to be poorly classgeneralizable (i.e., performance drops dramatically when used for new classes). In this work, we propose a simple but effective framework (called ResAD) that can be directly applied to detect anomalies in new classes. Our main insight is to learn the residual feature distribution rather than the initial feature distribution. In this way, we can significantly reduce feature variations. Even in new classes, the distribution of normal residual features would not remarkably shift from the learned distribution. Therefore, the learned model can be directly adapted to new classes. ResAD consists of three components: (1) a Feature Converter that converts initial features into residual features; (2) a simple and shallow Feature Constraintor that constrains normal residual features into a spatial hypersphere for further reducing feature variations and maintaining consistency in feature scales among different classes; (3) a Feature Distribution Estimator that estimates the normal residual feature distribution, anomalies can be recognized as out-of-distribution. Despite the simplicity, ResAD can achieve remarkable anomaly detection results when directly used in new classes. The code is available at https://github.com/xcyao00/ResAD.",Xincheng Yao; Zixin Chen; Chao Gao; Guangtao Zhai; Chongyang Zhang,~Xincheng_Yao2; ~Zixin_Chen1; ~Chao_Gao6; ~Guangtao_Zhai1; ~Chongyang_Zhang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/597429127fac8d70a05f0ca884272186eeefa326.pdf,2024-05-10T14:17:05.418000,2024-09-25T18:08:57.764000,2024-11-06T06:17:51.537000,https://openreview.net/forum?id=zNiJZUAlxg,Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University
3224,fkbMlfDBxm,fkbMlfDBxm,4013,Reconstruct and Match: Out-of-Distribution Robustness via Topological Homogeneity,"Since deep learning models are usually deployed in non-stationary environments, it is imperative to improve their robustness to out-of-distribution (OOD) data. A common approach to mitigate distribution shift is to regularize internal representations or predictors learned from in-distribution (ID) data to be domain invariant. Past studies have primarily learned pairwise invariances, ignoring the intrinsic structure and high-order dependencies of the data. Unlike machines, human recognizes objects by first dividing them into major components and then identifying the topological relation of these components. Motivated by this, we propose Reconstruct and Match (REMA), a general learning framework for object recognition tasks to endow deep models with the capability of capturing the topological homogeneity of objects without human prior knowledge or fine-grained annotations. To identify major components from objects, REMA introduces a selective slot-based reconstruction module to dynamically map dense pixels into a sparse and discrete set of slot vectors in an unsupervised manner. Then, to model high-order dependencies among these components, we propose a hypergraph-based relational reasoning module that models the intricate relations of nodes (slots) with structural constraints. Experiments on standard benchmarks show that REMA outperforms state-of-the-art methods in OOD generalization and test-time adaptation settings.",Chaoqi Chen; Luyao Tang; Hui Huang,~Chaoqi_Chen2; ~Luyao_Tang1; ~Hui_Huang3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/0b54a85b1942b39f94804d47e2c7515aa2556c20.pdf,2024-05-10T14:03:57.134000,2024-09-25T18:08:57.519000,2024-12-23T13:07:30.537000,https://openreview.net/forum?id=fkbMlfDBxm,University of Hong Kong; Shenzhen University; Xiamen University; Shenzhen University
3237,jXxvSkb9HD,jXxvSkb9HD,3964,Statistical Multicriteria Benchmarking via the GSD-Front,"Given the vast number of classifiers that have been (and continue to be) proposed, reliable methods for comparing them are becoming increasingly important. The desire for reliability is broken down into three main aspects: (1) Comparisons should allow for different quality metrics simultaneously. (2) Comparisons should take into account the statistical uncertainty induced by the choice of benchmark suite. (3) The robustness of the comparisons under small deviations in the underlying assumptions should be verifiable. To address (1), we propose to compare classifiers using a generalized stochastic dominance ordering (GSD) and present the GSD-front as an information-efficient alternative to the classical Pareto-front. For (2), we propose a consistent statistical estimator for the GSD-front and construct a statistical test for whether a (potentially new) classifier lies in the GSD-front of a set of state-of-the-art classifiers. For (3), we relax our proposed test using techniques from robust statistics and imprecise probabilities. We illustrate our concepts on the benchmark suite PMLB and on the platform OpenML.",Christoph Jansen; Georg Schollmeyer; Julian Rodemann; Hannah Blocher; Thomas Augustin,~Christoph_Jansen1; ~Georg_Schollmeyer1; ~Julian_Rodemann1; ~Hannah_Blocher1; ~Thomas_Augustin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,evaluation,/pdf/643e9327231a9522b4dfe2d70380d157f0657ddf.pdf,2024-05-10T12:45:28.957000,2024-09-25T18:08:55.823000,2024-11-06T06:17:50.843000,https://openreview.net/forum?id=jXxvSkb9HD,Lancaster University; Ludwig-Maximilians-Universität München; Department of Statistics
3251,FXJDcriMYH,FXJDcriMYH,3906,Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training,"LLMs are computationally expensive to pre-train due to their large scale.
Model growth emerges as a promising approach by leveraging smaller models to accelerate the training of larger ones. 
However, the viability of these model growth methods in efficient LLM pre-training remains underexplored.
This work identifies three critical $\underline{\textit{O}}$bstacles: ($\textit{O}$1) lack of comprehensive evaluation, ($\textit{O}$2) untested viability for scaling, and ($\textit{O}$3) lack of empirical guidelines.
To tackle $\textit{O}$1, we summarize existing approaches into four atomic growth operators and systematically evaluate them in a standardized LLM pre-training setting.
Our findings reveal that a depthwise stacking operator, called $G_{\text{stack}}$, exhibits remarkable acceleration in training, leading to decreased loss and improved overall performance on eight standard NLP benchmarks compared to strong baselines. 
Motivated by these promising results, we conduct extensive experiments to delve deeper into $G_{\text{stack}}$ to address $\textit{O}$2 and $\textit{O}$3.
For $\textit{O}$2 (untested scalability), our study shows that $G_{\text{stack}}$ is scalable and consistently performs well, with experiments up to 7B LLMs after growth and pre-training LLMs with 750B tokens.
For example, compared to a conventionally trained 7B model using 300B tokens, our $G_{\text{stack}}$ model converges to the same loss with 194B tokens, resulting in a 54.6\% speedup. 
We further address $\textit{O}$3 (lack of empirical guidelines) by formalizing guidelines to determine growth timing and growth factor for $G_{\text{stack}}$, making it practical in general LLM pre-training.
We also provide in-depth discussions and comprehensive ablation studies of $G_{\text{stack}}$. 
Our code and pre-trained model are available at https://llm-stacking.github.io/.",Wenyu Du; Tongxu Luo; Zihan Qiu; Zeyu Huang; Yikang Shen; Reynold Cheng; Yike Guo; Jie Fu,~Wenyu_Du1; ~Tongxu_Luo1; ~Zihan_Qiu1; ~Zeyu_Huang1; ~Yikang_Shen1; ~Reynold_Cheng1; ~Yike_Guo1; ~Jie_Fu2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/2c7146fd80b9afb7935702797fb5bfb715dfb090.pdf,2024-05-10T10:28:36.989000,2024-09-25T18:08:54.064000,2024-11-06T06:17:50.296000,https://openreview.net/forum?id=FXJDcriMYH,"University of Hong Kong; Alibaba Group; Tsinghua University, Beijing; University of Edinburgh; International Business Machines; University of Hong Kong; Hong Kong University of Science and Technology(Guangzhou); Imperial College London; Hong Kong University of Science and Technology(Guangzhou); Shanghai Artificial Intelligence Laboratory"
3268,jd3msHMtTL,jd3msHMtTL,3796,"Small coresets via negative dependence: DPPs, linear statistics, and concentration","Determinantal point processes (DPPs) are random configurations of points with tunable negative dependence. 
Because sampling is tractable, DPPs are natural candidates for subsampling tasks, such as minibatch selection or coreset construction. 
A \emph{coreset} is a subset of a (large) training set, such that minimizing an empirical loss averaged over the coreset is a controlled replacement for the intractable minimization of the original empirical loss.
Typically, the control takes the form of a guarantee that the average loss over the coreset approximates the total loss uniformly across the parameter space.
Recent work has provided significant empirical support in favor of using DPPs to build randomized coresets, coupled with interesting theoretical results that are suggestive but leave some key questions unanswered.
In particular, the central question of whether the cardinality of a DPP-based coreset is fundamentally smaller than one based on independent sampling remained open.
In this paper, we answer this question in the affirmative, demonstrating that \emph{DPPs can provably outperform independently drawn coresets}. 
In this vein, we contribute a conceptual understanding of coreset loss as a \emph{linear statistic} of the (random) coreset. 
We leverage this structural observation to connect the coresets problem to a more general problem of concentration phenomena for linear statistics of DPPs, wherein we obtain \emph{effective concentration inequalities that extend well-beyond the state-of-the-art}, encompassing general non-projection, even non-symmetric kernels. 
The latter have been recently shown to be of interest in machine learning beyond coresets, but come with a limited theoretical toolbox, to the extension of which our result contributes. Finally, we are also able to address the coresets problem for vector-valued objective functions, a novelty in the coresets literature.",Rémi Bardenet; Subhroshekhar Ghosh; Hugo Simon-Onfroy; Hoang-Son Tran,~Rémi_Bardenet1; ~Subhroshekhar_Ghosh1; ~Hugo_Simon-Onfroy1; ~Hoang-Son_Tran1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/82a0142c5cdb3f86dbd522ceae97947a5435cb25.pdf,2024-05-10T07:33:40.639000,2024-09-25T18:08:51.072000,2024-11-06T06:17:49.666000,https://openreview.net/forum?id=jd3msHMtTL,CEA; National University of Singapore
3290,7uqVfZW6Mo,7uqVfZW6Mo,3675,Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features,"Diffusion models are initially designed for image generation. Recent research shows that the internal signals within their backbones, named activations, can also serve as dense features for various discriminative tasks such as semantic segmentation. Given numerous activations, selecting a small yet effective subset poses a fundamental problem. To this end, the early study of this field performs a large-scale quantitative comparison of the discriminative ability of the activations. However, we find that many potential activations have not been evaluated, such as the queries and keys used to compute attention scores. Moreover, recent advancements in diffusion architectures bring many new activations, such as those within embedded ViT modules. Both combined, activation selection remains unresolved but overlooked. To tackle this issue, this paper takes a further step with a much broader range of activations evaluated. Considering the significant increase in activations, a full-scale quantitative comparison is no longer operational. Instead, we seek to understand the properties of these activations, such that the activations that are clearly inferior can be filtered out in advance via simple qualitative evaluation. After careful analysis, we discover three properties universal among diffusion models, enabling this study to go beyond specific models. On top of this, we present effective feature selection solutions for several popular diffusion models. Finally, the experiments across multiple discriminative tasks validate the superiority of our method over the SOTA competitors. Our code is available at https://github.com/Darkbblue/generic-diffusion-feature.",Benyuan Meng; Qianqian Xu; Zitai Wang; Xiaochun Cao; Qingming Huang,~Benyuan_Meng1; ~Qianqian_Xu2; ~Zitai_Wang1; ~Xiaochun_Cao3; ~Qingming_Huang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/62cfa5c7b177ef41ff9226b8f70c4119c76da3d3.pdf,2024-05-10T04:15:06.707000,2024-09-25T18:08:47.740000,2024-11-06T06:17:48.652000,https://openreview.net/forum?id=7uqVfZW6Mo,University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Sun Yat-sen University; University of Chinese Academy of Sciences
3298,6qr3932RWe,6qr3932RWe,3651,Memorize What Matters: Emergent Scene Decomposition from Multitraverse,"Humans naturally retain memories of permanent elements, while ephemeral moments often slip through the cracks of memory. This selective retention is crucial for robotic perception, localization, and mapping. To endow robots with this capability, we introduce 3D Gaussian Mapping (3DGM), a self-supervised, camera-only offline mapping framework grounded in 3D Gaussian Splatting. 3DGM converts multitraverse RGB videos from the same region into a Gaussian-based environmental map while concurrently performing 2D ephemeral object segmentation. Our key observation is that the environment remains consistent across traversals, while objects frequently change. This allows us to exploit self-supervision from repeated traversals to achieve environment-object decomposition. More specifically, 3DGM formulates multitraverse environmental mapping as a robust 3D representation learning problem, treating pixels of the environment and objects as inliers and outliers, respectively. Using robust feature distillation, feature residual mining, and robust optimization, 3DGM simultaneously performs 2D segmentation and 3D mapping without human intervention. We build the Mapverse benchmark, sourced from the Ithaca365 and nuPlan datasets, to evaluate our method in unsupervised 2D segmentation, 3D reconstruction, and neural rendering. Extensive results verify the effectiveness and potential of our method for self-driving and robotics.",Yiming Li; Zehong Wang; Yue Wang; Zhiding Yu; Zan Gojcic; Marco Pavone; Chen Feng; Jose M. Alvarez,~Yiming_Li2; ~Zehong_Wang3; ~Yue_Wang2; ~Zhiding_Yu1; ~Zan_Gojcic1; ~Marco_Pavone1; ~Chen_Feng2; ~Jose_M._Alvarez2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/87c09e2b7e2f39416a87c855d382e4d74db73b8a.pdf,2024-05-10T03:39:17.237000,2024-09-25T18:08:47.017000,2024-11-06T06:17:48.345000,https://openreview.net/forum?id=6qr3932RWe,New York University; New York University; University of Southern California; NVIDIA; NVIDIA; NVIDIA; Stanford University; NVIDIA; New York University; NVIDIA
3307,abuQMKDVkW,abuQMKDVkW,3587,SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection,"Synthetic Aperture Radar (SAR) object detection has gained significant attention recently due to its irreplaceable all-weather imaging capabilities. However, this research field suffers from both limited public datasets (mostly comprising <2K images with only mono-category objects) and inaccessible source code. To tackle these challenges, we establish a new benchmark dataset and an open-source method for large-scale SAR object detection. Our dataset, SARDet-100K, is a result of intense surveying, collecting, and standardizing 10 existing SAR detection datasets, providing a large-scale and diverse dataset for research purposes. To the best of our knowledge, SARDet-100K is the first COCO-level large-scale multi-class SAR object detection dataset ever created. With this high-quality dataset, we conducted comprehensive experiments and uncovered a crucial challenge in SAR object detection: the substantial disparities between the pretraining on RGB datasets and finetuning on SAR datasets in terms of both data domain and model structure. To bridge these gaps, we propose a novel Multi-Stage with Filter Augmentation (MSFA) pretraining framework that tackles the problems from the perspective of data input, domain transition, and model migration. The proposed MSFA method significantly enhances the performance of SAR object detection models while demonstrating exceptional generalizability and flexibility across diverse models. This work aims to pave the way for further advancements in SAR object detection. The dataset and code is available at \url{https://github.com/zcablii/SARDet_100K}.",Yuxuan Li; Xiang Li; Weijie Li; Qibin Hou; Li Liu; Ming-Ming Cheng; Jian Yang,~Yuxuan_Li4; ~Xiang_Li20; ~Weijie_Li11; ~Qibin_Hou1; ~Li_Liu9; ~Ming-Ming_Cheng3; ~Jian_Yang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/511ed5cdbbdab7fd65ebf292460460791da6821c.pdf,2024-05-10T02:11:41.662000,2024-09-25T18:08:45.286000,2024-11-06T06:17:47.933000,https://openreview.net/forum?id=abuQMKDVkW,Nankai University; Nankai University; National University of Defense Technology; Nankai University; National University of Defense Technology; Nankai University; Nanjing University
3319,9bu627mTfs,9bu627mTfs,3532,Context and Geometry Aware Voxel Transformer for Semantic Scene Completion,"Vision-based Semantic Scene Completion (SSC) has gained much attention due to its widespread applications in various 3D perception tasks. Existing sparse-to-dense approaches typically employ shared context-independent queries across various input images, which fails to capture distinctions among them as the focal regions of different inputs vary and may result in undirected feature aggregation of cross-attention. Additionally, the absence of depth information may lead to points projected onto the image plane sharing the same 2D position or similar sampling points in the feature map, resulting in depth ambiguity. In this paper, we present a novel context and geometry aware voxel transformer. It utilizes a context aware query generator to initialize context-dependent queries tailored to individual input images, effectively capturing their unique characteristics and aggregating information within the region of interest. Furthermore, it extend deformable cross-attention from 2D to 3D pixel space, enabling the differentiation of points with similar image coordinates based on their depth coordinates. Building upon this module, we introduce a neural network named CGFormer to achieve semantic scene completion. Simultaneously, CGFormer leverages multiple 3D representations (i.e., voxel and TPV) to boost the semantic and geometric representation abilities of the transformed 3D volume from both local and global perspectives. Experimental results demonstrate that CGFormer achieves state-of-the-art performance on the SemanticKITTI and SSCBench-KITTI-360 benchmarks, attaining a mIoU of 16.87 and 20.05, as well as an IoU of 45.99 and 48.07, respectively. Remarkably, CGFormer even outperforms approaches employing temporal images as inputs or much larger image backbone networks.",Zhu Yu; Runmin Zhang; Jiacheng Ying; Junchen Yu; Xiaohai Hu; Lun Luo; Si-Yuan Cao; Hui-liang Shen,~Zhu_Yu2; ~Runmin_Zhang1; ~Jiacheng_Ying1; ~Junchen_Yu1; ~Xiaohai_Hu1; ~Lun_Luo1; ~Si-Yuan_Cao1; ~Hui-liang_Shen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/a85e6bb16f97387d47e2c4cab6cb73dc8a9b1e08.pdf,2024-05-10T00:00:50.293000,2024-09-25T18:08:43.785000,2024-11-06T06:17:47.420000,https://openreview.net/forum?id=9bu627mTfs,Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; University of Washington; HAOMO.AI; Zhejiang University; Zhejiang University
3320,AB6XpMzvqH,AB6XpMzvqH,3528,Many-Shot In-Context Learning,"Large language models (LLMs) excel at few-shot in-context learning (ICL) -- learning from a few examples provided in context at inference, without any weight updates. Newly expanded context windows allow us to investigate ICL with hundreds or thousands of examples – the many-shot regime. Going from few-shot to many-shot, we observe significant performance gains across a wide variety of generative and discriminative tasks. While promising, many-shot ICL can be bottlenecked by the available amount of human-generated outputs. To mitigate this limitation, we explore two new settings: (1) ""Reinforced ICL"" that uses model-generated chain-of-thought rationales in place of human rationales, and (2) ""Unsupervised ICL"" where we remove rationales from the prompt altogether, and prompts the model only with domain-specific inputs. We find that both Reinforced and Unsupervised ICL can be quite effective in the many-shot regime, particularly on complex reasoning tasks. We demonstrate that, unlike few-shot learning, many-shot learning is effective at overriding pretraining biases, can learn high-dimensional functions with numerical inputs, and performs comparably to supervised fine-tuning. Finally, we reveal the limitations of next-token prediction loss as an indicator of downstream ICL performance.",Rishabh Agarwal; Avi Singh; Lei M Zhang; Bernd Bohnet; Luis Rosias; Stephanie C.Y. Chan; Biao Zhang; Ankesh Anand; Zaheer Abbas; Azade Nova; John D Co-Reyes; Eric Chu; Feryal Behbahani; Aleksandra Faust; Hugo Larochelle,~Rishabh_Agarwal2; ~Avi_Singh1; ~Lei_M_Zhang1; ~Bernd_Bohnet1; ~Luis_Rosias1; ~Stephanie_C.Y._Chan1; ~Biao_Zhang2; ~Ankesh_Anand1; ~Zaheer_Abbas1; ~Azade_Nova1; ~John_D_Co-Reyes1; ~Eric_Chu1; ~Feryal_Behbahani1; ~Aleksandra_Faust1; ~Hugo_Larochelle1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/314518db5ff85321727d47c688ea59cd23d2a470.pdf,2024-05-09T23:46:04.040000,2024-09-25T18:08:43.652000,2024-11-06T06:17:47.400000,https://openreview.net/forum?id=AB6XpMzvqH,McGill University; Google; Google; Google; Google; Google; Google; Montreal Institute of Learning Algorithms; Google
3322,6AeIDnrTN2,6AeIDnrTN2,3519,LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS,"Recent advances in real-time neural rendering using point-based techniques have enabled broader adoption of 3D representations. However, foundational approaches like 3D Gaussian Splatting impose substantial storage overhead, as Structure-from-Motion (SfM) points can grow to millions, often requiring gigabyte-level disk space for a single unbounded scene. This growth presents scalability challenges and hinders splatting efficiency. To address this, we introduce LightGaussian, a method for transforming 3D Gaussians into a more compact format. Inspired by Network Pruning, LightGaussian identifies Gaussians with minimal global significance on scene reconstruction, and applies a pruning and recovery process to reduce redundancy while preserving visual quality. Knowledge distillation and pseudo-view augmentation then transfer spherical harmonic coefficients to a lower degree, yielding compact representations. Gaussian Vector Quantization, based on each Gaussian’s global significance, further lowers bitwidth with minimal accuracy loss. LightGaussian achieves an average 15 times compression rate while boosting FPS from 144 to 237 within the 3D-GS framework, enabling efficient complex scene representation on the Mip-NeRF 360 and Tank & Temple datasets. The proposed Gaussian pruning approach is also adaptable to other 3D representations (e.g., Scaffold-GS), demonstrating strong generalization capabilities.",Zhiwen Fan; Kevin Wang; Kairun Wen; Zehao Zhu; Dejia Xu; Zhangyang Wang,~Zhiwen_Fan2; ~Kevin_Wang4; ~Kairun_Wen1; ~Zehao_Zhu1; ~Dejia_Xu1; ~Zhangyang_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/d0507b645e341f177a1e3de5af404a2a3def18ab.pdf,2024-05-09T23:11:35.331000,2024-09-25T18:08:43.385000,2024-11-06T06:17:47.268000,https://openreview.net/forum?id=6AeIDnrTN2,The University of Texas at Austin; The University of Texas at Austin; Xiamen University; The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin
3335,clTa4JFBML,clTa4JFBML,3478,Return of Unconditional Generation: A Self-supervised Representation Generation Method,"Unconditional generation -- the problem of modeling data distribution without relying on human-annotated labels -- is a long-standing and fundamental challenge in generative models, creating a potential of learning from large-scale unlabeled data. In the literature, the generation quality of an unconditional method has been much worse than that of its conditional counterpart. This gap can be attributed to the lack of semantic information provided by labels. In this work, we show that one can close this gap by generating semantic representations in the representation space produced by a self-supervised encoder. These representations can be used to condition the image generator. This framework, called Representation-Conditioned Generation (RCG), provides an effective solution to the unconditional generation problem without using labels. Through comprehensive experiments, we observe that RCG significantly improves unconditional generation quality: e.g., it achieves a new state-of-the-art FID of 2.15 on ImageNet 256x256, largely reducing the previous best of 5.91 by a relative 64%. Our unconditional results are situated in the same tier as the leading class-conditional ones. We hope these encouraging observations will attract the community's attention to the fundamental problem of unconditional generation. Code is available at [https://github.com/LTH14/rcg](https://github.com/LTH14/rcg).",Tianhong Li; Dina Katabi; Kaiming He,~Tianhong_Li3; ~Dina_Katabi1; ~Kaiming_He2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,generative_models,/pdf/5eb9f339be4769dbc0a7ac40c1b8e020626b9052.pdf,2024-05-09T21:03:17.772000,2024-09-25T18:08:42.059000,2024-11-06T06:17:46.717000,https://openreview.net/forum?id=clTa4JFBML,Massachusetts Institute of Technology; Massachusetts Institute of Technology; Meta; Massachusetts Institute of Technology
3338,5G7MRfPngt,5G7MRfPngt,3468,VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought,"Large-scale generative language and vision-language models (LLMs and VLMs) excel in few-shot in-context learning for decision making and instruction following. However, they require high-quality exemplar demonstrations to be included in their context window. In this work, we ask: Can LLMs and VLMs generate their own examples from generic, sub-optimal demonstrations? We propose In-Context Abstraction Learning (ICAL), a method that builds a memory of multimodal experience from sub-optimal demonstrations and human feedback. Given a task demonstration that may contain inefficiencies or mistakes, a VLM abstracts the trajectory into a generalized program by correcting inefficient actions and annotating cognitive abstractions: causal relationships, object state changes, temporal subgoals, and task-relevant visual elements. These abstractions are iteratively improved and adapted through human feedback while the agent attempts to execute the trajectory in a similar environment. The resulting examples, when used as exemplars in the prompt, significantly improve decision-making in retrieval-augmented LLM and VLM agents. Moreover, as the agent's library of examples grows, it becomes more efficient, relying less on human feedback and requiring fewer environment interactions per demonstration. Our ICAL agent surpasses the state-of-the-art in dialogue-based instruction following in TEACh, multimodal web agents in VisualWebArena, and action anticipation in Ego4D. In TEACh, we achieve a 12.6% improvement in goal-condition success. In VisualWebArena, our task success rate improves over the SOTA from 14.3% to 22.7% using GPT4V. In Ego4D action forecasting, we improve over few-shot GPT-4V and remain competitive with supervised models. We show finetuning our retrieval-augmented in-context agent yields additional improvements. Our approach significantly reduces reliance on manual prompt engineering and consistently outperforms in-context learning from action plans that lack such abstractions.",Gabriel Herbert Sarch; Lawrence Jang; Michael J. Tarr; William W. Cohen; Kenneth Marino; Katerina Fragkiadaki,~Gabriel_Herbert_Sarch1; ~Lawrence_Jang1; ~Michael_J._Tarr1; ~William_W._Cohen2; ~Kenneth_Marino1; ~Katerina_Fragkiadaki1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,human-AI_interaction,/pdf/5e9a92d28e4a08ae32f2c2c3ade645443ae537cb.pdf,2024-05-09T20:23:55.100000,2024-09-25T18:08:41.723000,2024-11-06T06:17:46.589000,https://openreview.net/forum?id=5G7MRfPngt,Microsoft; Carnegie Mellon University; Microsoft; Carnegie Mellon University; Carnegie Mellon University; Google; Carnegie Mellon University; Google; Carnegie Mellon University
3344,dB99jjwx3h,dB99jjwx3h,3446,Learning Linear Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity,"We study causal representation learning, the task of recovering high-level latent variables and their causal relationships in the form of a causal graph from low-level observed data (such as text and images), assuming access to observations generated from multiple environments. Prior results on the identifiability of causal representations typically assume access to single-node interventions which is rather unrealistic in practice, since the latent variables are unknown in the first place. In this work, we consider the task of learning causal representation learning with data collected from general environments. We show that even when the causal model and the mixing function are both linear, there exists a surrounded-node ambiguity (SNA) [Varici et al. 2023] which is basically unavoidable in our setting. On the other hand, in the same linear case, we show that identification up to SNA is possible under mild conditions, and propose an algorithm, LiNGCReL which provably achieves such identifiability guarantee. We conduct extensive experiments on synthetic data and demonstrate the effectiveness of LiNGCReL in the finite-sample regime.",Jikai Jin; Vasilis Syrgkanis,~Jikai_Jin1; ~Vasilis_Syrgkanis1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,causal_inference,/pdf/74d27afd65951da6e78b44c5d96eec4742bbfc47.pdf,2024-05-09T18:58:16.482000,2024-09-25T18:08:41.031000,2024-11-06T06:17:46.343000,https://openreview.net/forum?id=dB99jjwx3h,Stanford University; Stanford University
3350,Vi8AepAXGy,Vi8AepAXGy,3429,"Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs","We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a vision-centric approach. While stronger language models can enhance multimodal capabilities, the design choices for vision components are often insufficiently explored and disconnected from visual representation learning research. This gap hinders accurate sensory grounding in real-world scenarios. Our study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures—self-supervised, strongly supervised, or combinations thereof—based on experiments with over 15 vision models. We critically examine existing MLLM benchmarks, addressing the difficulties involved in consolidating and interpreting results from various tasks. To further improve visual grounding, we propose spatial vision aggregator (SVA), a dynamic and spatially-aware connector that integrates vision features with LLMs while reducing the number of tokens. Additionally, we discuss the curation of high-quality visual instruction-tuning data from publicly available sources, emphasizing the importance of distribution balancing. Collectively, Cambrian-1 not only achieves state-of-the-art performances but also serves as a comprehensive, open cookbook for instruction-tuned MLLMs. We provide model weights, code, supporting tools, datasets, and detailed instruction-tuning and evaluation recipes. We hope our release will inspire and accelerate advancements in multimodal systems and visual representation learning.",Shengbang Tong; Ellis L Brown II; Penghao Wu; Sanghyun Woo; ADITHYA JAIRAM IYER; Sai Charitha Akula; Shusheng Yang; Jihan Yang; Manoj Middepogu; Ziteng Wang; Xichen Pan; Rob Fergus; Yann LeCun; Saining Xie,~Shengbang_Tong1; ~Ellis_L_Brown_II1; ~Penghao_Wu1; ~Sanghyun_Woo1; ~ADITHYA_JAIRAM_IYER1; ~Sai_Charitha_Akula1; ~Shusheng_Yang1; ~Jihan_Yang1; ~Manoj_Middepogu1; ~Ziteng_Wang5; ~Xichen_Pan1; ~Rob_Fergus1; ~Yann_LeCun1; ~Saining_Xie2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_vision,/pdf/e8505e32b71e0eb67d3c8add2c07bc6210f2987d.pdf,2024-05-09T17:32:35.278000,2024-09-25T18:08:40.186000,2025-01-17T22:39:15.966000,https://openreview.net/forum?id=Vi8AepAXGy,New York University; Allen Institute; New York University; New York University; Google; Morphic; New York University; New York University; New York University; University of Hong Kong; New York University; New York University; New York University; Meta; New York University; Google; New York University; Meta; New York University
3363,PfOeAKxx6i,PfOeAKxx6i,3373,Algebraic Positional Encodings,"We introduce a novel positional encoding strategy for Transformer-style models, addressing the shortcomings of existing, often ad hoc, approaches. Our framework implements a flexible mapping from the algebraic specification of a domain to a positional encoding scheme where positions are interpreted as orthogonal operators. This design preserves the structural properties of the source domain, thereby ensuring that the end-model upholds them. The framework can accommodate various structures, including sequences, grids and trees, but also their compositions. We conduct a series of experiments demonstrating the practical applicability of our method. Our results suggest performance on par with or surpassing the current state of the art, without hyper-parameter optimizations or ``task search'' of any kind.
Code is available through https://aalto-quml.github.io/ape/.",Konstantinos Kogkalidis; Jean-Philippe Bernardy; Vikas Garg,~Konstantinos_Kogkalidis1; ~Jean-Philippe_Bernardy1; ~Vikas_Garg2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/60c8e2100fabff13149d679367427e8c15c2c4b8.pdf,2024-05-09T14:25:35.373000,2024-09-25T18:08:37.601000,2025-01-15T10:38:54.982000,https://openreview.net/forum?id=PfOeAKxx6i,Aalto University
3372,ktpG37Dzh5,ktpG37Dzh5,3321,BMRS: Bayesian Model Reduction for Structured Pruning,"Modern neural networks are often massively overparameterized leading to high compute costs during training and at inference. One effective method to improve both the compute and energy efficiency of neural networks while maintaining good performance is structured pruning, where full network structures (e.g. neurons or convolutional filters) that have limited impact on the model output are removed. In this work, we propose Bayesian Model Reduction for Structured pruning (BMRS), a fully end-to-end Bayesian method of structured pruning. BMRS is based on two recent methods: Bayesian structured pruning with multiplicative noise, and Bayesian model reduction (BMR), a method which allows efficient comparison of Bayesian models under a change in prior. We present two realizations of BMRS derived from different priors which yield different structured pruning characteristics:  1) BMRS_N with the truncated log-normal prior, which offers reliable compression rates and accuracy without the need for tuning any thresholds and 2) BMRS_U with the truncated log-uniform prior that can achieve more aggressive compression based on the boundaries of truncation. Overall, we find that BMRS offers a theoretically grounded approach to structured pruning of neural networks yielding both high compression rates and accuracy. Experiments on multiple datasets and neural networks of varying complexity showed that the two BMRS methods offer a competitive performance-efficiency trade-off compared to other pruning methods.",Dustin Wright; Christian Igel; Raghavendra Selvan,~Dustin_Wright2; ~Christian_Igel1; ~Raghavendra_Selvan1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/4d318f245a9a2a2e0fd394f7f7b3c91bdb084724.pdf,2024-05-09T13:06:39.944000,2024-09-25T18:08:36.390000,2024-11-06T06:17:45.139000,https://openreview.net/forum?id=ktpG37Dzh5,University of Copenhagen; University of Copenhagen; University of Copenhagen
3374,D4yRz3s7UL,D4yRz3s7UL,3314,DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms,"Vision transformers have shown remarkable advancements in the computer vision domain, demonstrating state-of-the-art performance in diverse tasks (e.g., image classification, object detection). However, their high computational requirements grow quadratically with the number of tokens used. Token sparsification mechanisms have been proposed to address this issue. These mechanisms employ an input-dependent strategy, in which uninformative tokens are discarded from the computation pipeline, improving the model’s efficiency. However, their dynamism and average-case assumption makes them vulnerable to a new threat vector – carefully crafted adversarial examples capable of fooling the sparsification mechanism, resulting in worst-case performance. In this paper, we present DeSparsify, an attack targeting the availability of vision transformers that use token sparsification mechanisms. The attack aims to exhaust the operating system’s resources, while maintaining its stealthiness. Our evaluation demonstrates the attack’s effectiveness on three token sparsification mechanisms and examines the attack’s transferability between them and its effect on the GPU resources. To mitigate the impact of the attack, we propose various countermeasures.",Oryan Yehezkel; Alon Zolfi; Amit Baras; Yuval Elovici; Asaf Shabtai,~Oryan_Yehezkel1; ~Alon_Zolfi1; ~Amit_Baras2; ~Yuval_Elovici1; ~Asaf_Shabtai1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/a670025a9c78bd2f36bec60a4890132699bd515f.pdf,2024-05-09T12:59:08.214000,2024-09-25T18:08:36.289000,2024-11-06T06:17:45.089000,https://openreview.net/forum?id=D4yRz3s7UL,Ben-Gurion University of the Negev; Ben-Gurion University of the Negev
3384,jYypS5VIPj,jYypS5VIPj,3257,Bridge the Points: Graph-based Few-shot Segment Anything Semantically,"The recent advancements in large-scale pre-training techniques have significantly enhanced the capabilities of vision foundation models, notably the Segment Anything Model (SAM), which can generate precise masks based on point and box prompts. Recent studies extend SAM to Few-shot Semantic Segmentation (FSS), focusing on prompt generation for SAM-based automatic semantic segmentation. However, these methods struggle with selecting suitable prompts, require specific hyperparameter settings for different scenarios, and experience prolonged one-shot inference times due to the overuse of SAM, resulting in low efficiency and limited automation ability. To address these issues, we propose a simple yet effective approach based on graph analysis. In particular, a Positive-Negative Alignment module dynamically selects the point prompts for generating masks, especially uncovering the potential of the background context as the negative reference. Another subsequent Point-Mask Clustering module aligns the granularity of masks and selected points as a directed graph, based on mask coverage over points. These points are then aggregated by decomposing the weakly connected components of the directed graph in an efficient manner, constructing distinct natural clusters. Finally, the positive and overshooting gating, benefiting from graph-based granularity alignment, aggregates high-confident masks and filters the false-positive masks for final prediction, reducing the usage of additional hyperparameters and redundant mask generation. Extensive experimental analysis across standard FSS, One-shot Part Segmentation, and Cross Domain FSS datasets validate the effectiveness and efficiency of the proposed approach, surpassing state-of-the-art generalist models with a mIoU of 58.7% on COCO-20i and 35.2% on LVIS-92i. The project page of this work is https://andyzaq.github.io/GF-SAM/.",Anqi Zhang; Guangyu Gao; Jianbo Jiao; Chi Harold Liu; Yunchao Wei,~Anqi_Zhang2; ~Guangyu_Gao2; ~Jianbo_Jiao2; ~Chi_Harold_Liu1; ~Yunchao_Wei1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/079fc6b64dad865cb98866238ab263d437333a2c.pdf,2024-05-09T09:50:31.710000,2024-09-25T18:08:34.597000,2024-11-06T06:17:44.702000,https://openreview.net/forum?id=jYypS5VIPj,Beijing Institute of Technology; Beijing Institute of Technology; University of Birmingham; Beijing Institute of Technology; Beijing Jiaotong University
3394,ZgtLQQR1K7,ZgtLQQR1K7,3213,VMamba: Visual State Space Model,"Designing computationally efficient network architectures remains an ongoing necessity in computer vision. In this paper, we adapt Mamba, a state-space language model, into VMamba, a vision backbone with linear time complexity. At the core of VMamba is a stack of Visual State-Space (VSS) blocks with the 2D Selective Scan (SS2D) module. By traversing along four scanning routes, SS2D bridges the gap between the ordered nature of 1D selective scan and the non-sequential structure of 2D vision data, which facilitates the collection of contextual information from various sources and perspectives. Based on the VSS blocks, we develop a family of VMamba architectures and accelerate them through a succession of architectural and implementation enhancements. Extensive experiments demonstrate VMamba’s
 promising performance across diverse visual perception tasks, highlighting its superior input scaling efficiency compared to existing benchmark models. Source code is available at https://github.com/MzeroMiko/VMamba",Yue Liu; Yunjie Tian; Yuzhong Zhao; Hongtian Yu; Lingxi Xie; Yaowei Wang; Qixiang Ye; Jianbin Jiao; Yunfan Liu,~Yue_Liu19; ~Yunjie_Tian1; ~Yuzhong_Zhao1; ~Hongtian_Yu1; ~Lingxi_Xie1; ~Yaowei_Wang1; ~Qixiang_Ye1; ~Jianbin_Jiao1; ~Yunfan_Liu3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/496ccac4131e6ee0bc83b0ca167de274006e7b1a.pdf,2024-05-09T08:29:49.417000,2024-09-25T18:08:33.185000,2024-12-29T08:45:32.440000,https://openreview.net/forum?id=ZgtLQQR1K7,"University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; State University of New York, Buffalo; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Huawei Technologies Research & Development (UK) Ltd; Beijing Institute of Technology; Peng Cheng Laboratory; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences"
3436,NKzLqRgG45,NKzLqRgG45,2982,Parameter-Inverted Image Pyramid Networks,"Image pyramids are commonly used in modern computer vision tasks to obtain multi-scale features for precise understanding of images. However, image pyramids process multiple resolutions of images using the same large-scale model, which requires significant computational cost. To overcome this issue, we propose a novel network architecture known as the Parameter-Inverted Image Pyramid Networks (PIIP). Our core idea is to use models with different parameter sizes to process different resolution levels of the image pyramid, thereby balancing computational efficiency and performance. Specifically, the input to PIIP is a set of multi-scale images, where higher resolution images are processed by smaller networks. We further propose a feature interaction mechanism to allow features of different resolutions to complement each other and effectively integrate information from different spatial scales. Extensive experiments demonstrate that the PIIP achieves superior performance in tasks such as object detection, segmentation, and image classification, compared to traditional image pyramid methods and single-branch networks, while reducing computational cost. Notably, when applying our method on a large-scale vision foundation model InternViT-6B, we improve its performance by 1\%-2\% on detection and segmentation with only 40\%-60\% of the original computation. These results validate the effectiveness of the PIIP approach and provide a new technical direction for future vision computing tasks.",Xizhou Zhu; Xue Yang; Zhaokai Wang; Hao Li; Wenhan Dou; Junqi Ge; Lewei Lu; Yu Qiao; Jifeng Dai,~Xizhou_Zhu1; ~Xue_Yang2; ~Zhaokai_Wang1; ~Hao_Li13; ~Wenhan_Dou1; ~Junqi_Ge1; ~Lewei_Lu1; ~Yu_Qiao1; ~Jifeng_Dai1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/c7ff3c70653922b42ef92a6995a611c1fe80aa50.pdf,2024-05-08T20:13:25.360000,2024-09-25T18:08:26.927000,2024-12-25T12:40:08.776000,https://openreview.net/forum?id=NKzLqRgG45,"Shanghai Artificial Intelligence Laboratory; Tsinghua University, Beijing; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; Shanghai Jiao Tong University; Chinese University of Hong Kong; Tsinghua University, Beijing; Tsinghua University, Beijing; SenseTime Research; SenseTime Research; Shanghai Artificial Intelligence Laboratory; Tsinghua University, Beijing"
3437,5l5bhYexYO,5l5bhYexYO,2981,Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers,"Decision Transformers have recently emerged as a new and compelling paradigm for offline Reinforcement Learning (RL), completing a trajectory in an autoregressive way. While improvements have been made to overcome  initial shortcomings, online finetuning of decision transformers has been surprisingly under-explored. The widely adopted state-of-the-art Online Decision Transformer (ODT) still struggles when pretrained with low-reward offline data. In this paper, we theoretically analyze the online-finetuning of the decision transformer,  showing that the commonly used Return-To-Go (RTG) that's far from the expected return hampers the online fine-tuning process. This problem, however, is well-addressed by the value function and advantage of standard RL algorithms. As suggested by our analysis, in our experiments, we hence find that simply adding TD3 gradients to the finetuning process of ODT effectively improves the online finetuning performance of ODT, especially if ODT is pretrained with low-reward offline data. These findings provide new directions to further improve decision transformers.",Kai Yan; Alex Schwing; Yu-Xiong Wang,~Kai_Yan1; ~Alex_Schwing1; ~Yu-Xiong_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/ecce2f00d7d353921acab4fa6ec0c37938a55c2a.pdf,2024-05-08T20:06:01.653000,2024-09-25T18:08:26.865000,2024-11-06T06:17:42.502000,https://openreview.net/forum?id=5l5bhYexYO,"Department of Computer Science, University of Illinois at Urbana Champaign; Department of Computer Science, University of Illinois at Urbana Champaign"
3441,URyeU8mwz1,URyeU8mwz1,2972,The Value of Reward Lookahead in Reinforcement Learning,"In reinforcement learning (RL), agents sequentially interact with changing environments while aiming to maximize the obtained rewards. Usually, rewards are observed only _after_ acting, and so the goal is to maximize the _expected_ cumulative reward. Yet, in many practical settings, reward information is observed in advance -- prices are observed before performing transactions; nearby traffic information is partially known; and goals are oftentimes given to agents prior to the interaction. In this work, we aim to quantifiably analyze the value of such future reward information through the lens of _competitive analysis. In particular, we measure the ratio between the value of standard RL agents and that of agents with partial future-reward lookahead. We characterize the worst-case reward distribution and derive exact ratios for the worst-case reward expectations. Surprisingly, the resulting ratios relate to known quantities in offline RL and reward-free exploration. We further provide tight bounds for the ratio given the worst-case dynamics. Our results cover the full spectrum between observing the immediate rewards before acting to observing all the rewards before the interaction starts.",Nadav Merlis; Dorian Baudry; Vianney Perchet,~Nadav_Merlis1; ~Dorian_Baudry1; ~Vianney_Perchet3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/e0663efe7780a95dd320d2a3e73ed3f12cf8fad9.pdf,2024-05-08T19:25:56.600000,2024-09-25T18:08:26.493000,2024-11-06T06:17:42.375000,https://openreview.net/forum?id=URyeU8mwz1,Ecole Nationale de la Statistique et de l'Administration Economique; Ecole Nationale de la Statistique et de l'Administration Economique; University of Oxford
3445,EKdk4vxKO4,EKdk4vxKO4,2959,MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making,"Foundation models are becoming valuable tools in medicine. Yet despite their promise, the best way to leverage Large Language Models (LLMs) in complex medical tasks remains an open question. We introduce a novel multi-agent framework, named **M**edical **D**ecision-making **Agents** (**MDAgents**) that helps to address this gap by automatically assigning a collaboration structure to a team of LLMs. The assigned solo or group collaboration structure is tailored to the medical task at hand, a simple emulation inspired by the way real-world medical decision-making processes are adapted to tasks of different complexities. We evaluate our framework and baseline methods using state-of-the-art LLMs across a suite of real-world medical knowledge and clinical diagnosis benchmarks, including a comparison of
LLMs’ medical complexity classification against human physicians. MDAgents achieved the **best performance in seven out of ten** benchmarks on tasks requiring an understanding of medical knowledge and multi-modal reasoning, showing a significant **improvement of up to 4.2\%** ($p$ < 0.05) compared to previous methods' best performances. Ablation studies reveal that MDAgents effectively determines medical complexity to optimize for efficiency and accuracy across diverse medical tasks. Notably, the combination of moderator review and external medical knowledge in group collaboration resulted in an average accuracy **improvement of 11.8\%**. Our code can be found at https://github.com/mitmedialab/MDAgents.",Yubin Kim; Chanwoo Park; Hyewon Jeong; Yik Siu Chan; Xuhai Xu; Daniel McDuff; Hyeonhoon Lee; Marzyeh Ghassemi; Cynthia Breazeal; Hae Won Park,~Yubin_Kim2; ~Chanwoo_Park2; ~Hyewon_Jeong1; ~Yik_Siu_Chan1; ~Xuhai_Xu1; ~Daniel_McDuff1; ~Hyeonhoon_Lee1; ~Marzyeh_Ghassemi2; ~Cynthia_Breazeal1; ~Hae_Won_Park1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_learning_for_healthcare,/pdf/9993edbaf6679577c07aeae6b39fe0a546abaca1.pdf,2024-05-08T18:31:50.262000,2024-09-25T18:08:26.058000,2024-11-06T06:17:42.232000,https://openreview.net/forum?id=EKdk4vxKO4,Massachusetts Institute of Technology; Apple; Massachusetts Institute of Technology; Brown University; Wellesley College; Massachusetts Institute of Technology; Google; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Amazon; Massachusetts Institute of Technology
3448,StapcUWm9q,StapcUWm9q,2944,Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement,"Disentangled representation learning strives to extract the intrinsic factors within the observed data. Factoring these representations in an unsupervised manner is notably challenging and usually requires tailored loss functions or specific structural designs. In this paper, we introduce a new perspective and framework, demonstrating that diffusion models with cross-attention itself can serve as a powerful inductive bias to facilitate the learning of disentangled representations. We propose to encode an image into a set of concept tokens and treat them as the condition of the latent diffusion model for image reconstruction, where cross attention over the concept tokens is used to bridge the encoder and the U-Net of the diffusion model. We analyze that the diffusion process inherently possesses the time-varying information bottlenecks. Such information bottlenecks and cross attention act as strong inductive biases for promoting disentanglement. Without any regularization term in the loss function, this framework achieves superior disentanglement performance on the benchmark datasets, surpassing all previous methods with intricate designs. We have conducted comprehensive ablation studies and visualization analyses, shedding a light on the functioning of this model. We anticipate that our findings will inspire more investigation on exploring diffusion model for disentangled representation learning towards more sophisticated data analysis and understanding.",Tao Yang; Cuiling Lan; Yan Lu; Nanning Zheng,~Tao_Yang9; ~Cuiling_Lan1; ~Yan_Lu7; ~Nanning_Zheng1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/6f069051c5995c719f953ebe412454ae4af0e218.pdf,2024-05-08T17:33:15.300000,2024-09-25T18:08:25.829000,2024-12-19T02:48:28.692000,https://openreview.net/forum?id=StapcUWm9q,Microsoft; ByteDance Inc.; Ubiquant Inc.; Xi'an Jiaotong University; Microsoft; Microsoft; Xi'an Jiaotong University
3455,JDAQwysFOc,JDAQwysFOc,2901,Non-convolutional graph neural networks.,"Rethink convolution-based graph neural networks (GNN)---they characteristically suffer from limited expressiveness, over-smoothing, and over-squashing, and require specialized sparse kernels for efficient computation.
Here, we design a simple graph learning module entirely free of convolution operators, coined _random walk with unifying memory_ (RUM) neural network, where an RNN merges the topological and semantic graph features along the random walks terminating at each node.
Relating the rich literature on RNN behavior and graph topology, we theoretically show and experimentally verify that RUM attenuates the aforementioned symptoms and is more expressive than the Weisfeiler-Lehman (WL) isomorphism test.
On a variety of node- and graph-level classification and regression tasks, RUM not only achieves competitive performance, but is also robust, memory-efficient, scalable, and faster than the simplest convolutional GNNs.",Yuanqing Wang; Kyunghyun Cho,~Yuanqing_Wang1; ~Kyunghyun_Cho1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,graph_neural_networks,/pdf/2870a95d2bd1d0d70140159f1050e6493384f783.pdf,2024-05-08T14:46:30.319000,2024-09-25T18:08:24.340000,2024-11-06T06:17:41.846000,https://openreview.net/forum?id=JDAQwysFOc,New York University; Genentech
3456,N12B6wvA55,N12B6wvA55,2898,Mirror and Preconditioned Gradient Descent in Wasserstein Space,"As the problem of minimizing functionals on the Wasserstein space encompasses many applications in machine learning, different optimization algorithms on $\mathbb{R}^d$ have received their counterpart analog on the Wasserstein space. We focus here on lifting two explicit algorithms: mirror descent and preconditioned gradient descent. These algorithms have been introduced to better capture the geometry of the function to minimize and are provably convergent under appropriate (namely relative) smoothness and convexity conditions. Adapting these notions to the Wasserstein space, we prove guarantees of convergence of some Wasserstein-gradient-based discrete-time schemes for new pairings of objective functionals and regularizers. The difficulty here is to carefully select along which curves the functionals should be smooth and convex. We illustrate the advantages of adapting the geometry induced by the regularizer on ill conditioned optimization tasks, and showcase the improvement of choosing different discrepancies and geometries in a computational biology task of aligning single-cells.",Clément Bonet; Théo Uscidda; Adam David; Pierre-Cyril Aubin-Frankowski; Anna Korba,~Clément_Bonet1; ~Théo_Uscidda1; ~Adam_David1; ~Pierre-Cyril_Aubin-Frankowski1; ~Anna_Korba2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/221caa4fc808b48dde462c74cfa2826b15f837b3.pdf,2024-05-08T14:38:01.623000,2024-09-25T18:08:24.228000,2024-11-06T06:17:41.795000,https://openreview.net/forum?id=N12B6wvA55,Ecole Nationale de la Statistique et de l'Administration Economique; Helmholtz Center CISPA for Information Security; Ecole Nationale de la Statistique et de l'Administration Economique; Institut Polytechnique de Paris
3465,A5pabdZp2F,A5pabdZp2F,2833,MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities,"Detecting out-of-distribution (OOD) samples is important for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. Existing research has mainly focused on unimodal scenarios on image data. However, real-world applications are inherently multimodal, which makes it essential to leverage information from multiple modalities to enhance the efficacy of OOD detection. To establish a foundation for more realistic Multimodal OOD Detection, we introduce the first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes and varying modality combinations. We first evaluate existing unimodal OOD detection algorithms on MultiOOD, observing that the mere inclusion of additional modalities yields substantial improvements. This underscores the importance of utilizing multiple modalities for OOD detection. Based on the observation of Modality Prediction Discrepancy between in-distribution (ID) and OOD data, and its strong correlation with OOD performance, we propose the Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during training. Moreover, we introduce a novel outlier synthesis method, NP-Mix, which explores broader feature spaces by leveraging the information from nearest neighbor classes and complements A2D to strengthen OOD detection performance. Extensive experiments on MultiOOD demonstrate that training with A2D and NP-Mix improves existing OOD detection algorithms by a large margin. To support accessibility and reproducibility, our source code and MultiOOD benchmark are available at https://github.com/donghao51/MultiOOD.",Hao Dong; Yue Zhao; Eleni Chatzi; Olga Fink,~Hao_Dong4; ~Yue_Zhao13; ~Eleni_Chatzi1; ~Olga_Fink1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,safety_in_machine_learning,/pdf/9d70465c6462352f6d0ba5d124979dd81b7f1cd0.pdf,2024-05-08T11:52:29.775000,2024-09-25T18:08:22.259000,2024-11-06T06:17:41.479000,https://openreview.net/forum?id=A5pabdZp2F,ETH Zurich; University of Southern California; ETH Zurich; EPFL - EPF Lausanne
3477,gkJ5nBIOU4,gkJ5nBIOU4,2783,Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity,"Effective communication between the server and workers plays a key role in distributed optimization. In this paper, we focus on optimizing communication, uncovering inefficiencies in prevalent downlink compression approaches. Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors. Theoretical analysis demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms. We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression: we introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number of workers increases. Theoretical findings align closely with empirical experiments, underscoring the efficiency of the proposed algorithms.",Kaja Gruntkowska; Alexander Tyurin; Peter Richtárik,~Kaja_Gruntkowska1; ~Alexander_Tyurin1; ~Peter_Richtárik1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/cb3ca819fc13ff5359da94f4be5db2b63f12d5a2.pdf,2024-05-08T09:43:42.627000,2024-09-25T18:08:20.148000,2024-11-06T06:17:40.953000,https://openreview.net/forum?id=gkJ5nBIOU4,King Abdullah University of Science and Technology; The Skolkovo Institute of Science and Technology; AIRI; King Abdullah University of Science and Technology; King Abdullah University of Science and Technology
3479,36tMV15dPO,36tMV15dPO,2779,X-Ray: A Sequential 3D Representation For Generation,"We introduce X-Ray, a novel 3D sequential representation inspired by the penetrability of x-ray scans. X-Ray transforms a 3D object into a series of surface frames at different layers, making it suitable for generating 3D models from images. Our method utilizes ray casting from the camera center to capture geometric and textured details, including depth, normal, and color, across all intersected surfaces. This process efficiently condenses the whole 3D object into a multi-frame video format, motivating the utilize of a network architecture similar to those in video diffusion models. This design ensures an efficient 3D representation by focusing solely on surface information. Also, we propose a two-stage pipeline to generate 3D objects from X-Ray Diffusion Model and Upsampler. We demonstrate the practicality and adaptability of our X-Ray representation by synthesizing the complete visible and hidden surfaces of a 3D object from a single input image. Experimental results reveal the state-of-the-art superiority of our representation in enhancing the accuracy of 3D generation, paving the way for new 3D representation research and practical applications. 
Our project page is in \url{https://tau-yihouxiang.github.io/projects/X-Ray/X-Ray.html}.",Tao Hu; Wenhang Ge; Yuyang Zhao; Gim Hee Lee,~Tao_Hu1; ~Wenhang_Ge1; ~Yuyang_Zhao1; ~Gim_Hee_Lee1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/d0b1e685a6f22e29758764fc397575a3bd457ebe.pdf,2024-05-08T09:21:41.349000,2024-09-25T18:08:19.983000,2024-11-06T06:17:40.867000,https://openreview.net/forum?id=36tMV15dPO,National University of Singapore; Hong Kong University of Science and Technology(Guangzhou); National University of Singapore; National University of Singapore
3500,BFWdIPPLgZ,BFWdIPPLgZ,2683,A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention,"Many empirical studies have provided evidence for the emergence of algorithmic mechanisms (abilities) in the learning of language models, that lead to qualitative improvements of the model capabilities. Yet, a theoretical characterization of how such mechanisms emerge remains elusive. In this paper, we take a step in this direction by providing a tight theoretical analysis of the emergence of semantic attention in a solvable model of dot-product attention. More precisely, we consider a non-linear self-attention layer with trainable tied and low-rank query and key matrices. In the asymptotic limit of high-dimensional data and a comparably large number of training samples we provide a tight closed-form characterization of the global minimum of the non-convex empirical loss landscape. We show that this minimum corresponds to either a positional attention mechanism (with tokens attending to each other based on their respective positions) or a semantic attention mechanism (with tokens attending to each other based on their meaning), and evidence an emergent phase transition from the former to the latter with increasing sample complexity. Finally, we compare the dot-product attention layer to a linear positional baseline, and show that it outperforms the latter using the semantic mechanism provided it has access to sufficient data.",Hugo Cui; Freya Behrens; Florent Krzakala; Lenka Zdeborova,~Hugo_Cui1; ~Freya_Behrens1; ~Florent_Krzakala1; ~Lenka_Zdeborova1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/411f5d2e925c9100cd435ceb6cd2b1badcbe1f52.pdf,2024-05-08T05:52:33.608000,2024-09-25T18:08:17.514000,2024-11-06T06:17:40.010000,https://openreview.net/forum?id=BFWdIPPLgZ,EPFL - EPF Lausanne; Harvard University; EPFL - EPF Lausanne; EPFL - EPF Lausanne; EPFL - EPF Lausanne
3525,cfrDLD1wfO,cfrDLD1wfO,2570,Graph Diffusion Transformers for Multi-Conditional Molecular Generation,"Inverse molecular design with diffusion models holds great potential for advancements in material and drug discovery. Despite success in unconditional molecule generation, integrating multiple properties such as synthetic score and gas permeability as condition constraints into diffusion models remains unexplored. We present the Graph Diffusion Transformer (Graph DiT) for multi-conditional molecular generation. Graph DiT has a condition encoder to learn the representation of numerical and categorical properties and utilizes a Transformer-based graph denoiser to achieve molecular graph denoising under conditions. Unlike previous graph diffusion models that add noise separately on the atoms and bonds in the forward diffusion process, we propose a graph-dependent noise model for training Graph DiT, designed to accurately estimate graph-related noise in molecules. We extensively validate the Graph DiT for multi-conditional polymer and small molecule generation. Results demonstrate our superiority across metrics from distribution learning to condition control for molecular properties. A polymer inverse design task for gas separation with feedback from domain experts further demonstrates its practical utility. The code is available at https://github.com/liugangcode/Graph-DiT.",Gang Liu; Jiaxin Xu; Tengfei Luo; Meng Jiang,~Gang_Liu6; ~Jiaxin_Xu1; ~Tengfei_Luo1; ~Meng_Jiang3,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_learning_for_physical_sciences,/pdf/46c02e1bf7e313ee41cca4c78d39825812de8c3d.pdf,2024-05-07T16:40:41.644000,2024-09-25T18:08:13.911000,2024-11-06T06:17:39.107000,https://openreview.net/forum?id=cfrDLD1wfO,University of Notre Dame; University of Notre Dame; University of Notre Dame
3526,zLClygeRK8,zLClygeRK8,2564,"Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning","This work investigates the offline formulation of the contextual bandit problem, where the goal is to leverage past interactions collected under a behavior policy to evaluate, select, and learn new, potentially better-performing, policies. Motivated by critical applications, we move beyond point estimators. Instead, we adopt the principle of _pessimism_ where we construct upper bounds that assess a policy's worst-case performance, enabling us to confidently select and learn improved policies. Precisely, we introduce novel, fully empirical concentration bounds for a broad class of importance weighting risk estimators. These bounds are general enough to cover most existing estimators and pave the way for the development of new ones. In particular, our pursuit of the tightest bound within this class motivates a novel estimator (LS), that _logarithmically smoothes_ large importance weights. The bound for LS is provably tighter than its competitors, and naturally results in improved policy selection and learning strategies. Extensive policy evaluation, selection, and learning experiments highlight the versatility and favorable performance of LS.",Otmane Sakhi; Imad Aouali; Pierre Alquier; Nicolas Chopin,~Otmane_Sakhi1; ~Imad_Aouali2; ~Pierre_Alquier1; ~Nicolas_Chopin1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/176852333e6e4a1430f1fe58cab4bcb648cf96b2.pdf,2024-05-07T16:19:57.268000,2024-09-25T18:08:13.745000,2024-11-06T06:17:39.061000,https://openreview.net/forum?id=zLClygeRK8,"Criteo; ESSEC Business School, Asia-Pacific campus; Ecole Nationale de la Statistique et de l'Administration Economique"
3527,rk2L9YGDi2,rk2L9YGDi2,2560,Sequoia: Scalable and Robust Speculative Decoding,"As the usage of large language models (LLMs) grows, it becomes increasingly important to serve them quickly and efficiently. While speculative decoding has recently emerged as a promising direction for accelerating LLM serving, existing methods are limited in their ability to scale to larger speculation budgets and adapt to different hyperparameters. This paper introduces Sequoia, a scalable and robust algorithm for speculative decoding. To improve scalability, Sequoia introduces a dynamic programming algorithm to find an optimal tree structure for the speculated tokens. To achieve robust speculative decoding, Sequoia uses a novel sampling and verification method that outperforms prior work across different decoding temperatures. Sequoia improves the decoding speed of Llama2-7B, Llama2-13B, and Vicuna-33B on an A100 GPU by up to $4.04\times$, $3.73\times$, and $2.27 \times$. To serve Llama3-70B-Instruct on a single L40 GPU through offloading, Sequoia reduces the per-token decoding latency to 0.60 s/token, $9.5\times$ faster than DeepSpeed-Zero-Inference.",Zhuoming Chen; Avner May; Ruslan Svirschevski; Yu-Hsun Huang; Max Ryabinin; Zhihao Jia; Beidi Chen,~Zhuoming_Chen1; ~Avner_May1; ~Ruslan_Svirschevski1; ~Yu-Hsun_Huang1; ~Max_Ryabinin1; ~Zhihao_Jia2; ~Beidi_Chen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/b37bd645defe5a17e94f0ba7ac5d5cb2c3db1b4f.pdf,2024-05-07T16:04:01.735000,2024-09-25T18:08:13.661000,2024-11-06T06:17:39.013000,https://openreview.net/forum?id=rk2L9YGDi2,Carnegie Mellon University; Together.ai; Yandex; Carnegie Mellon University; Together AI; Carnegie Mellon University; Meta; Carnegie Mellon University
3531,WyVTj77KEV,WyVTj77KEV,2529,Generalized Protein Pocket Generation with Prior-Informed Flow Matching,"Designing ligand-binding proteins, such as enzymes and biosensors, is essential in bioengineering and protein biology. One critical step in this process involves designing protein pockets, the protein interface binding with the ligand. Current approaches to pocket generation often suffer from time-intensive physical computations or template-based methods, as well as compromised generation quality due to the overlooking of domain knowledge. To tackle these challenges, we propose PocketFlow, a generative model that incorporates protein-ligand interaction priors based on flow matching. During training, PocketFlow learns to model key types of protein-ligand interactions, such as hydrogen bonds. In the sampling, PocketFlow leverages multi-granularity guidance (overall binding affinity and interaction geometry constraints) to facilitate generating high-affinity and valid pockets. Extensive experiments show that PocketFlow outperforms baselines on multiple benchmarks, e.g., achieving an average improvement of 1.29 in Vina Score and 0.05 in scRMSD. Moreover, modeling interactions make PocketFlow a generalized generative model across multiple ligand modalities, including small molecules, peptides, and RNA.",ZAIXI ZHANG; Marinka Zitnik; Qi Liu,~ZAIXI_ZHANG2; ~Marinka_Zitnik1; ~Qi_Liu3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/8e3258542a044155281d07e06f9bc062d4c9ec04.pdf,2024-05-07T13:52:17.457000,2024-09-25T18:08:12.803000,2024-11-06T06:17:38.871000,https://openreview.net/forum?id=WyVTj77KEV,Princeton University; University of Science and Technology of China; Harvard University; University of Science and Technology of China
3532,OJximyClit,OJximyClit,2527,Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting,"Vision-language models, such as CLIP, have shown impressive generalization capacities when using appropriate text descriptions. While optimizing prompts on downstream labeled data has proven effective in improving performance, these methods entail labor costs for annotations and are limited by their quality. Additionally, since CLIP is pre-trained on highly imbalanced Web-scale data, it suffers from inherent label bias that leads to suboptimal performance. 
 To tackle the above challenges, we propose a label-**F**ree p**ro**mpt distribution **l**earning and b**i**as **c**orrection framework, dubbed as **Frolic**, which boosts zero-shot performance without the need for labeled data. Specifically, our Frolic learns distributions over prompt prototypes to capture diverse visual representations and adaptively fuses these with the original CLIP through confidence matching.
This fused model is further enhanced by correcting label bias via a label-free logit adjustment. Notably, our method is not only training-free but also circumvents the necessity for hyper-parameter tuning. Extensive experimental results across 16 datasets demonstrate the efficacy of our approach, particularly outperforming the state-of-the-art by an average of $2.6\%$ on 10 datasets with CLIP ViT-B/16 and achieving an average margin of $1.5\%$ on ImageNet and its five distribution shifts with CLIP ViT-B/16. Codes are available in [https://github.com/zhuhsingyuu/Frolic](https://github.com/zhuhsingyuu/Frolic).",Xingyu Zhu; Beier Zhu; Yi Tan; Shuo Wang; Yanbin Hao; Hanwang Zhang,~Xingyu_Zhu3; ~Beier_Zhu1; ~Yi_Tan3; ~Shuo_Wang9; ~Yanbin_Hao1; ~Hanwang_Zhang3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/54c3f930bd6bd6781016e4f882d4e6d9e00ab910.pdf,2024-05-07T13:49:34.989000,2024-09-25T18:08:12.686000,2024-11-06T06:17:38.829000,https://openreview.net/forum?id=OJximyClit,University of Science and Technology of China; Nanyang Technological University; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; Nanyang Technological University
3563,x7pjdDod6Z,x7pjdDod6Z,2381,MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model,"Open-world 3D reconstruction models have recently garnered significant attention. However, without sufficient 3D inductive bias, existing methods typically entail expensive training costs and struggle to extract high-quality 3D meshes. In this work, we introduce MeshFormer, a sparse-view reconstruction model that explicitly leverages 3D native structure, input guidance, and training supervision. Specifically, instead of using a triplane representation, we store features in 3D sparse voxels and combine transformers with 3D convolutions to leverage an explicit 3D structure and projective bias. In addition to sparse-view RGB input, we require the network to take input and generate corresponding normal maps. The input normal maps can be predicted by 2D diffusion models, significantly aiding in the guidance and refinement of the geometry's learning. Moreover, by combining Signed Distance Function (SDF) supervision with surface rendering, we directly learn to generate high-quality meshes without the need for complex multi-stage training processes. By incorporating these explicit 3D biases, MeshFormer can be trained efficiently and deliver high-quality textured meshes with fine-grained geometric details. It can also be integrated with 2D diffusion models to enable fast single-image-to-3D and text-to-3D tasks. **Videos are available at https://meshformer3d.github.io/**",Minghua Liu; Chong Zeng; Xinyue Wei; Ruoxi Shi; Linghao Chen; Chao Xu; Mengqi Zhang; Zhaoning Wang; Xiaoshuai Zhang; Isabella Liu; Hongzhi Wu; Hao Su,~Minghua_Liu1; ~Chong_Zeng1; ~Xinyue_Wei1; ~Ruoxi_Shi1; ~Linghao_Chen2; ~Chao_Xu6; ~Mengqi_Zhang2; ~Zhaoning_Wang2; ~Xiaoshuai_Zhang1; ~Isabella_Liu1; ~Hongzhi_Wu1; ~Hao_Su1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_vision,/pdf/0137993914b1c34b105ba8ce5545d99389e3b12a.pdf,2024-05-07T05:38:32.325000,2024-09-25T18:08:08.948000,2024-11-06T06:17:37.622000,https://openreview.net/forum?id=x7pjdDod6Z,"Hillbot; University of California, San Diego; Zhejiang University; University of California, San Diego; University of California, San Diego; University of California, San Diego; Hillbot; Zhejiang University; Georgia Institute of Technology; Hillbot; University of Central Florida; Hillbot; University of California, San Diego; University of California, San Diego; Zhejiang University; University of California, San Diego"
3568,zGN0YWy2he,zGN0YWy2he,2335,Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation,"There has been exciting progress in generating images from natural language or layout conditions. However, these methods struggle to faithfully reproduce complex scenes due to the insufficient modeling of multiple objects and their relationships. To address this issue, we leverage the scene graph, a powerful structured representation, for complex image generation. Different from the previous works that directly use scene graphs for generation, we employ the generative capabilities of variational autoencoders and diffusion models in a generalizable manner, compositing diverse disentangled visual clues from scene graphs. Specifically, we first propose a Semantics-Layout Variational AutoEncoder (SL-VAE) to jointly derive (layouts, semantics) from the input scene graph, which allows a more diverse and reasonable generation in a one-to-many mapping. We then develop a Compositional Masked Attention (CMA) integrated with a diffusion model, incorporating (layouts, semantics) with fine-grained attributes as generation guidance. To further achieve graph manipulation while keeping the visual content consistent, we introduce a Multi-Layered Sampler (MLS) for an ""isolated"" image editing effect. Extensive experiments demonstrate that our method outperforms recent competitors based on text, layout, or scene graph, in terms of generation rationality and controllability.",Yunnan Wang; Ziqiang Li; Wenyao Zhang; Zequn Zhang; Baao Xie; Xihui Liu; Wenjun Zeng; Xin Jin,~Yunnan_Wang1; ~Ziqiang_Li3; ~Wenyao_Zhang1; ~Zequn_Zhang1; ~Baao_Xie3; ~Xihui_Liu1; ~Wenjun_Zeng3; ~Xin_Jin8,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/66bc4339c157f7e9cfc224307ac92ad79e98a4b8.pdf,2024-05-07T01:51:09.461000,2024-09-25T18:08:07.424000,2024-11-06T06:17:37.445000,https://openreview.net/forum?id=zGN0YWy2he,"Eastern Institute of Technology, Ningbo; Ant Group; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; University of Science and Technology of China; Ningbo Institute of Digital Twin; University of Hong Kong; Eastern Institute of Technology, Ningbo; Eastern Institute of Technology, Ningbo"
3578,kf80ZS3fVy,kf80ZS3fVy,2278,Towards Unified Multimodal Editing with Enhanced Knowledge Collaboration,"The swift advancement in Multimodal LLMs (MLLMs) also presents significant challenges for effective knowledge editing. Current methods, including intrinsic knowledge editing and external knowledge resorting, each possess strengths and weaknesses, struggling to balance the desired properties of reliability, generality, and locality when applied to MLLMs. In this paper, we propose \textbf{UniKE}, a novel multimodal editing method that establishes a unified perspective and paradigm for intrinsic knowledge editing and external knowledge resorting. Both types of knowledge are conceptualized as vectorized key-value memories, with the corresponding editing processes resembling the assimilation and accommodation phases of human cognition, conducted at the same semantic levels.  Within such a unified framework, we further promote knowledge collaboration by disentangling the knowledge representations into the semantic and truthfulness spaces. Extensive experiments validate the effectiveness of our method, which ensures that the post-edit MLLM simultaneously maintains excellent reliability, generality, and locality. The code for UniKE is available at https://github.com/beepkh/UniKE.",Kaihang Pan; Zhaoyu Fan; Juncheng Li; Qifan Yu; Hao Fei; Siliang Tang; Richang Hong; Hanwang Zhang; Qianru Sun,~Kaihang_Pan1; ~Zhaoyu_Fan1; ~Juncheng_Li3; ~Qifan_Yu1; ~Hao_Fei1; ~Siliang_Tang1; ~Richang_Hong1; ~Hanwang_Zhang3; ~Qianru_Sun2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/97d46003efdb73c62ba270d8ea1a2c70c2afea04.pdf,2024-05-06T17:08:27.839000,2024-09-25T18:08:05.743000,2024-11-06T06:17:37.077000,https://openreview.net/forum?id=kf80ZS3fVy,Zhejiang University; Zhejiang University; Zhejiang University; National University of Singapore; Zhejiang University; National University of Singapore; Zhejiang University; Hefei University of Technology; Nanyang Technological University; Singapore Management University
3594,gHYhVSCtDH,gHYhVSCtDH,2210,Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection,"Serialization-based methods, which serialize the 3D voxels and group them into multiple sequences before inputting to Transformers, have demonstrated their effectiveness in 3D object detection. However, serializing 3D voxels into 1D sequences will inevitably sacrifice the voxel spatial proximity. Such an issue is hard to be addressed by enlarging the group size with existing serialization-based methods due to the quadratic complexity of Transformers with feature sizes. Inspired by the recent advances of state space models (SSMs), we present a Voxel SSM, termed as Voxel Mamba, which employs a group-free strategy to serialize the whole space of voxels into a single sequence. The linear complexity of SSMs encourages our group-free design, alleviating the loss of spatial proximity of voxels. To further enhance the spatial proximity, we propose a Dual-scale SSM Block to establish a hierarchical structure, enabling a larger receptive field in the 1D serialization curve, as well as more complete local regions in 3D space. Moreover, we implicitly apply window partition under the group-free framework by positional encoding, which further enhances spatial proximity by encoding voxel positional information. Our experiments on Waymo Open Dataset and nuScenes dataset show that Voxel Mamba not only achieves higher accuracy than state-of-the-art methods, but also demonstrates significant advantages in computational efficiency. The source code is available at https://github.com/gwenzhang/Voxel-Mamba.",Guowen Zhang; Lue Fan; Chenhang HE; Zhen Lei; Zhaoxiang Zhang; Lei Zhang,~Guowen_Zhang1; ~Lue_Fan1; ~Chenhang_HE1; ~Zhen_Lei2; ~Zhaoxiang_Zhang3; ~Lei_Zhang2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/0cd37d7602d988cb025ea9d85f62abe79ef5139d.pdf,2024-05-06T11:36:09.671000,2024-09-25T18:08:03.873000,2024-11-06T06:17:36.414000,https://openreview.net/forum?id=gHYhVSCtDH,Hong Kong Polytechnic University; University of Chinese Academy of Sciences; Hong Kong Polytechnic University; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Hong Kong Polytechnic University
3612,i1xjK5a0X8,i1xjK5a0X8,2128,PCP-MAE: Learning to Predict Centers for Point Masked Autoencoders,"Masked autoencoder has been widely explored in point cloud self-supervised learning, whereby the point cloud is generally divided into visible and masked parts. These methods typically include an encoder accepting visible patches (normalized) and corresponding patch centers (position) as input, with the decoder accepting the output of the encoder and the centers (position) of the masked parts to reconstruct each point in the masked patches. Then, the pre-trained encoders are used for downstream tasks. In this paper, we show a motivating empirical result that when directly feeding the centers of masked patches to the decoder without information from the encoder, it still reconstructs well. In other words, the centers of patches are important and the reconstruction objective does not necessarily rely on representations of the encoder, thus preventing the encoder from learning semantic representations. Based on this key observation, we propose a simple yet effective method, $i.e.$, learning to \textbf{P}redict \textbf{C}enters for \textbf{P}oint \textbf{M}asked \textbf{A}uto\textbf{E}ncoders (\textbf{PCP-MAE}) which guides the model to learn to predict the significant centers and use the predicted centers to replace the directly provided centers. Specifically, we propose a Predicting Center Module (PCM) that shares parameters with the original encoder with extra cross-attention to predict centers. Our method is of high pre-training efficiency compared to other alternatives and achieves great improvement over Point-MAE, particularly surpassing it by \textbf{5.50\% on OBJ-BG, 6.03\% on OBJ-ONLY, and 5.17\% on PB-T50-RS} for 3D object classification on the ScanObjectNN dataset. The code is available at \url{https://github.com/aHapBean/PCP-MAE}.",Xiangdong Zhang; Shaofeng Zhang; Junchi Yan,~Xiangdong_Zhang3; ~Shaofeng_Zhang1; ~Junchi_Yan2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/b818d048207faef6da67184389f8afb17b0ec9c3.pdf,2024-05-06T07:44:54.077000,2024-09-25T18:08:01.753000,2024-11-06T06:17:35.496000,https://openreview.net/forum?id=i1xjK5a0X8,Shandong University; Shanghai Artificial Intelligence Laboratory; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University
3626,tnh4LK72yj,tnh4LK72yj,2077,Get Rid of Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework,"Spatiotemporal learning has become a pivotal technique to enable urban intelligence. Traditional spatiotemporal models mostly focus on a specific task by assuming a same distribution between training and testing sets. However, given that urban systems are usually dynamic, multi-sourced with imbalanced data distributions, current specific task-specific models fail to generalize to new urban conditions and adapt to new domains without explicitly modeling interdependencies across various dimensions and types of urban data. To this end, we argue that there is an essential to propose a Continuous Multi-task Spatio-Temporal learning framework (CMuST) to empower  collective urban intelligence, which  reforms the urban spatiotemporal learning from single-domain  to cooperatively multi-dimensional and multi-task learning. Specifically, CMuST proposes a new multi-dimensional spatiotemporal interaction network (MSTI) to allow cross-interactions between context and main observations as well as  self-interactions within spatial and temporal aspects  to be  exposed, which is also the core for capturing task-level commonality and personalization. To ensure continuous task learning, a novel Rolling Adaptation training scheme (RoAda) is devised, which not only preserves task uniqueness by constructing data summarization-driven task prompts, but also harnesses correlated patterns among tasks  by iterative model behavior modeling. We further establish a benchmark of three cities for multi-task spatiotemporal learning, and empirically demonstrate the superiority of CMuST via extensive evaluations on these datasets. The impressive improvements on both few-shot streaming data and new domain tasks against existing SOAT methods are achieved. Code is available at https://github.com/DILab-USTCSZ/CMuST.",Zhongchao Yi; Zhengyang Zhou; Qihe Huang; Yanjiang Chen; Liheng Yu; Xu Wang; Yang Wang,~Zhongchao_Yi1; ~Zhengyang_Zhou1; ~Qihe_Huang2; ~Yanjiang_Chen1; ~Liheng_Yu1; ~Xu_Wang16; ~Yang_Wang32,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_learning_for_other_sciences_and_fields,/pdf/97148ef3439d4c09aeb2847ed85a61ab7bd105d9.pdf,2024-05-06T03:47:39.278000,2024-09-25T18:08:00.168000,2024-12-21T03:19:46.833000,https://openreview.net/forum?id=tnh4LK72yj,University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China
3653,uwSaDHLlYc,uwSaDHLlYc,1946,Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment,"The sharp increase in data-related expenses has motivated research into condensing datasets while retaining the most informative features. Dataset distillation has thus recently come to the fore. This paradigm generates synthetic datasets that are representative enough to replace the original dataset in training a neural network. To avoid redundancy in these synthetic datasets, it is crucial that each element contains unique features and remains diverse from others during the synthesis stage. In this paper, we provide a thorough theoretical and empirical analysis of diversity within synthesized datasets. We argue that enhancing diversity can improve the parallelizable yet isolated synthesizing approach. Specifically, we introduce a novel method that employs dynamic and directed weight adjustment techniques to modulate the synthesis process, thereby maximizing the representativeness and diversity of each synthetic instance. Our method ensures that each batch of synthetic data mirrors the characteristics of a large, varying subset of the original dataset. Extensive experiments across multiple datasets, including CIFAR, Tiny-ImageNet, and ImageNet-1K, demonstrate the superior performance of our method, highlighting its effectiveness in producing diverse and representative synthetic datasets with minimal computational expense. Our code is available at https://github.com/AngusDujw/Diversity-Driven-Synthesis.",Jiawei Du; Xin Zhang; Juncheng Hu; Wenxin Huang; Joey Tianyi Zhou,~Jiawei_Du1; ~Xin_Zhang29; ~Juncheng_Hu1; ~Wenxin_Huang1; ~Joey_Tianyi_Zhou1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/15929c1e779391b46cb1e2a2780b2c8c2975171b.pdf,2024-05-05T09:52:27.045000,2024-09-25T18:07:56.288000,2024-11-19T01:42:38.439000,https://openreview.net/forum?id=uwSaDHLlYc,A*STAR; Xidian University; A*STAR; National University of Singapore; Northwestern Polytechnical University; Hubei University; A*STAR
3675,I6tBNcJE2F,I6tBNcJE2F,1840,Real-world Image Dehazing with Coherence-based Pseudo Labeling and Cooperative Unfolding Network,"Real-world Image Dehazing (RID) aims to alleviate haze-induced degradation in real-world settings. This task remains challenging due to the complexities in accurately modeling real haze distributions and the scarcity of paired real-world data. To address these challenges, we first introduce a cooperative unfolding network that jointly models atmospheric scattering and image scenes, effectively integrating physical knowledge into deep networks to restore haze-contaminated details. Additionally, we propose the first RID-oriented iterative mean-teacher framework, termed the Coherence-based Label Generator, to generate high-quality pseudo labels for network training. Specifically, we provide an optimal label pool to store the best pseudo-labels during network training, leveraging both global and local coherence to select high-quality candidates and assign weights to prioritize haze-free regions. We verify the effectiveness of our method, with experiments demonstrating that it achieves state-of-the-art performance on RID tasks. Code will be available at https://github.com/cnyvfang/CORUN-Colabator.",Chengyu Fang; Chunming He; Fengyang Xiao; Yulun Zhang; Longxiang Tang; Yuelin Zhang; Kai Li; Xiu Li,~Chengyu_Fang3; ~Chunming_He1; ~Fengyang_Xiao1; ~Yulun_Zhang1; ~Longxiang_Tang1; ~Yuelin_Zhang1; ~Kai_Li11; ~Xiu_Li1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/13a77685b055136f270a3312d0a20e581c8da7ea.pdf,2024-05-04T16:14:42.189000,2024-09-25T18:07:53.108000,2024-12-20T08:14:30.763000,https://openreview.net/forum?id=I6tBNcJE2F,"Southwest University; Tsinghua University, Beijing; Tsinghua University, Beijing; Duke University; Sun Yat-sen University; ETH Zurich; Shanghai Jiao Tong University; Tsinghua University, Beijing; Chinese University of Hong Kong; NEC Laboratories, America; Tsinghua University, Beijing"
3697,STrpbhrvt3,STrpbhrvt3,1760,A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis,"While deep networks have achieved broad success in analyzing natural images, when applied to medical scans, they often fail in unexcepted situations. We investigate this challenge and focus on model sensitivity to domain shifts, such as data sampled from different hospitals or data confounded by demographic variables such as sex, race, etc, in the context of chest X-rays and skin lesion images. A key finding we show empirically is that existing visual backbones lack an appropriate prior from the architecture for reliable generalization in these settings. Taking inspiration from medical training, we propose giving deep networks a prior grounded in explicit medical knowledge communicated in natural language. To this end, we introduce Knowledge-enhanced Bottlenecks (KnoBo), a class of concept bottleneck models that incorporates knowledge priors that constrain it to reason with clinically relevant factors found in medical textbooks or PubMed. KnoBo uses retrieval-augmented language models to design an appropriate concept space paired with an automatic training procedure for recognizing the concept. We evaluate different resources of knowledge and recognition architectures on a broad range of domain shifts across 20 datasets. In our comprehensive evaluation with two imaging modalities, KnoBo outperforms fine-tuned models on confounded datasets by 32.4% on average. Finally, evaluations reveal that PubMed is a promising resource for making medical models less sensitive to domain shift, outperforming other resources on both diversity of information and final prediction performance.",Yue Yang; Mona Gandhi; Yufei Wang; Yifan Wu; Michael S Yao; Chris Callison-Burch; James Gee; Mark Yatskar,~Yue_Yang3; ~Mona_Gandhi1; ~Yufei_Wang11; ~Yifan_Wu4; ~Michael_S_Yao1; ~Chris_Callison-Burch1; ~James_Gee1; ~Mark_Yatskar1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,interpretability_and_explainability,/pdf/22b58e051cda38cd27de0e141f4f341514cce55a.pdf,2024-05-04T02:57:25.085000,2024-09-25T18:07:50.595000,2024-11-06T06:17:31.732000,https://openreview.net/forum?id=STrpbhrvt3,University of Pennsylvania; University of Pennsylvania; The Ohio State University; University of Pittsburgh; University of Pennsylvania; Meta; University of Pennsylvania; University of Pennsylvania; Allen Institute; University of Pennsylvania; University of Pennsylvania
3703,5jRU8ufi8H,5jRU8ufi8H,1726,Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models,"Large language models (LLMs) with billions of parameters excel at predicting the next token in a sequence. Recent work computes non-vacuous compression-based generalization bounds for LLMs, but these bounds are vacuous for large models at the billion-parameter scale. Moreover, these bounds are obtained through restrictive compression techniques, bounding compressed models that generate low-quality text. Additionally, the tightness of these existing bounds depends on the number of IID documents in a training set rather than the much larger number of non-IID constituent tokens, leaving untapped potential for tighter bounds. In this work, we instead use properties of martingales to derive generalization bounds that benefit from the vast number of tokens in LLM training sets. Since a dataset contains far more tokens than documents, our generalization bounds not only tolerate but actually benefit from far less restrictive compression schemes. With Monarch matrices, Kronecker factorizations, and post-training quantization, we achieve non-vacuous generalization bounds for LLMs as large as LLaMA2-70B. Unlike previous approaches, our work achieves the first non-vacuous bounds for models that are deployed in practice and generate high-quality text.",Sanae Lotfi; Yilun Kuang; Marc Anton Finzi; Brandon Amos; Micah Goldblum; Andrew Gordon Wilson,~Sanae_Lotfi1; ~Yilun_Kuang1; ~Marc_Anton_Finzi1; ~Brandon_Amos1; ~Micah_Goldblum1; ~Andrew_Gordon_Wilson1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/1792e33e3f87cbfc2fc18118f236e384f1489112.pdf,2024-05-03T19:36:07.681000,2024-09-25T18:07:49.509000,2024-11-06T06:17:31.447000,https://openreview.net/forum?id=5jRU8ufi8H,New York University; New York University; Carnegie Mellon University; Meta; New York University; Columbia University; New York University
3704,k9PXsryuWG,k9PXsryuWG,1720,Metric Transforms and Low Rank Representations of Kernels for Fast Attention,"We introduce a new linear-algebraic tool based on group representation theory, and use it to address three key problems in machine learning.

1. Past researchers have proposed fast attention algorithms for LLMs by approximating or replace softmax attention with other functions, such as low-degree polynomials. The key property of these functions is that, when applied entry-wise to the matrix $QK^{\top}$, the result is a low rank matrix when $Q$ and $K$ are $n \times d$ matrices and $n \gg d$. This suggests a natural question: what are all functions $f$ with this property? If other $f$ exist and are quickly computable, they can be used in place of softmax for fast subquadratic attention algorithms. It was previously known that low-degree polynomials have this property. We prove that low-degree polynomials are the only piecewise continuous functions with this property. This suggests that the low-rank fast attention only works for functions approximable by polynomials. Our work gives a converse to the polynomial method in algorithm design.

2. We prove the first full classification of all positive definite kernels that are functions of Manhattan or $\ell_1$ distance. Our work generalizes an existing theorem at the heart of all kernel methods in machine learning: the classification of all positive definite kernels that are functions of Euclidean distance. 

3. The key problem in metric transforms, a mathematical theory used in geometry and machine learning, asks what functions transform pairwise distances in semi-metric space $M$ to semi-metric space $N$ for specified $M$ and $N$. We provide the first full classification of functions that transform Manhattan distances to Manhattan distances. Our work generalizes the foundational work of Schoenberg, which fully classifies functions that transform Euclidean to Euclidean distances.
 
We additionally prove results about stable-rank preserving functions that are potentially useful in algorithmic design, and more. Our core new tool is called the representation theory of the hyperrectangle.",Timothy Zer-An Chu; Josh Alman; Gary Miller; Shyam Narayanan; Mark Sellke; Zhao Song,~Timothy_Zer-An_Chu1; ~Josh_Alman1; ~Gary_Miller1; ~Shyam_Narayanan1; ~Mark_Sellke1; ~Zhao_Song3,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/f786c80be037eb55165d1a67bfb4db0a35bff5f5.pdf,2024-05-03T18:30:58.722000,2024-09-25T18:07:49.354000,2024-11-06T06:17:31.406000,https://openreview.net/forum?id=k9PXsryuWG,"AAAS; Columbia University; Harvard University; Adobe Systems; University of California, Berkeley"
3711,E7fZOoiEKl,E7fZOoiEKl,1696,FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion,"One-shot Federated Learning (OFL) significantly reduces communication costs in FL by aggregating trained models only once. However, the performance of advanced OFL methods is far behind the normal FL. In this work, we provide a causal view to find that this performance drop of OFL methods comes from the isolation problem, which means that local isolatedly trained models in OFL may easily fit to spurious correlations due to the data heterogeneity. From the causal perspective, we observe that the spurious fitting can be alleviated by augmenting intermediate features from other clients. Built upon our observation, we propose a novel learning approach to endow OFL with superb performance and low communication and storage costs, termed as FuseFL. Specifically, FuseFL decomposes neural networks into several blocks, and progressively trains and fuses each block following a bottom-up manner for feature augmentation, introducing no additional communication costs. Comprehensive experiments demonstrate that FuseFL outperforms existing OFL and ensemble FL by a significant margin. We conduct comprehensive experiments to show that FuseFL supports high scalability of clients, heterogeneous model training, and low memory costs. Our work is the first attempt using causality to analyze and alleviate data heterogeneity of OFL.",Zhenheng Tang; Yonggang Zhang; Peijie Dong; Yiu-ming Cheung; Amelie Chi Zhou; Bo Han; Xiaowen Chu,~Zhenheng_Tang2; ~Yonggang_Zhang1; ~Peijie_Dong1; ~Yiu-ming_Cheung1; ~Amelie_Chi_Zhou1; ~Bo_Han1; ~Xiaowen_Chu2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,other,/pdf/2dcd01b177fcc5f2911ee510759f5216521ba49a.pdf,2024-05-03T15:26:47.695000,2024-09-25T18:07:48.662000,2024-11-06T06:17:31.139000,https://openreview.net/forum?id=E7fZOoiEKl,Hong Kong University of Science and Technology(Guangzhou); Hong Kong Baptist University; Hong Kong Baptist University; Hong Kong University of Science and Technology(Guangzhou); Hong Kong Baptist University; Hong Kong Baptist University; Hong Kong Baptist University; Mohamed bin Zayed University of Artificial Intelligence; RIKEN; Hong Kong University of Science and Technology(Guangzhou)
3718,p3gMGkHMkM,p3gMGkHMkM,1654,Particle Semi-Implicit Variational Inference,"Semi-implicit variational inference (SIVI) enriches the expressiveness of variational
families by utilizing a kernel and a mixing distribution to hierarchically define the
variational distribution. Existing SIVI methods parameterize the mixing distribution
using implicit distributions, leading to intractable variational densities. As a result,
directly maximizing the evidence lower bound (ELBO) is not possible, so they
resort to one of the following: optimizing bounds on the ELBO, employing costly
inner-loop Markov chain Monte Carlo runs, or solving minimax objectives. In this
paper, we propose a novel method for SIVI called Particle Variational Inference
(PVI) which employs empirical measures to approximate the optimal mixing
distributions characterized as the minimizer of a free energy functional. PVI arises
naturally as a particle approximation of a Euclidean–Wasserstein gradient flow and,
unlike prior works, it directly optimizes the ELBO whilst making no parametric
assumption about the mixing distribution. Our empirical results demonstrate that
PVI performs favourably compared to other SIVI methods across various tasks.
Moreover, we provide a theoretical analysis of the behaviour of the gradient flow
of a related free energy functional: establishing the existence and uniqueness of
solutions as well as propagation of chaos results.",Jen Ning Lim; Adam Michael Johansen,~Jen_Ning_Lim1; ~Adam_Michael_Johansen1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/5eb4c3bb21789c23444061ea4b22d94c6a4852a1.pdf,2024-05-03T11:40:30.283000,2024-09-25T18:07:47.522000,2025-01-14T17:05:55.037000,https://openreview.net/forum?id=p3gMGkHMkM,University of Warwick
3723,XUAcPEaeBU,XUAcPEaeBU,1632,PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless Imaging,"Lensless cameras offer significant advantages in size, weight, and cost compared to traditional lens-based systems. Without a focusing lens, lensless cameras rely on computational algorithms to recover the scenes from multiplexed measurements. However, current algorithms struggle with inaccurate forward imaging models and insufficient priors to reconstruct high-quality images. To overcome these limitations, we introduce a novel two-stage approach for consistent and photorealistic lensless image reconstruction. The first stage of our approach ensures data consistency by focusing on accurately reconstructing the low-frequency content with a spatially varying deconvolution method that adjusts to changes in the Point Spread Function (PSF) across the camera's field of view. The second stage enhances photorealism by incorporating a generative prior from pre-trained diffusion models. By conditioning on the low-frequency content retrieved in the first stage, the diffusion model effectively reconstructs the high-frequency details that are typically lost in the lensless imaging process, while also maintaining image fidelity. Our method achieves a superior balance between data fidelity and visual quality compared to existing methods, as demonstrated with two popular lensless systems, PhlatCam and DiffuserCam.",Xin Cai; Zhiyuan You; Hailong Zhang; Jinwei Gu; Wentao Liu; Tianfan Xue,~Xin_Cai2; ~Zhiyuan_You1; ~Hailong_Zhang1; ~Jinwei_Gu1; ~Wentao_Liu1; ~Tianfan_Xue2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/0bd0332633ec91c508ca7408976908dbed56509e.pdf,2024-05-03T08:26:56.193000,2024-09-25T18:07:46.745000,2024-11-06T06:17:30.614000,https://openreview.net/forum?id=XUAcPEaeBU,"Chinese University of Hong Kong; Chinese University of Hong Kong; Tsinghua University, Beijing; Chinese University of Hong Kong; NVIDIA; SenseTime Research; Chinese University of Hong Kong"
3731,QVSP1uk7b5,QVSP1uk7b5,1606,Tetrahedron Splatting for 3D Generation,"3D representation is essential to the significant advance of 3D generation with 2D diffusion priors. As a flexible representation, NeRF has been first adopted for 3D representation. With density-based volumetric rendering, it however suffers both intensive computational overhead and inaccurate mesh extraction. Using a signed distance field and Marching Tetrahedra, DMTet allows for precise mesh extraction and real-time rendering but is limited in handling large topological changes in meshes, leading to optimization challenges. Alternatively, 3D Gaussian Splatting (3DGS) is favored in both training and rendering efficiency while falling short in mesh extraction. In this work, we introduce a novel 3D representation, Tetrahedron Splatting (TeT-Splatting), that supports easy convergence during optimization, precise mesh extraction, and real-time rendering simultaneously. This is achieved by integrating surface-based volumetric rendering within a structured tetrahedral grid while preserving the desired ability of precise mesh extraction, and a tile-based differentiable tetrahedron rasterizer. Furthermore, we incorporate eikonal and normal consistency regularization terms for the signed distance field to improve generation quality and stability. Critically, our representation can be trained without mesh extraction, making the optimization process easier to converge. Our TeT-Splatting can be readily integrated in existing 3D generation pipelines, along with polygonal mesh for texture optimization. Extensive experiments show that our TeT-Splatting strikes a superior tradeoff among convergence speed, render efficiency, and mesh quality as compared to previous alternatives under varying 3D generation settings.",Chun Gu; Zeyu Yang; Zijie Pan; Xiatian Zhu; Li Zhang,~Chun_Gu1; ~Zeyu_Yang3; ~Zijie_Pan2; ~Xiatian_Zhu3; ~Li_Zhang5,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/01fce14ad6d6b686fd5e33480d693ab6d04b37cb.pdf,2024-05-03T05:32:01.024000,2024-09-25T18:07:45.931000,2024-11-06T06:17:30.321000,https://openreview.net/forum?id=QVSP1uk7b5,Fudan University; Fudan University; Fudan University; University of Surrey; Fudan University
3748,kMxdV4Blhn,kMxdV4Blhn,1528,Rethinking 3D Convolution in $\ell_p$-norm Space,"Convolution is a fundamental operation in the 3D backbone. However, under certain conditions, the feature extraction ability of traditional convolution methods may be weakened. In this paper, we introduce a new convolution method based on  $\ell_p$-norm. 
For theoretical support, we prove the universal approximation theorem for $\ell_p$-norm based convolution, and analyze the robustness and feasibility of  $\ell_p$-norms in 3D point cloud tasks. Concretely, $\ell_{\infty}$-norm based convolution is prone to feature loss. $\ell_2$-norm based convolution is essentially a linear transformation of the traditional convolution.  $\ell_1$-norm based convolution is an economical and effective feature extractor. We propose customized optimization strategies to accelerate the training process of $\ell_1$-norm based Nets and enhance the performance. Besides, a theoretical guarantee is given for the convergence by \textit{regret} argument. We apply our methods to classic networks and conduct related experiments. Experimental results indicate that our approach exhibits competitive performance with traditional CNNs, with lower energy consumption and instruction latency.",Li Zhang; Yan Zhong; Jianan Wang; Zhe Min; RujingWang; Liu Liu,~Li_Zhang25; ~Yan_Zhong2; ~Jianan_Wang2; ~Zhe_Min2; ~RujingWang1; ~Liu_Liu13,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/78929bbc3eea171f200078a0b1108595b20ad678.pdf,2024-05-02T15:38:52.289000,2024-09-25T18:07:43.478000,2024-11-06T06:17:29.560000,https://openreview.net/forum?id=kMxdV4Blhn,University of Science and Technology of China; Peking University; Astribot; The International Digital Economy Academy; Shandong University; University of Chinese Academy of Sciences; Hefei University of Technology
3752,Llu9nJal7b,Llu9nJal7b,1520,MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models,"Large Language Models (LLMs) are distinguished by their massive parameter counts, which typically result in significant redundancy. This work introduces MaskLLM, a learnable pruning method that establishes Semi-structured (or ``N:M'') Sparsity in LLMs, aimed at reducing computational overhead during inference. Instead of developing a new importance criterion, MaskLLM explicitly models N:M patterns as a learnable distribution through Gumbel Softmax sampling. This approach facilitates end-to-end training on large-scale datasets and offers two notable advantages: 1) High-quality Masks - our method effectively scales to large datasets and learns accurate masks; 2) Transferability - the probabilistic modeling of mask distribution enables the transfer learning of sparsity across domains or tasks. We assessed MaskLLM using 2:4 sparsity on various LLMs, including LLaMA-2, Nemotron-4, and GPT-3, with sizes ranging from 843M to 15B parameters, and our empirical results show substantial improvements over state-of-the-art methods. For instance, leading approaches achieve a perplexity (PPL) of 10 or greater on Wikitext compared to the dense model's 5.12 PPL, but MaskLLM achieves a significantly lower 6.72 PPL solely by learning the masks with frozen weights. Furthermore, MaskLLM's learnable nature allows customized masks for lossless application of 2:4 sparsity to downstream tasks or domains. Code is available at https://github.com/NVlabs/MaskLLM.",Gongfan Fang; Hongxu Yin; Saurav Muralidharan; Greg Heinrich; Jeff Pool; Jan Kautz; Pavlo Molchanov; Xinchao Wang,~Gongfan_Fang2; ~Hongxu_Yin2; ~Saurav_Muralidharan1; ~Greg_Heinrich1; ~Jeff_Pool1; ~Jan_Kautz1; ~Pavlo_Molchanov1; ~Xinchao_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,natural_language_processing,/pdf/9f3722ddd8d9682b00ab8e00e22d7f39e647575d.pdf,2024-05-02T15:00:22.956000,2024-09-25T18:07:43.165000,2024-11-06T06:17:29.384000,https://openreview.net/forum?id=Llu9nJal7b,National University of Singapore; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; National University of Singapore
3773,qEpi8uWX3N,qEpi8uWX3N,1402,HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning,"Adapting Large Language Models (LLMs) to new tasks through fine-tuning has been made more efficient by the introduction of Parameter-Efficient Fine-Tuning (PEFT) techniques, such as LoRA. However, these methods often underperform compared to full fine-tuning, particularly in scenarios involving complex datasets. This issue becomes even more pronounced in complex domains, highlighting the need for improved PEFT approaches that can achieve better performance. Through a series of experiments, we have uncovered two critical insights that shed light on the training and parameter inefficiency of LoRA. Building on these insights, we have developed HydraLoRA, a LoRA framework with an asymmetric structure that eliminates the need for domain expertise. Our experiments demonstrate that HydraLoRA outperforms other PEFT approaches, even those that rely on domain knowledge during the training and inference phases. Our anonymous codes are submitted with the paper and will be publicly available. Code is available: https://github.com/Clin0212/HydraLoRA.",Chunlin Tian; Zhan Shi; Zhijiang Guo; Li Li; Cheng-zhong Xu,~Chunlin_Tian1; ~Zhan_Shi3; ~Zhijiang_Guo2; ~Li_Li10; ~Cheng-zhong_Xu1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,generative_models,/pdf/60e4bb51758f975380df1586e785d29a101c7f4a.pdf,2024-05-02T04:20:14.477000,2024-09-25T18:07:39.999000,2024-11-06T06:17:28.504000,https://openreview.net/forum?id=qEpi8uWX3N,University of Macau; University of Cambridge; University of Macau
3774,79q206xswc,79q206xswc,1401,Is Your LiDAR Placement Optimized for 3D Scene Understanding?,"The reliability of driving perception systems under unprecedented conditions is crucial for practical usage. Latest advancements have prompted increasing interest in multi-LiDAR perception. However, prevailing driving datasets predominantly utilize single-LiDAR systems and collect data devoid of adverse conditions, failing to capture the complexities of real-world environments accurately. Addressing these gaps, we proposed Place3D, a full-cycle pipeline that encompasses LiDAR placement optimization, data generation, and downstream evaluations. Our framework makes three appealing contributions. 1) To identify the most effective configurations for multi-LiDAR systems, we introduce the Surrogate Metric of the Semantic Occupancy Grids (M-SOG) to evaluate LiDAR placement quality. 2) Leveraging the M-SOG metric, we propose a novel optimization strategy to refine multi-LiDAR placements. 3) Centered around the theme of multi-condition multi-LiDAR perception, we collect a 280,000-frame dataset from both clean and adverse conditions. Extensive experiments demonstrate that LiDAR placements optimized using our approach outperform various baselines. We showcase exceptional results in both LiDAR semantic segmentation and 3D object detection tasks, under diverse weather and sensor failure conditions.",Ye Li; Lingdong Kong; Hanjiang Hu; Xiaohao Xu; Xiaonan Huang,~Ye_Li8; ~Lingdong_Kong1; ~Hanjiang_Hu1; ~Xiaohao_Xu1; ~Xiaonan_Huang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/de35ca98edb8f84e21aa32bb35f90d6edc3f803a.pdf,2024-05-02T04:17:18.034000,2024-09-25T18:07:39.942000,2024-11-06T06:17:28.488000,https://openreview.net/forum?id=79q206xswc,University of Michigan - Ann Arbor; CNRS@CREATE; National University of Singapore; NVIDIA; Carnegie Mellon University; University of Michigan - Ann Arbor; University of Michigan - Ann Arbor
3798,mSaqxZVZW8,mSaqxZVZW8,1325,SeeA*: Efficient Exploration-Enhanced A* Search by Selective Sampling,"Monte-Carlo tree search (MCTS) and reinforcement learning contributed crucially to the success of AlphaGo and AlphaZero, and A$^*$ is a tree search algorithm among the most well-known ones in the classical AI literature. MCTS and  A$^*$ both perform heuristic search and are mutually beneficial. Efforts have been made to the renaissance of A$^*$ from three possible aspects, two of which have been confirmed by studies in recent years, while the third is about the OPEN list that consists of open nodes of A$^*$ search, but still lacks deep investigation. This paper aims at the third, i.e., developing the Sampling-exploration enhanced A$^*$ (SeeA$^*$) search by constructing a dynamic subset of OPEN through a selective sampling process, such that the node with the best heuristic value in this subset instead of in the OPEN is expanded. Nodes with the best heuristic values in OPEN are most probably picked into this subset, but sometimes may not be included, which enables SeeA$^*$ to explore other promising branches. Three sampling techniques are presented for comparative investigations. Moreover, under the assumption about the distribution of prediction errors, we have theoretically shown the superior efficiency of SeeA$^*$ over A$^*$ search, particularly when the accuracy of the guiding heuristic function is insufficient. Experimental results on retrosynthetic planning in organic chemistry, logic synthesis in integrated circuit design, and the classical Sokoban game empirically demonstrate the efficiency of SeeA$^*$, in comparison with the state-of-the-art heuristic search algorithms.",Dengwei Zhao; Shikui Tu; Lei Xu,~Dengwei_Zhao1; ~Shikui_Tu1; ~Lei_Xu7,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,reinforcement_learning,/pdf/fa5dedfe169ea46edcf332d8d7d9b5256b506793.pdf,2024-05-01T12:59:14.478000,2024-09-25T18:07:37.728000,2024-12-19T01:57:33.510000,https://openreview.net/forum?id=mSaqxZVZW8,Shanghai Jiao Tong University; Shanghai Jiao Tong University; Chinese University of Hong Kong; Shanghai Jiao Tong University
3813,88TzdGyPT6,88TzdGyPT6,1260,Benign overfitting in leaky ReLU networks with moderate input dimension,"The problem of benign overfitting asks whether it is possible for a model to perfectly fit noisy training data and still generalize well. We study benign overfitting in two-layer leaky ReLU networks trained with the hinge loss on a binary classification task. We consider input data which can be decomposed into the sum of a common signal and a random noise component, which lie on subspaces orthogonal to one another. We characterize conditions on the signal to noise ratio (SNR) of the model parameters giving rise to benign versus non-benign, or harmful, overfitting: in particular, if the SNR is high then benign overfitting occurs, conversely if the SNR is low then harmful overfitting occurs. We attribute both benign and non-benign overfitting to an approximate margin maximization property and show that leaky ReLU networks trained on hinge loss with gradient descent (GD) satisfy this property. In contrast to prior work we do not require the training data to be nearly orthogonal. Notably, for input dimension $d$ and training sample size $n$, while results in prior work require $d = \Omega(n^2 \log n)$, here we require only $d = \Omega(n)$.",Kedar Karhadkar; Erin George; Michael Murray; Guido Montufar; Deanna Needell,~Kedar_Karhadkar1; ~Erin_George1; ~Michael_Murray3; ~Guido_Montufar1; ~Deanna_Needell2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/4229ba466899f8f513b2892f44ae2dc30f999e67.pdf,2024-04-30T19:28:17.156000,2024-09-25T18:07:35.972000,2024-11-06T06:17:26.915000,https://openreview.net/forum?id=88TzdGyPT6,"Susquehanna International Group; University of California, Los Angeles; University of Bath; University of California, Los Angeles; Max Planck Institute for Software Systems; UCLA; University of California, Los Angeles; University of California, Los Angeles"
3815,tQukGCDaNT,tQukGCDaNT,1257,Improved Distribution Matching Distillation for Fast Image Synthesis,"Recent approaches have shown promises distilling expensive diffusion models into efficient one-step generators.
Amongst them, Distribution Matching Distillation (DMD) produces one-step generators that match their teacher in distribution, i.e., the distillation process does not enforce a one-to-one correspondence with the sampling trajectories of their teachers.
However, to ensure stable training in practice, DMD requires an additional regression loss computed using a large set of noise--image pairs, generated by the teacher with many steps of a deterministic sampler.
This is not only computationally expensive for large-scale text-to-image synthesis, but it also limits the student's quality, tying it too closely to the teacher's original sampling paths.
We introduce DMD2, a set of techniques that lift this limitation and improve DMD training.
First, we eliminate the regression loss and the need for expensive dataset construction.
We show that the resulting instability is due to the ""fake"" critic not estimating the distribution 
of generated samples with sufficient accuracy and propose a two time-scale update rule as a remedy.
Second, we integrate a GAN loss into the distillation procedure, discriminating between generated samples and real images.
This lets us train the student model on real data, thus mitigating the imperfect ""real"" score estimation from the teacher model, and thereby enhancing quality.
Third, we introduce a new training procedure that enables multi-step sampling in the student, and
addresses the training--inference input mismatch of previous work, by simulating inference-time generator samples during training. 
Taken together, our improvements set new benchmarks in one-step image generation, with FID scores of 1.28 on ImageNet-64×64 and 8.35 on zero-shot COCO 2014, surpassing the original teacher despite a 500X reduction in inference cost.
Further, we show our approach can generate megapixel images by distilling SDXL, demonstrating exceptional visual quality among few-step methods, and surpassing the teacher. 
We release our code and pretrained models.",Tianwei Yin; Michaël Gharbi; Taesung Park; Richard Zhang; Eli Shechtman; Fredo Durand; William T. Freeman,~Tianwei_Yin1; ~Michaël_Gharbi1; ~Taesung_Park2; ~Richard_Zhang1; ~Eli_Shechtman3; ~Fredo_Durand1; ~William_T._Freeman1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/1905628c3311a975f3893addcfe05ba10aa58153.pdf,2024-04-30T18:30:56.701000,2024-09-25T18:07:35.901000,2025-01-16T05:06:57.406000,https://openreview.net/forum?id=tQukGCDaNT,Massachusetts Institute of Technology; Adobe Systems; Adobe Systems; Adobe Systems; Adobe Systems; Massachusetts Institute of Technology; Google; Massachusetts Institute of Technology
3821,PQt6Vg2X5u,PQt6Vg2X5u,1225,Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss,"PAC-Bayesian analysis is a frequentist framework for incorporating prior knowledge into learning. It was inspired by Bayesian learning, which allows sequential data processing and naturally turns posteriors from one processing step into priors for the next. However, despite two and a half decades of research, the ability to update priors sequentially without losing confidence information along the way remained elusive for PAC-Bayes. While PAC-Bayes allows construction of data-informed priors, the final confidence intervals depend only on the number of points that were not used for the construction of the prior, whereas confidence information in the prior, which is related to the number of points used to construct the prior, is lost. This limits the possibility and benefit of sequential prior updates, because the final bounds depend only on the size of the final batch.

We present a novel and, in retrospect, surprisingly simple and powerful PAC-Bayesian procedure that allows  sequential prior updates with no information loss. The procedure is based on a novel decomposition of the expected loss of randomized classifiers. The decomposition rewrites the loss of the posterior as an excess loss relative to a downscaled loss of the prior plus the downscaled loss of the prior, which is bounded recursively. As a side result, we also present a generalization of the split-kl and PAC-Bayes-split-kl inequalities to discrete random variables, which we use for bounding the excess losses, and which can be of independent interest. In empirical evaluation the new procedure significantly outperforms state-of-the-art.",Yi-Shan Wu; Yijie Zhang; Badr-Eddine Chérief-Abdellatif; Yevgeny Seldin,~Yi-Shan_Wu1; ~Yijie_Zhang1; ~Badr-Eddine_Chérief-Abdellatif1; ~Yevgeny_Seldin2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,learning_theory,/pdf/5235ca8b377715d592cb3e02ed9aa3c743eadc2e.pdf,2024-04-30T13:04:24.117000,2024-09-25T18:07:35.247000,2025-01-14T13:16:19.494000,https://openreview.net/forum?id=PQt6Vg2X5u,University of Southern Denmark - SDU; University of Copenhagen
3833,VFqzxhINFU,VFqzxhINFU,1165,StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation,"For recent diffusion-based generative models, maintaining consistent content across a series of generated images, especially those containing subjects and complex details, presents a significant challenge. In this paper, we propose a simple but effective self-attention mechanism, termed Consistent Self-Attention, that boosts the consistency between the generated images. It can be used to augment pre-trained diffusion-based text-to-image models in a zero-shot manner. Based on the images with consistent content, we further show that our method can be extended to long range video generation by introducing a semantic space temporal motion prediction module, named Semantic Motion Predictor. It is trained to estimate the motion conditions between two provided images in the semantic spaces. This module converts the generated sequence of images into videos with smooth transitions and consistent subjects that are more stable than the modules based on latent spaces only, especially in the context of long video generation. By merging these two novel components, our framework, referred to as StoryDiffusion, can describe a text-based story with consistent images or videos encompassing a rich variety of contents. The proposed StoryDiffusion encompasses pioneering explorations in visual story generation with the presentation of images and videos, which we hope could inspire more research from the aspect of architectural modifications.",Yupeng Zhou; Daquan Zhou; Ming-Ming Cheng; Jiashi Feng; Qibin Hou,~Yupeng_Zhou1; ~Daquan_Zhou1; ~Ming-Ming_Cheng3; ~Jiashi_Feng1; ~Qibin_Hou1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/992e1d8483d14f713dff3f74f664f722bfa72930.pdf,2024-04-30T03:51:22.695000,2024-09-25T18:07:33.780000,2024-11-06T06:17:26.072000,https://openreview.net/forum?id=VFqzxhINFU,Nankai University; ByteDance Inc.; Nankai University; ByteDance Inc.; Nankai University
3843,VFpXYBqMSU,VFpXYBqMSU,1119,Slight Corruption in Pre-training Data Makes Better Diffusion Models,"Diffusion models (DMs) have shown remarkable capabilities in generating realistic high-quality images, audios, and videos. 
They benefit significantly from extensive pre-training on large-scale datasets, including web-crawled data with paired data and conditions, such as image-text and image-class pairs.
Despite rigorous filtering, these pre-training datasets often inevitably contain corrupted pairs where conditions do not accurately describe the data. 
This paper presents the first comprehensive study on the impact of such corruption in pre-training data of DMs.
We synthetically corrupt ImageNet-1K and CC3M to pre-train and evaluate over $50$ conditional DMs. 
Our empirical findings reveal that various types of slight corruption in pre-training can significantly enhance the quality, diversity, and fidelity of the generated images across different DMs, both during pre-training and downstream adaptation stages. 
Theoretically, we consider a Gaussian mixture model and prove that slight corruption in the condition leads to higher entropy and a reduced 2-Wasserstein distance to the ground truth of the data distribution generated by the corruptly trained DMs.
Inspired by our analysis, we propose a simple method to improve the training of DMs on practical datasets by adding condition embedding perturbations (CEP).
CEP significantly improves the performance of various DMs in both pre-training and downstream tasks.
We hope that our study provides new insights into understanding the data and pre-training processes of DMs.",Hao Chen; Yujin Han; Diganta Misra; Xiang Li; Kai Hu; Difan Zou; Masashi Sugiyama; Jindong Wang; Bhiksha Raj,~Hao_Chen15; ~Yujin_Han1; ~Diganta_Misra1; ~Xiang_Li35; ~Kai_Hu2; ~Difan_Zou1; ~Masashi_Sugiyama1; ~Jindong_Wang4; ~Bhiksha_Raj1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,diffusion_based_models,/pdf/83e7547eb58a1bedcc438af00577dddd6fca0c4c.pdf,2024-04-29T14:48:21.827000,2024-09-25T18:07:32.699000,2024-11-15T21:20:18.428000,https://openreview.net/forum?id=VFpXYBqMSU,"Carnegie Mellon University; University of Hong Kong; Montreal Institute of Learning Algorithms; Max Planck Institute for Software Systems; ELLIS Institute, Tübingen; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; University of Hong Kong; The University of Tokyo; RIKEN; Microsoft; Carnegie Mellon University; Mohamed bin Zayed University of Artificial Intelligence"
3855,47loYmzxep,47loYmzxep,1054,E2E-MFD: Towards End-to-End Synchronous Multimodal Fusion Detection,"Multimodal image fusion and object detection are crucial for autonomous driving. While current methods have advanced the fusion of texture details and semantic information, their complex training processes hinder broader applications. Addressing this challenge, we introduce E2E-MFD, a novel end-to-end algorithm for multimodal fusion detection. E2E-MFD streamlines the process, achieving high performance with a single training phase. It employs synchronous joint optimization across components to avoid suboptimal solutions associated to individual tasks. Furthermore, it implements a comprehensive optimization strategy in the gradient matrix for shared parameters, ensuring convergence to an optimal fusion detection configuration. Our extensive testing on multiple public datasets reveals E2E-MFD's superior capabilities, showcasing not only visually appealing image fusion but also impressive detection outcomes, such as a 3.9\% and  2.0\% $\text{mAP}_{50}$ increase on horizontal object detection dataset M3FD and oriented object detection dataset DroneVehicle, respectively, compared to state-of-the-art approaches.",Jiaqing Zhang; Mingxiang Cao; Weiying Xie; Jie Lei; DaixunLi; Wenbo Huang; Yunsong Li; Xue Yang,~Jiaqing_Zhang1; ~Mingxiang_Cao1; ~Weiying_Xie1; ~Jie_Lei5; ~DaixunLi1; ~Wenbo_Huang1; ~Yunsong_Li1; ~Xue_Yang2,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_vision,/pdf/b861f70a3f6d0b0377a6c809e5aeb3cc2bb8a6ba.pdf,2024-04-29T03:42:47.399000,2024-09-25T18:07:30.825000,2024-11-06T06:17:25.093000,https://openreview.net/forum?id=47loYmzxep,Xi'an University; State Key Laboratory of Integrated Services Networks; Xidian University; State Key Laboratory of Integrated Services Networks; Southeast University; Xidian University; Shanghai Artificial Intelligence Laboratory
3860,VNBIF0gmkb,VNBIF0gmkb,1047,Autoregressive Image Generation without Vector Quantization,"Conventional wisdom holds that autoregressive models for image generation are typically accompanied by vector-quantized tokens. We observe that while a discrete-valued space can facilitate representing a categorical distribution, it is not a necessity for autoregressive modeling. In this work, we propose to model the per-token probability distribution using a diffusion procedure, which allows us to apply autoregressive models in a continuous-valued space. Rather than using categorical cross-entropy loss, we define a Diffusion Loss function to model the per-token probability. This approach eliminates the need for discrete-valued tokenizers. We evaluate its effectiveness across a wide range of cases, including standard autoregressive models and generalized masked autoregressive (MAR) variants. By removing vector quantization, our image generator achieves strong results while enjoying the speed advantage of sequence modeling. We hope this work will motivate the use of autoregressive generation in other continuous-valued domains and applications. Code is available at [https://github.com/LTH14/mar](https://github.com/LTH14/mar).",Tianhong Li; Yonglong Tian; He Li; Mingyang Deng; Kaiming He,~Tianhong_Li3; ~Yonglong_Tian1; ~He_Li13; ~Mingyang_Deng1; ~Kaiming_He2,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,generative_models,/pdf/764114424159b501aa25135ee8bb36c253e2f38d.pdf,2024-04-29T02:30:12.257000,2024-09-25T18:07:30.456000,2024-11-14T14:19:46.333000,https://openreview.net/forum?id=VNBIF0gmkb,"Massachusetts Institute of Technology; Google; OpenAI; Tsinghua University, Beijing; Massachusetts Institute of Technology; Meta; Massachusetts Institute of Technology"
3876,mHtOyh5taj,mHtOyh5taj,937,Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare,"While recent advancements in large multimodal models (LMMs) have significantly improved their abilities in image quality assessment (IQA) relying on absolute quality rating, how to transfer reliable relative quality comparison outputs to continuous perceptual quality scores remains largely unexplored. To address this gap, we introduce an all-around LMM-based NR-IQA model, which is capable of producing qualitatively comparative responses and effectively translating these discrete comparison outcomes into a continuous quality score. Specifically, during training, we present to generate scaled-up comparative instructions by comparing images from the same IQA dataset, allowing for more flexible integration of diverse IQA datasets. Utilizing the established large-scale training corpus, we develop a human-like visual quality comparator. During inference, moving beyond binary choices, we propose a soft comparison method that calculates the likelihood of the test image being preferred over multiple predefined anchor images. The quality score is further optimized by maximum a posteriori estimation with the resulting probability matrix. Extensive experiments on nine IQA datasets validate that the Compare2Score effectively bridges text-defined comparative levels during training with converted single image quality scores for inference, surpassing state-of-the-art IQA models across diverse scenarios. Moreover, we verify that the probability-matrix-based inference conversion not only improves the rating accuracy of Compare2Score but also zero-shot general-purpose LMMs, suggesting its intrinsic effectiveness.",Hanwei Zhu; Haoning Wu; Yixuan Li; Zicheng Zhang; Baoliang Chen; Lingyu Zhu; Yuming Fang; Guangtao Zhai; Weisi Lin; Shiqi Wang,~Hanwei_Zhu1; ~Haoning_Wu1; ~Yixuan_Li12; ~Zicheng_Zhang7; ~Baoliang_Chen2; ~Lingyu_Zhu3; ~Yuming_Fang1; ~Guangtao_Zhai1; ~Weisi_Lin1; ~Shiqi_Wang1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,evaluation,/pdf/4a7c252d88318fd8cb811b8d23cd9956a27dc305.pdf,2024-04-27T13:19:44.649000,2024-09-25T18:07:27.943000,2024-11-06T06:17:24.229000,https://openreview.net/forum?id=mHtOyh5taj,City University of Hong Kong; Rhymes AI; Nanyang Technological University; City University of Hong Kong; Shanghai Jiao Tong University; Central China Normal University; City University of Hong Kong; City University of Hong Kong; Nanjing University; Shanghai Jiao Tong University; Nanyang Technological University; City University of Hong Kong
3890,YCKuXkw6UL,YCKuXkw6UL,874,Acoustic Volume Rendering for Neural Impulse Response Fields,"Realistic audio synthesis that captures accurate acoustic phenomena is essential for creating immersive experiences in virtual and augmented reality. Synthesizing the sound received at any position relies on the estimation of impulse response (IR), which characterizes how sound propagates in one scene along different paths before arriving at the listener position. In this paper, we present Acoustic Volume Rendering (AVR), a novel approach that adapts volume rendering techniques to model acoustic impulse responses. While volume rendering has been successful in modeling radiance fields for images and neural scene representations, IRs present unique challenges as time-series signals. To address these challenges, we introduce frequency-domain volume rendering and use spherical integration to fit the IR measurements. Our method constructs an impulse response field that inherently encodes wave propagation principles and achieves state of-the-art performance in synthesizing impulse responses for novel poses. Experiments show that AVR surpasses current leading methods by a substantial margin. Additionally, we develop an acoustic simulation platform, AcoustiX, which provides more accurate and realistic IR simulations than existing simulators. Code for AVR and AcoustiX are available at https://zitonglan.github.io/avr.",Zitong Lan; Chenhao Zheng; Zhiwei Zheng; Mingmin Zhao,~Zitong_Lan1; ~Chenhao_Zheng1; ~Zhiwei_Zheng1; ~Mingmin_Zhao1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,speech_and_audio,/pdf/8272e37def4b7e74dcfc0263b1e62e5086f9669b.pdf,2024-04-26T20:38:26.542000,2024-09-25T18:07:26.335000,2024-11-06T06:17:23.593000,https://openreview.net/forum?id=YCKuXkw6UL,University of Pennsylvania; University of Washington; University of Pennsylvania; University of Pennsylvania
3927,Y8YVCOMEpz,Y8YVCOMEpz,575,MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map,"Various linear complexity models, such as Linear Transformer (LinFormer), State Space Model (SSM), and Linear RNN (LinRNN), have been proposed to replace the conventional softmax attention in Transformer structures. However, the optimal design of these linear models is still an open question. In this work, we attempt to answer this question by finding the best linear approximation to softmax attention from a theoretical perspective. We start by unifying existing linear complexity models as the linear attention form and then identify three conditions for the optimal linear attention design: (1) Dynamic memory ability; (2) Static approximation ability; (3) Least parameter approximation. We find that none of the current linear models meet all three conditions, resulting in suboptimal performance. Instead, we propose Meta Linear Attention (MetaLA) as a solution that satisfies these conditions. Our experiments on Multi-Query Associative Recall (MQAR) task, language modeling, image classification, and Long-Range Arena (LRA) benchmark demonstrate that MetaLA is more effective than the existing linear models.",Yuhong Chou; Man Yao; Kexin Wang; Yuqi Pan; Rui-Jie Zhu; Jibin Wu; Yiran Zhong; Yu Qiao; Bo XU; Guoqi Li,~Yuhong_Chou1; ~Man_Yao1; ~Kexin_Wang2; ~Yuqi_Pan2; ~Rui-Jie_Zhu2; ~Jibin_Wu1; ~Yiran_Zhong1; ~Yu_Qiao1; ~Bo_XU10; ~Guoqi_Li1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,deep_learning_architectures,/pdf/6115a7c6711108daff03a490bc177f2d26b8446b.pdf,2024-04-24T14:49:56.389000,2024-09-25T18:07:21.001000,2024-11-06T06:17:22.062000,https://openreview.net/forum?id=Y8YVCOMEpz,Hong Kong Polytechnic University; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Nanjing University; University of California Santa Cruz; Hong Kong Polytechnic University; Shanghai Artificial Intelligence Laboratory; Shanghai Artificial Intelligence Laboratory; University of Chinese Academy of Sciences
3934,VKKY3Uv7vi,VKKY3Uv7vi,539,BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning,"Data-driven decision-making processes increasingly utilize end-to-end learnable deep neural networks to render final decisions. Sometimes, the output of the forward functions in certain layers is determined by the solutions to mathematical optimization problems, leading to the emergence of differentiable optimization layers that permit gradient back-propagation.
However, real-world scenarios often involve large-scale datasets and numerous constraints, presenting significant challenges. Current methods for differentiating optimization problems typically rely on implicit differentiation, which necessitates costly computations on the Jacobian matrices, resulting in low efficiency.
In this paper, we introduce BPQP, a differentiable convex optimization framework designed for efficient end-to-end learning. To enhance efficiency, we reformulate the backward pass as a simplified and decoupled quadratic programming problem by leveraging the structural properties of the Karush–Kuhn–Tucker (KKT) matrix. This reformulation enables the use of first-order optimization algorithms in calculating the backward pass gradients, allowing our framework to potentially utilize any state-of-the-art solver. As solver technologies evolve, BPQP can continuously adapt and improve its efficiency.
Extensive experiments on both simulated and real-world datasets demonstrate that BPQP achieves a significant improvement in efficiency—typically an order of magnitude faster in overall execution time compared to other differentiable optimization layers. Our results not only highlight the efficiency gains of BPQP but also underscore its superiority over differential optimization layer baselines.",Jianming Pan; Zeqi Ye; Xiao Yang; Xu Yang; Weiqing Liu; Lewen Wang; Jiang Bian,~Jianming_Pan1; ~Zeqi_Ye1; ~Xiao_Yang11; ~Xu_Yang7; ~Weiqing_Liu1; ~Lewen_Wang1; ~Jiang_Bian1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization,/pdf/59ae5159172fe4a7a66b4a77141977269e5a21d6.pdf,2024-04-24T09:52:19.804000,2024-09-25T18:07:20.110000,2024-12-30T03:20:46.201000,https://openreview.net/forum?id=VKKY3Uv7vi,Nankai University; Northwestern University; Microsoft; Microsoft
3940,cOuLbPhOT1,cOuLbPhOT1,506,PACE: Marrying generalization in PArameter-efficient fine-tuning with Consistency rEgularization,"Parameter-Efficient Fine-Tuning (PEFT) effectively adapts pre-trained transformers to downstream tasks. However, the optimization of tasks performance often comes at the cost of generalizability in fine-tuned models. To address this issue, we theoretically connect smaller weight gradient norms during training and larger datasets to the improvements in model generalization. Motivated by this connection, we propose reducing gradient norms for enhanced generalization and aligning fine-tuned model with the pre-trained counterpart to retain knowledge from large-scale pre-training data. Yet, naive alignment does not guarantee gradient reduction and can potentially cause gradient explosion, complicating efforts to manage gradients. To address such an issue, we propose PACE, marrying generalization of PArameter-efficient fine-tuning with Consistency rEgularization. We perturb features learned from the adapter with the multiplicative noise and ensure the fine-tuned model remains consistent for same sample under different perturbations. Theoretical analysis shows that PACE not only implicitly regularizes gradients for enhanced generalization, but also implicitly aligns the fine-tuned and pre-trained models to retain knowledge. Experimental evidence supports our theories. PACE surpasses existing PEFT methods in visual adaptation tasks (VTAB-1k, FGVC, few-shot learning, domain adaptation) showcasing its potential for resource-efficient fine-tuning. It also improves LoRA in text classification (GLUE) and mathematical reasoning (GSM-8K).",Yao Ni; Shan Zhang; Piotr Koniusz,~Yao_Ni1; ~Shan_Zhang1; ~Piotr_Koniusz1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/a15dde638376512a338864a8c0ec121954101451.pdf,2024-04-24T06:57:39.390000,2024-09-25T18:07:19.116000,2025-01-15T16:38:31.372000,https://openreview.net/forum?id=cOuLbPhOT1,"Australian National University; Mitsubishi Electric Research Labs; Australian National University; Australian National University; UNSW Sydney; Commonwealth Scientific and Industrial Research Organisation, CSIRO"
3945,C4NbtYnyQg,C4NbtYnyQg,466,Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery,"Recent advancements have shown promise in applying traditional Semi-Supervised Learning strategies to the task of Generalized Category Discovery (GCD). Typically, this involves a teacher-student framework in which the teacher imparts knowledge to the student to classify categories, even in the absence of explicit labels. Nevertheless, GCD presents unique challenges, particularly the absence of priors for new classes, which can lead to the teacher's misguidance and unsynchronized learning with the student, culminating in suboptimal outcomes. In our work, we delve into why traditional teacher-student designs falter in generalized category discovery as compared to their success in closed-world semi-supervised learning. We identify inconsistent pattern learning as the crux of this issue and introduce FlipClass—a method that dynamically updates the teacher to align with the student's attention, instead of maintaining a static teacher reference. Our teacher-attention-update strategy refines the teacher's focus based on student feedback, promoting consistent pattern recognition and synchronized learning across old and new classes. Extensive experiments on a spectrum of benchmarks affirm that FlipClass significantly surpasses contemporary GCD methods, establishing new standards for the field.",Haonan Lin; Wenbin An; Jiahao Wang; Yan Chen; Feng Tian; Mengmeng Wang; QianYing Wang; Guang Dai; Jingdong Wang,~Haonan_Lin1; ~Wenbin_An1; ~Jiahao_Wang14; ~Yan_Chen16; ~Feng_Tian4; ~Mengmeng_Wang1; ~QianYing_Wang1; ~Guang_Dai1; ~Jingdong_Wang1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_vision,/pdf/2b0097d679b2b1297e2351cac3b7369e7b84e150.pdf,2024-04-24T03:00:28.655000,2024-09-25T18:07:18.384000,2024-11-06T06:17:21.182000,https://openreview.net/forum?id=C4NbtYnyQg,Xi'an Jiaotong University; Xi'an Jiaotong University; Alibaba Group; Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an Jiaotong University; Zhejiang University; lenovo group; SGIT AI; Baidu
3950,xZxXNhndXU,xZxXNhndXU,443,Dynamic 3D Gaussian Fields for Urban Areas,"We present an efficient neural 3D scene representation for novel-view synthesis (NVS) in large-scale, dynamic urban areas. Existing works are not well suited for applications like mixed-reality or closed-loop simulation due to their limited visual quality and non-interactive rendering speeds. Recently, rasterization-based approaches have achieved high-quality NVS at impressive speeds. However, these methods are limited to small-scale, homogeneous data, i.e. they cannot handle severe appearance and geometry variations due to weather, season, and lighting and do not scale to larger, dynamic areas with thousands of images. We propose 4DGF, a neural scene representation that scales to large-scale dynamic urban areas, handles heterogeneous input data, and substantially improves rendering speeds. We use 3D Gaussians as an efficient geometry scaffold while relying on neural fields as a compact and flexible appearance model. We integrate scene dynamics via a scene graph at global scale while modeling articulated motions on a local level via deformations. This decomposed approach enables flexible scene composition suitable for real-world applications. In experiments, we surpass the state-of-the-art by over 3 dB in PSNR and more than 200x in rendering speed.",Tobias Fischer; Jonas Kulhanek; Samuel Rota Bulò; Lorenzo Porzi; Marc Pollefeys; Peter Kontschieder,~Tobias_Fischer3; ~Jonas_Kulhanek1; ~Samuel_Rota_Bulò3; ~Lorenzo_Porzi1; ~Marc_Pollefeys2; ~Peter_Kontschieder1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,machine_vision,/pdf/65abb3d26796730cf34d63a16451810604040c39.pdf,2024-04-23T21:47:28.780000,2024-09-25T18:07:17.743000,2024-11-06T06:17:20.965000,https://openreview.net/forum?id=xZxXNhndXU,ETH Zurich; Meta; Google; ETH Zurich; Czech Technical University in Prague; Meta; Meta; Microsoft; ETH Zurich; Meta
3968,8qu52Fl1Dt,8qu52Fl1Dt,351,NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction,"Reconstruction of static visual stimuli from non-invasion brain activity fMRI achieves great success, owning to advanced deep learning models such as CLIP and Stable Diffusion. However, the research on fMRI-to-video reconstruction remains limited since decoding the spatiotemporal perception of continuous visual experiences is formidably challenging. We contend that the key to addressing these challenges lies in accurately decoding both high-level semantics and low-level perception flows, as perceived by the brain in response to video stimuli. To the end, we propose NeuroClips, an innovative framework to decode high-fidelity and smooth video from fMRI. NeuroClips utilizes a semantics reconstructor to reconstruct video keyframes, guiding semantic accuracy and consistency, and employs a perception reconstructor to capture low-level perceptual details, ensuring video smoothness. During inference, it adopts a pre-trained T2V diffusion model injected with both keyframes and low-level perception flows for video reconstruction. Evaluated on a publicly available fMRI-video dataset, NeuroClips achieves smooth high-fidelity video reconstruction of up to 6s at 8FPS, gaining significant improvements over state-of-the-art models in various metrics, e.g., a 128% improvement in SSIM and an 81% improvement in spatiotemporal metrics. Our project is available at https://github.com/gongzix/NeuroClips.",Zixuan Gong; Guangyin Bao; Qi Zhang; Zhongwei Wan; Duoqian Miao; Shoujin Wang; Lei Zhu; Changwei Wang; Rongtao Xu; Liang Hu; Ke Liu; Yu Zhang,~Zixuan_Gong2; ~Guangyin_Bao1; ~Qi_Zhang25; ~Zhongwei_Wan1; ~Duoqian_Miao1; ~Shoujin_Wang1; ~Lei_Zhu8; ~Changwei_Wang2; ~Rongtao_Xu1; ~Liang_Hu1; ~Ke_Liu11; ~Yu_Zhang60,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,neuroscience_and_cognitive_science,/pdf/258f5ea41fed74143053a220d1c9971bc970b99a.pdf,2024-04-23T12:00:54.541000,2024-09-25T18:07:15.639000,2024-11-06T06:17:20.187000,https://openreview.net/forum?id=8qu52Fl1Dt,Tongji University; Tongji University; Tongji University; The Ohio State University; Tongji University; University of Technology Sydney; Tongji University; Qilu University of Technology; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Mohamed bin Zayed University of Artificial Intelligence; Tongji University; Beijing Normal University; Tongji University
3990,IDn9SiKgLy,IDn9SiKgLy,220,Principled Bayesian Optimization in Collaboration with Human Experts,"Bayesian optimisation for real-world problems is often performed interactively with human experts, and integrating their domain knowledge is key to accelerate the optimisation process. We consider a setup where experts provide advice on the next query point through binary accept/reject recommendations (labels). Experts’ labels are often costly, requiring efficient use of their efforts, and can at the same time be unreliable, requiring careful adjustment of the degree to which any expert is trusted. We introduce the first principled approach that provides two key guarantees. (1) Handover guarantee: similar to a no-regret property, we establish a sublinear bound on the cumulative number of experts’ binary labels. Initially, multiple labels per query are needed, but the number of expert labels required asymptotically converges to zero, saving both expert effort and computation time. (2) No-harm guarantee with data-driven trust level adjustment: our adaptive trust level ensures that the convergence rate will not be worse than the one without using advice, even if the advice from experts is adversarial. Unlike existing methods that employ a user-defined function that hand-tunes the trust level adjustment, our approach enables data-driven adjustments. Real-world applications empirically demonstrate that our method not only outperforms existing baselines, but also maintains robustness despite varying labelling accuracy, in tasks of battery design with human experts.",Wenjie Xu; Masaki Adachi; Colin Jones; Michael A Osborne,~Wenjie_Xu3; ~Masaki_Adachi1; ~Colin_Jones1; ~Michael_A_Osborne1,NeurIPS 2024 spotlight,NeurIPS.cc/2024/Conference,probabilistic_methods,/pdf/b1945fe2b72e490e9c7e95adbdc326222d288c7c.pdf,2024-04-23T05:51:06.112000,2024-09-25T18:07:12.971000,2024-11-06T06:17:19.247000,https://openreview.net/forum?id=IDn9SiKgLy,University of Oxford; Toyota Motor Europe; University of Oxford
4030,0XeNkkENuI,0XeNkkENuI,14,The Road Less Scheduled,"Existing learning rate schedules that do not require specification of the optimization stopping step $T$ are greatly out-performed by learning rate schedules that depend on $T$. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available at https://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the core algorithm behind our winning entry to the MLCommons 2024 AlgoPerf Algorithmic Efficiency Challenge Self-Tuning track.",Aaron Defazio; Xingyu Alice Yang; Ahmed Khaled; Konstantin Mishchenko; Harsh Mehta; Ashok Cutkosky,~Aaron_Defazio1; ~Xingyu_Alice_Yang1; ~Ahmed_Khaled1; ~Konstantin_Mishchenko1; ~Harsh_Mehta1; ~Ashok_Cutkosky1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,optimization_for_deep_networks,/pdf/0916e1419cd701686fd3b9c460f051d162f09684.pdf,2024-04-22T20:03:37.557000,2024-09-25T18:07:08.482000,2025-01-14T21:18:48.444000,https://openreview.net/forum?id=0XeNkkENuI,Meta; Meta; Princeton University; Samsung Research UK; Meta
4031,4bKEFyUHT4,4bKEFyUHT4,10,Convolutional Differentiable Logic Gate Networks,"With the increasing inference cost of machine learning models, there is a growing interest in models with fast and efficient inference. 
Recently, an approach for learning logic gate networks directly via a differentiable relaxation was proposed. Logic gate networks are faster than conventional neural network approaches because their inference only requires logic gate operators such as NAND, OR, and XOR, which are the underlying building blocks of current hardware and can be efficiently executed. We build on this idea, extending it by deep logic gate tree convolutions, logical OR pooling, and residual initializations. This allows scaling logic gate networks up by over one order of magnitude and utilizing the paradigm of convolution. On CIFAR-10, we achieve an accuracy of 86.29% using only 61 million logic gates, which improves over the SOTA while being 29x smaller.",Felix Petersen; Hilde Kuehne; Christian Borgelt; Julian Welzel; Stefano Ermon,~Felix_Petersen1; ~Hilde_Kuehne5; ~Christian_Borgelt1; ~Julian_Welzel1; ~Stefano_Ermon1,NeurIPS 2024 oral,NeurIPS.cc/2024/Conference,machine_vision,/pdf/ed5cc7e7c11e265ee3829cfa395ffc4d8e6168f0.pdf,2024-04-22T20:02:57.696000,2024-09-25T18:07:08.202000,2025-01-15T17:48:42.741000,https://openreview.net/forum?id=4bKEFyUHT4,Stanford University; University of Tübingen; International Business Machines; University of Bonn; Ludwig-Maximilians-Universität München; InftyLabs Research; Stanford University
